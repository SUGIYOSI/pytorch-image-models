--Start--
Fri Jun 4 15:11:49 JST 2021
Added key: store_based_barrier_key:1 to store for rank: 3
Added key: store_based_barrier_key:1 to store for rank: 2
Added key: store_based_barrier_key:1 to store for rank: 0
Added key: store_based_barrier_key:1 to store for rank: 1
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
wandb: Currently logged in as: gyama_x (use `wandb login --relogin` to force relogin)
wandb: WARNING Tried to auto resume run with id PreTraining_vit_deit_tiny_patch16_224_fake_v2_1k but id PreTraining_vit_deit_tiny_patch16_224_1k is set.
wandb: wandb version 0.10.31 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
wandb: Tracking run with wandb version 0.10.27
wandb: Resuming run PreTraining_vit_deit_tiny_patch16_224_1k
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gyama_x/pytorch-image-models
wandb: üöÄ View run at https://wandb.ai/gyama_x/pytorch-image-models/runs/PreTraining_vit_deit_tiny_patch16_224_1k
wandb: Run data is saved locally in /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210604_151251-PreTraining_vit_deit_tiny_patch16_224_1k
wandb: Run `wandb offline` to turn off syncing.

Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
Model vit_deit_tiny_patch16_224 created, param count:5717416
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.9
AMP not enabled. Training in float32.
Restoring model state from checkpoint...
Restoring optimizer state from checkpoint...
Loaded checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar' (epoch 165)
Using native Torch DistributedDataParallel.
Scheduled epochs: 188
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Train: 166 [   0/1251 (  0%)]  Loss:  4.585174 (4.5852)  Time: 15.279s,   67.02/s  (15.279s,   67.02/s)  LR: 4.308e-05  Data: 13.739 (13.739)
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Train: 166 [  50/1251 (  4%)]  Loss:  4.667910 (4.6265)  Time: 0.583s, 1755.79/s  (2.855s,  358.67/s)  LR: 4.308e-05  Data: 0.019 (2.249)
Train: 166 [ 100/1251 (  8%)]  Loss:  4.688946 (4.6473)  Time: 0.590s, 1736.30/s  (2.537s,  403.63/s)  LR: 4.308e-05  Data: 0.019 (1.941)
Train: 166 [ 150/1251 ( 12%)]  Loss:  4.188485 (4.5326)  Time: 0.582s, 1759.11/s  (2.364s,  433.24/s)  LR: 4.308e-05  Data: 0.018 (1.772)
Train: 166 [ 200/1251 ( 16%)]  Loss:  4.253224 (4.4767)  Time: 0.984s, 1040.24/s  (2.329s,  439.70/s)  LR: 4.308e-05  Data: 0.420 (1.740)
Train: 166 [ 250/1251 ( 20%)]  Loss:  3.930788 (4.3858)  Time: 0.583s, 1756.80/s  (2.269s,  451.35/s)  LR: 4.308e-05  Data: 0.021 (1.681)
Train: 166 [ 300/1251 ( 24%)]  Loss:  4.658699 (4.4247)  Time: 0.581s, 1762.97/s  (2.232s,  458.68/s)  LR: 4.308e-05  Data: 0.020 (1.645)
Train: 166 [ 350/1251 ( 28%)]  Loss:  4.206464 (4.3975)  Time: 0.733s, 1397.84/s  (2.192s,  467.19/s)  LR: 4.308e-05  Data: 0.092 (1.604)
Train: 166 [ 400/1251 ( 32%)]  Loss:  4.651997 (4.4257)  Time: 0.585s, 1750.55/s  (2.175s,  470.75/s)  LR: 4.308e-05  Data: 0.021 (1.587)
Train: 166 [ 450/1251 ( 36%)]  Loss:  4.268049 (4.4100)  Time: 2.376s,  430.98/s  (2.160s,  474.14/s)  LR: 4.308e-05  Data: 1.813 (1.571)
Train: 166 [ 500/1251 ( 40%)]  Loss:  4.354222 (4.4049)  Time: 0.583s, 1755.70/s  (2.169s,  472.13/s)  LR: 4.308e-05  Data: 0.019 (1.580)
Train: 166 [ 550/1251 ( 44%)]  Loss:  4.562680 (4.4181)  Time: 1.915s,  534.72/s  (2.159s,  474.28/s)  LR: 4.308e-05  Data: 1.237 (1.567)
Train: 166 [ 600/1251 ( 48%)]  Loss:  5.184838 (4.4770)  Time: 0.582s, 1758.33/s  (2.146s,  477.16/s)  LR: 4.308e-05  Data: 0.017 (1.552)
Train: 166 [ 650/1251 ( 52%)]  Loss:  4.299881 (4.4644)  Time: 3.347s,  305.98/s  (2.138s,  479.06/s)  LR: 4.308e-05  Data: 2.773 (1.542)
Train: 166 [ 700/1251 ( 56%)]  Loss:  4.577752 (4.4719)  Time: 0.582s, 1759.53/s  (2.124s,  482.11/s)  LR: 4.308e-05  Data: 0.018 (1.530)
Train: 166 [ 750/1251 ( 60%)]  Loss:  4.820949 (4.4938)  Time: 2.913s,  351.50/s  (2.116s,  484.03/s)  LR: 4.308e-05  Data: 2.330 (1.520)
Train: 166 [ 800/1251 ( 64%)]  Loss:  4.518066 (4.4952)  Time: 0.582s, 1759.62/s  (2.111s,  484.97/s)  LR: 4.308e-05  Data: 0.020 (1.516)
Train: 166 [ 850/1251 ( 68%)]  Loss:  4.554505 (4.4985)  Time: 0.683s, 1499.82/s  (2.108s,  485.79/s)  LR: 4.308e-05  Data: 0.101 (1.512)
Train: 166 [ 900/1251 ( 72%)]  Loss:  4.820495 (4.5154)  Time: 0.583s, 1757.15/s  (2.120s,  482.96/s)  LR: 4.308e-05  Data: 0.020 (1.524)
Train: 166 [ 950/1251 ( 76%)]  Loss:  4.287943 (4.5041)  Time: 3.706s,  276.35/s  (2.128s,  481.19/s)  LR: 4.308e-05  Data: 3.107 (1.532)
Train: 166 [1000/1251 ( 80%)]  Loss:  4.014767 (4.4808)  Time: 0.583s, 1755.49/s  (2.130s,  480.79/s)  LR: 4.308e-05  Data: 0.020 (1.534)
Train: 166 [1050/1251 ( 84%)]  Loss:  4.456898 (4.4797)  Time: 3.170s,  323.05/s  (2.137s,  479.22/s)  LR: 4.308e-05  Data: 2.607 (1.540)
Train: 166 [1100/1251 ( 88%)]  Loss:  4.452426 (4.4785)  Time: 0.583s, 1755.24/s  (2.135s,  479.71/s)  LR: 4.308e-05  Data: 0.019 (1.537)
Train: 166 [1150/1251 ( 92%)]  Loss:  4.011770 (4.4590)  Time: 1.114s,  918.96/s  (2.137s,  479.13/s)  LR: 4.308e-05  Data: 0.448 (1.539)
Train: 166 [1200/1251 ( 96%)]  Loss:  4.320079 (4.4535)  Time: 0.591s, 1731.39/s  (2.134s,  479.96/s)  LR: 4.308e-05  Data: 0.020 (1.536)
Train: 166 [1250/1251 (100%)]  Loss:  4.637554 (4.4606)  Time: 0.563s, 1819.81/s  (2.135s,  479.63/s)  LR: 4.308e-05  Data: 0.000 (1.537)
Test: [   0/48]  Time: 14.106 (14.106)  Loss:  1.0438 (1.0438)  Acc@1: 78.3203 (78.3203)  Acc@5: 92.8711 (92.8711)
Test: [  48/48]  Time: 0.474 (3.351)  Loss:  1.0732 (1.9142)  Acc@1: 77.7123 (57.6960)  Acc@5: 91.2736 (81.3680)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 167 [   0/1251 (  0%)]  Loss:  4.498935 (4.4989)  Time: 6.873s,  148.98/s  (6.873s,  148.98/s)  LR: 4.017e-05  Data: 5.552 (5.552)
Train: 167 [  50/1251 (  4%)]  Loss:  4.256831 (4.3779)  Time: 0.587s, 1744.44/s  (2.325s,  440.47/s)  LR: 4.017e-05  Data: 0.020 (1.733)
Train: 167 [ 100/1251 (  8%)]  Loss:  4.775877 (4.5105)  Time: 0.587s, 1745.12/s  (2.278s,  449.59/s)  LR: 4.017e-05  Data: 0.018 (1.689)
Train: 167 [ 150/1251 ( 12%)]  Loss:  4.237914 (4.4424)  Time: 0.586s, 1747.31/s  (2.221s,  461.11/s)  LR: 4.017e-05  Data: 0.020 (1.635)
Train: 167 [ 200/1251 ( 16%)]  Loss:  4.448392 (4.4436)  Time: 0.861s, 1189.73/s  (2.210s,  463.43/s)  LR: 4.017e-05  Data: 0.298 (1.621)
Train: 167 [ 250/1251 ( 20%)]  Loss:  3.931512 (4.3582)  Time: 0.583s, 1755.88/s  (2.176s,  470.63/s)  LR: 4.017e-05  Data: 0.021 (1.586)
Train: 167 [ 300/1251 ( 24%)]  Loss:  5.138902 (4.4698)  Time: 0.584s, 1753.09/s  (2.163s,  473.44/s)  LR: 4.017e-05  Data: 0.018 (1.571)
Train: 167 [ 350/1251 ( 28%)]  Loss:  4.178310 (4.4333)  Time: 0.585s, 1751.06/s  (2.138s,  478.94/s)  LR: 4.017e-05  Data: 0.022 (1.547)
Train: 167 [ 400/1251 ( 32%)]  Loss:  4.450330 (4.4352)  Time: 2.308s,  443.63/s  (2.180s,  469.69/s)  LR: 4.017e-05  Data: 1.651 (1.585)
Train: 167 [ 450/1251 ( 36%)]  Loss:  4.686723 (4.4604)  Time: 0.585s, 1750.26/s  (2.170s,  471.85/s)  LR: 4.017e-05  Data: 0.020 (1.575)
Train: 167 [ 500/1251 ( 40%)]  Loss:  4.139941 (4.4312)  Time: 2.567s,  398.96/s  (2.185s,  468.57/s)  LR: 4.017e-05  Data: 2.004 (1.589)
Train: 167 [ 550/1251 ( 44%)]  Loss:  4.681104 (4.4521)  Time: 0.584s, 1752.60/s  (2.186s,  468.42/s)  LR: 4.017e-05  Data: 0.020 (1.590)
Train: 167 [ 600/1251 ( 48%)]  Loss:  4.862756 (4.4837)  Time: 5.845s,  175.20/s  (2.198s,  465.81/s)  LR: 4.017e-05  Data: 4.919 (1.602)
Train: 167 [ 650/1251 ( 52%)]  Loss:  4.853652 (4.5101)  Time: 0.586s, 1748.08/s  (2.203s,  464.72/s)  LR: 4.017e-05  Data: 0.020 (1.607)
Train: 167 [ 700/1251 ( 56%)]  Loss:  4.412391 (4.5036)  Time: 5.955s,  171.95/s  (2.209s,  463.51/s)  LR: 4.017e-05  Data: 5.357 (1.612)
Train: 167 [ 750/1251 ( 60%)]  Loss:  4.849823 (4.5252)  Time: 0.584s, 1753.01/s  (2.198s,  465.90/s)  LR: 4.017e-05  Data: 0.019 (1.601)
Train: 167 [ 800/1251 ( 64%)]  Loss:  5.033665 (4.5551)  Time: 7.648s,  133.89/s  (2.219s,  461.54/s)  LR: 4.017e-05  Data: 7.085 (1.621)
Train: 167 [ 850/1251 ( 68%)]  Loss:  4.530306 (4.5537)  Time: 0.584s, 1754.43/s  (2.225s,  460.13/s)  LR: 4.017e-05  Data: 0.018 (1.629)
Train: 167 [ 900/1251 ( 72%)]  Loss:  4.557068 (4.5539)  Time: 7.598s,  134.77/s  (2.241s,  457.02/s)  LR: 4.017e-05  Data: 6.902 (1.644)
Train: 167 [ 950/1251 ( 76%)]  Loss:  4.291687 (4.5408)  Time: 0.587s, 1745.60/s  (2.239s,  457.37/s)  LR: 4.017e-05  Data: 0.018 (1.643)
Train: 167 [1000/1251 ( 80%)]  Loss:  4.638471 (4.5455)  Time: 4.506s,  227.26/s  (2.239s,  457.28/s)  LR: 4.017e-05  Data: 3.825 (1.643)
Train: 167 [1050/1251 ( 84%)]  Loss:  4.659684 (4.5506)  Time: 0.588s, 1742.02/s  (2.233s,  458.56/s)  LR: 4.017e-05  Data: 0.018 (1.637)
Train: 167 [1100/1251 ( 88%)]  Loss:  4.944279 (4.5678)  Time: 3.167s,  323.34/s  (2.229s,  459.37/s)  LR: 4.017e-05  Data: 2.601 (1.633)
Train: 167 [1150/1251 ( 92%)]  Loss:  5.144969 (4.5918)  Time: 0.582s, 1758.21/s  (2.220s,  461.28/s)  LR: 4.017e-05  Data: 0.020 (1.625)
Train: 167 [1200/1251 ( 96%)]  Loss:  4.461655 (4.5866)  Time: 4.968s,  206.12/s  (2.229s,  459.34/s)  LR: 4.017e-05  Data: 4.405 (1.634)
Train: 167 [1250/1251 (100%)]  Loss:  4.590265 (4.5867)  Time: 0.564s, 1817.08/s  (2.224s,  460.38/s)  LR: 4.017e-05  Data: 0.000 (1.629)
Test: [   0/48]  Time: 14.635 (14.635)  Loss:  1.0080 (1.0080)  Acc@1: 78.5156 (78.5156)  Acc@5: 93.2617 (93.2617)
Test: [  48/48]  Time: 0.149 (3.315)  Loss:  1.0450 (1.9083)  Acc@1: 77.2406 (57.7760)  Acc@5: 91.5094 (81.3020)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 168 [   0/1251 (  0%)]  Loss:  4.703563 (4.7036)  Time: 11.176s,   91.62/s  (11.176s,   91.62/s)  LR: 3.739e-05  Data: 10.336 (10.336)
Train: 168 [  50/1251 (  4%)]  Loss:  4.122105 (4.4128)  Time: 0.584s, 1752.81/s  (2.268s,  451.50/s)  LR: 3.739e-05  Data: 0.016 (1.674)
Train: 168 [ 100/1251 (  8%)]  Loss:  4.210939 (4.3455)  Time: 0.585s, 1751.23/s  (2.231s,  459.00/s)  LR: 3.739e-05  Data: 0.019 (1.642)
Train: 168 [ 150/1251 ( 12%)]  Loss:  4.921299 (4.4895)  Time: 0.586s, 1746.59/s  (2.153s,  475.65/s)  LR: 3.739e-05  Data: 0.021 (1.562)
Train: 168 [ 200/1251 ( 16%)]  Loss:  4.790153 (4.5496)  Time: 1.863s,  549.79/s  (2.140s,  478.47/s)  LR: 3.739e-05  Data: 1.174 (1.547)
Train: 168 [ 250/1251 ( 20%)]  Loss:  4.814814 (4.5938)  Time: 0.584s, 1754.03/s  (2.110s,  485.34/s)  LR: 3.739e-05  Data: 0.022 (1.518)
Train: 168 [ 300/1251 ( 24%)]  Loss:  4.742058 (4.6150)  Time: 0.589s, 1739.66/s  (2.172s,  471.52/s)  LR: 3.739e-05  Data: 0.022 (1.578)
Train: 168 [ 350/1251 ( 28%)]  Loss:  4.678382 (4.6229)  Time: 0.583s, 1755.50/s  (2.177s,  470.32/s)  LR: 3.739e-05  Data: 0.021 (1.585)
Train: 168 [ 400/1251 ( 32%)]  Loss:  4.556716 (4.6156)  Time: 0.587s, 1743.66/s  (2.184s,  468.80/s)  LR: 3.739e-05  Data: 0.021 (1.593)
Train: 168 [ 450/1251 ( 36%)]  Loss:  4.502963 (4.6043)  Time: 0.583s, 1756.27/s  (2.184s,  468.76/s)  LR: 3.739e-05  Data: 0.021 (1.593)
Train: 168 [ 500/1251 ( 40%)]  Loss:  4.412114 (4.5868)  Time: 0.587s, 1744.92/s  (2.188s,  467.97/s)  LR: 3.739e-05  Data: 0.021 (1.598)
Train: 168 [ 550/1251 ( 44%)]  Loss:  4.160967 (4.5513)  Time: 0.585s, 1751.92/s  (2.180s,  469.63/s)  LR: 3.739e-05  Data: 0.022 (1.590)
Train: 168 [ 600/1251 ( 48%)]  Loss:  4.206859 (4.5248)  Time: 0.586s, 1748.07/s  (2.181s,  469.53/s)  LR: 3.739e-05  Data: 0.023 (1.591)
Train: 168 [ 650/1251 ( 52%)]  Loss:  3.969084 (4.4851)  Time: 0.585s, 1750.90/s  (2.176s,  470.53/s)  LR: 3.739e-05  Data: 0.018 (1.587)
Train: 168 [ 700/1251 ( 56%)]  Loss:  4.229787 (4.4681)  Time: 0.583s, 1755.89/s  (2.211s,  463.16/s)  LR: 3.739e-05  Data: 0.021 (1.621)
Train: 168 [ 750/1251 ( 60%)]  Loss:  4.971329 (4.4996)  Time: 0.585s, 1749.43/s  (2.214s,  462.45/s)  LR: 3.739e-05  Data: 0.021 (1.625)
Train: 168 [ 800/1251 ( 64%)]  Loss:  4.417362 (4.4947)  Time: 0.586s, 1746.44/s  (2.231s,  459.01/s)  LR: 3.739e-05  Data: 0.023 (1.641)
Train: 168 [ 850/1251 ( 68%)]  Loss:  3.705957 (4.4509)  Time: 0.585s, 1751.43/s  (2.228s,  459.54/s)  LR: 3.739e-05  Data: 0.020 (1.639)
Train: 168 [ 900/1251 ( 72%)]  Loss:  4.724739 (4.4653)  Time: 0.585s, 1750.58/s  (2.230s,  459.17/s)  LR: 3.739e-05  Data: 0.022 (1.641)
Train: 168 [ 950/1251 ( 76%)]  Loss:  4.870636 (4.4856)  Time: 0.584s, 1753.58/s  (2.223s,  460.58/s)  LR: 3.739e-05  Data: 0.020 (1.634)
Train: 168 [1000/1251 ( 80%)]  Loss:  4.457448 (4.4843)  Time: 0.588s, 1742.51/s  (2.221s,  461.06/s)  LR: 3.739e-05  Data: 0.018 (1.632)
Train: 168 [1050/1251 ( 84%)]  Loss:  4.248000 (4.4735)  Time: 0.587s, 1743.27/s  (2.213s,  462.69/s)  LR: 3.739e-05  Data: 0.025 (1.624)
Train: 168 [1100/1251 ( 88%)]  Loss:  4.636698 (4.4806)  Time: 0.587s, 1745.30/s  (2.227s,  459.79/s)  LR: 3.739e-05  Data: 0.020 (1.638)
Train: 168 [1150/1251 ( 92%)]  Loss:  4.288056 (4.4726)  Time: 3.565s,  287.21/s  (2.225s,  460.16/s)  LR: 3.739e-05  Data: 3.002 (1.635)
Train: 168 [1200/1251 ( 96%)]  Loss:  4.594301 (4.4775)  Time: 0.583s, 1757.05/s  (2.227s,  459.86/s)  LR: 3.739e-05  Data: 0.020 (1.636)
Train: 168 [1250/1251 (100%)]  Loss:  4.574007 (4.4812)  Time: 0.565s, 1812.87/s  (2.226s,  460.09/s)  LR: 3.739e-05  Data: 0.000 (1.635)
Test: [   0/48]  Time: 13.640 (13.640)  Loss:  1.0284 (1.0284)  Acc@1: 78.5156 (78.5156)  Acc@5: 92.9688 (92.9688)
Test: [  48/48]  Time: 0.149 (3.128)  Loss:  1.0827 (1.9125)  Acc@1: 77.8302 (57.9860)  Acc@5: 91.7453 (81.4040)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 169 [   0/1251 (  0%)]  Loss:  4.530112 (4.5301)  Time: 9.284s,  110.30/s  (9.284s,  110.30/s)  LR: 3.474e-05  Data: 8.706 (8.706)
Train: 169 [  50/1251 (  4%)]  Loss:  4.200209 (4.3652)  Time: 0.584s, 1753.53/s  (2.191s,  467.46/s)  LR: 3.474e-05  Data: 0.019 (1.607)
Train: 169 [ 100/1251 (  8%)]  Loss:  4.746729 (4.4924)  Time: 0.584s, 1752.29/s  (2.135s,  479.69/s)  LR: 3.474e-05  Data: 0.019 (1.551)
Train: 169 [ 150/1251 ( 12%)]  Loss:  4.605845 (4.5207)  Time: 0.589s, 1738.78/s  (2.093s,  489.28/s)  LR: 3.474e-05  Data: 0.020 (1.509)
Train: 169 [ 200/1251 ( 16%)]  Loss:  4.352126 (4.4870)  Time: 0.584s, 1753.80/s  (2.197s,  466.08/s)  LR: 3.474e-05  Data: 0.019 (1.614)
Train: 169 [ 250/1251 ( 20%)]  Loss:  4.751585 (4.5311)  Time: 0.584s, 1754.51/s  (2.208s,  463.77/s)  LR: 3.474e-05  Data: 0.019 (1.621)
Train: 169 [ 300/1251 ( 24%)]  Loss:  4.924514 (4.5873)  Time: 0.585s, 1750.78/s  (2.218s,  461.58/s)  LR: 3.474e-05  Data: 0.018 (1.628)
Train: 169 [ 350/1251 ( 28%)]  Loss:  4.794062 (4.6131)  Time: 0.584s, 1752.27/s  (2.213s,  462.63/s)  LR: 3.474e-05  Data: 0.018 (1.622)
Train: 169 [ 400/1251 ( 32%)]  Loss:  4.317649 (4.5803)  Time: 0.585s, 1749.76/s  (2.208s,  463.85/s)  LR: 3.474e-05  Data: 0.020 (1.615)
Train: 169 [ 450/1251 ( 36%)]  Loss:  3.994770 (4.5218)  Time: 0.583s, 1755.56/s  (2.195s,  466.59/s)  LR: 3.474e-05  Data: 0.020 (1.603)
Train: 169 [ 500/1251 ( 40%)]  Loss:  5.073564 (4.5719)  Time: 0.588s, 1741.70/s  (2.188s,  468.03/s)  LR: 3.474e-05  Data: 0.023 (1.596)
Train: 169 [ 550/1251 ( 44%)]  Loss:  4.732162 (4.5853)  Time: 0.610s, 1679.70/s  (2.175s,  470.74/s)  LR: 3.474e-05  Data: 0.048 (1.582)
Train: 169 [ 600/1251 ( 48%)]  Loss:  4.817099 (4.6031)  Time: 0.584s, 1754.35/s  (2.208s,  463.84/s)  LR: 3.474e-05  Data: 0.017 (1.611)
Train: 169 [ 650/1251 ( 52%)]  Loss:  4.775834 (4.6154)  Time: 2.560s,  400.07/s  (2.228s,  459.51/s)  LR: 3.474e-05  Data: 1.965 (1.632)
Train: 169 [ 700/1251 ( 56%)]  Loss:  4.944584 (4.6374)  Time: 0.581s, 1761.91/s  (2.254s,  454.34/s)  LR: 3.474e-05  Data: 0.017 (1.657)
Train: 169 [ 750/1251 ( 60%)]  Loss:  4.761058 (4.6451)  Time: 0.587s, 1745.02/s  (2.257s,  453.74/s)  LR: 3.474e-05  Data: 0.019 (1.660)
Train: 169 [ 800/1251 ( 64%)]  Loss:  4.696953 (4.6482)  Time: 0.587s, 1745.53/s  (2.263s,  452.47/s)  LR: 3.474e-05  Data: 0.021 (1.666)
Train: 169 [ 850/1251 ( 68%)]  Loss:  4.152252 (4.6206)  Time: 0.582s, 1759.17/s  (2.256s,  453.85/s)  LR: 3.474e-05  Data: 0.018 (1.660)
Train: 169 [ 900/1251 ( 72%)]  Loss:  4.187467 (4.5978)  Time: 0.581s, 1761.88/s  (2.253s,  454.42/s)  LR: 3.474e-05  Data: 0.018 (1.658)
Train: 169 [ 950/1251 ( 76%)]  Loss:  4.325502 (4.5842)  Time: 1.301s,  787.00/s  (2.245s,  456.21/s)  LR: 3.474e-05  Data: 0.738 (1.650)
Train: 169 [1000/1251 ( 80%)]  Loss:  4.172837 (4.5646)  Time: 0.587s, 1743.69/s  (2.259s,  453.34/s)  LR: 3.474e-05  Data: 0.021 (1.664)
Train: 169 [1050/1251 ( 84%)]  Loss:  4.933102 (4.5814)  Time: 3.665s,  279.40/s  (2.264s,  452.28/s)  LR: 3.474e-05  Data: 3.102 (1.669)
Train: 169 [1100/1251 ( 88%)]  Loss:  4.700809 (4.5866)  Time: 0.584s, 1754.09/s  (2.267s,  451.63/s)  LR: 3.474e-05  Data: 0.018 (1.672)
Train: 169 [1150/1251 ( 92%)]  Loss:  4.681962 (4.5905)  Time: 2.088s,  490.41/s  (2.269s,  451.38/s)  LR: 3.474e-05  Data: 1.517 (1.673)
Train: 169 [1200/1251 ( 96%)]  Loss:  3.972150 (4.5658)  Time: 0.583s, 1756.46/s  (2.268s,  451.48/s)  LR: 3.474e-05  Data: 0.018 (1.673)
Train: 169 [1250/1251 (100%)]  Loss:  4.380113 (4.5587)  Time: 0.567s, 1806.26/s  (2.262s,  452.62/s)  LR: 3.474e-05  Data: 0.000 (1.667)
Test: [   0/48]  Time: 13.802 (13.802)  Loss:  1.0311 (1.0311)  Acc@1: 78.6133 (78.6133)  Acc@5: 92.9688 (92.9688)
Test: [  48/48]  Time: 0.149 (3.110)  Loss:  1.0519 (1.9106)  Acc@1: 78.3019 (57.9340)  Acc@5: 91.8632 (81.4760)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 170 [   0/1251 (  0%)]  Loss:  4.390914 (4.3909)  Time: 9.234s,  110.90/s  (9.234s,  110.90/s)  LR: 3.222e-05  Data: 8.649 (8.649)
Train: 170 [  50/1251 (  4%)]  Loss:  4.169311 (4.2801)  Time: 0.586s, 1748.40/s  (2.560s,  399.96/s)  LR: 3.222e-05  Data: 0.021 (1.953)
Train: 170 [ 100/1251 (  8%)]  Loss:  4.843741 (4.4680)  Time: 2.468s,  414.84/s  (2.476s,  413.54/s)  LR: 3.222e-05  Data: 1.816 (1.864)
Train: 170 [ 150/1251 ( 12%)]  Loss:  3.789258 (4.2983)  Time: 0.583s, 1755.67/s  (2.386s,  429.15/s)  LR: 3.222e-05  Data: 0.019 (1.778)
Train: 170 [ 200/1251 ( 16%)]  Loss:  4.905926 (4.4198)  Time: 2.242s,  456.68/s  (2.377s,  430.86/s)  LR: 3.222e-05  Data: 1.580 (1.768)
Train: 170 [ 250/1251 ( 20%)]  Loss:  4.941245 (4.5067)  Time: 0.585s, 1751.66/s  (2.346s,  436.40/s)  LR: 3.222e-05  Data: 0.021 (1.739)
Train: 170 [ 300/1251 ( 24%)]  Loss:  4.490960 (4.5045)  Time: 1.688s,  606.67/s  (2.324s,  440.56/s)  LR: 3.222e-05  Data: 1.012 (1.716)
Train: 170 [ 350/1251 ( 28%)]  Loss:  4.236480 (4.4710)  Time: 0.586s, 1748.81/s  (2.295s,  446.15/s)  LR: 3.222e-05  Data: 0.019 (1.688)
Train: 170 [ 400/1251 ( 32%)]  Loss:  5.114460 (4.5425)  Time: 4.438s,  230.73/s  (2.282s,  448.74/s)  LR: 3.222e-05  Data: 3.840 (1.674)
Train: 170 [ 450/1251 ( 36%)]  Loss:  4.172290 (4.5055)  Time: 0.587s, 1745.58/s  (2.307s,  443.83/s)  LR: 3.222e-05  Data: 0.020 (1.700)
Train: 170 [ 500/1251 ( 40%)]  Loss:  4.236230 (4.4810)  Time: 3.719s,  275.37/s  (2.322s,  441.07/s)  LR: 3.222e-05  Data: 3.007 (1.715)
Train: 170 [ 550/1251 ( 44%)]  Loss:  4.169541 (4.4550)  Time: 0.587s, 1744.20/s  (2.315s,  442.40/s)  LR: 3.222e-05  Data: 0.019 (1.707)
Train: 170 [ 600/1251 ( 48%)]  Loss:  4.844242 (4.4850)  Time: 1.284s,  797.48/s  (2.319s,  441.61/s)  LR: 3.222e-05  Data: 0.699 (1.711)
Train: 170 [ 650/1251 ( 52%)]  Loss:  4.233304 (4.4670)  Time: 0.586s, 1747.97/s  (2.330s,  439.42/s)  LR: 3.222e-05  Data: 0.020 (1.721)
Train: 170 [ 700/1251 ( 56%)]  Loss:  4.142309 (4.4453)  Time: 2.918s,  350.93/s  (2.331s,  439.35/s)  LR: 3.222e-05  Data: 2.320 (1.721)
Train: 170 [ 750/1251 ( 60%)]  Loss:  4.428157 (4.4443)  Time: 0.586s, 1747.91/s  (2.324s,  440.53/s)  LR: 3.222e-05  Data: 0.019 (1.715)
Train: 170 [ 800/1251 ( 64%)]  Loss:  4.439524 (4.4440)  Time: 9.687s,  105.71/s  (2.328s,  439.95/s)  LR: 3.222e-05  Data: 9.013 (1.718)
Train: 170 [ 850/1251 ( 68%)]  Loss:  4.332932 (4.4378)  Time: 0.586s, 1746.91/s  (2.329s,  439.58/s)  LR: 3.222e-05  Data: 0.021 (1.720)
Train: 170 [ 900/1251 ( 72%)]  Loss:  4.155223 (4.4229)  Time: 4.624s,  221.44/s  (2.338s,  437.97/s)  LR: 3.222e-05  Data: 3.923 (1.729)
Train: 170 [ 950/1251 ( 76%)]  Loss:  4.711612 (4.4374)  Time: 0.588s, 1742.68/s  (2.335s,  438.61/s)  LR: 3.222e-05  Data: 0.019 (1.726)
Train: 170 [1000/1251 ( 80%)]  Loss:  4.735981 (4.4516)  Time: 4.989s,  205.26/s  (2.332s,  439.08/s)  LR: 3.222e-05  Data: 4.410 (1.724)
Train: 170 [1050/1251 ( 84%)]  Loss:  4.017677 (4.4319)  Time: 0.585s, 1751.03/s  (2.324s,  440.69/s)  LR: 3.222e-05  Data: 0.019 (1.717)
Train: 170 [1100/1251 ( 88%)]  Loss:  4.300519 (4.4262)  Time: 3.852s,  265.86/s  (2.317s,  441.96/s)  LR: 3.222e-05  Data: 3.289 (1.711)
Train: 170 [1150/1251 ( 92%)]  Loss:  4.946039 (4.4478)  Time: 0.583s, 1755.67/s  (2.310s,  443.31/s)  LR: 3.222e-05  Data: 0.020 (1.703)
Train: 170 [1200/1251 ( 96%)]  Loss:  5.109840 (4.4743)  Time: 6.646s,  154.08/s  (2.310s,  443.23/s)  LR: 3.222e-05  Data: 5.962 (1.704)
Train: 170 [1250/1251 (100%)]  Loss:  4.603873 (4.4793)  Time: 0.563s, 1818.80/s  (2.311s,  443.04/s)  LR: 3.222e-05  Data: 0.000 (1.706)
Test: [   0/48]  Time: 15.124 (15.124)  Loss:  1.0385 (1.0385)  Acc@1: 78.1250 (78.1250)  Acc@5: 93.3594 (93.3594)
Test: [  48/48]  Time: 0.149 (3.381)  Loss:  1.0599 (1.9028)  Acc@1: 77.3585 (58.1300)  Acc@5: 91.8632 (81.5440)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 171 [   0/1251 (  0%)]  Loss:  4.526402 (4.5264)  Time: 10.075s,  101.64/s  (10.075s,  101.64/s)  LR: 2.984e-05  Data: 9.437 (9.437)
Train: 171 [  50/1251 (  4%)]  Loss:  4.926575 (4.7265)  Time: 0.584s, 1753.90/s  (2.396s,  427.33/s)  LR: 2.984e-05  Data: 0.020 (1.786)
Train: 171 [ 100/1251 (  8%)]  Loss:  4.210814 (4.5546)  Time: 0.587s, 1742.98/s  (2.323s,  440.87/s)  LR: 2.984e-05  Data: 0.020 (1.724)
Train: 171 [ 150/1251 ( 12%)]  Loss:  4.592566 (4.5641)  Time: 0.589s, 1739.60/s  (2.249s,  455.34/s)  LR: 2.984e-05  Data: 0.026 (1.647)
Train: 171 [ 200/1251 ( 16%)]  Loss:  4.571695 (4.5656)  Time: 0.583s, 1757.65/s  (2.234s,  458.31/s)  LR: 2.984e-05  Data: 0.019 (1.637)
Train: 171 [ 250/1251 ( 20%)]  Loss:  4.651139 (4.5799)  Time: 2.111s,  484.98/s  (2.200s,  465.56/s)  LR: 2.984e-05  Data: 1.447 (1.603)
Train: 171 [ 300/1251 ( 24%)]  Loss:  4.205425 (4.5264)  Time: 0.582s, 1759.64/s  (2.254s,  454.23/s)  LR: 2.984e-05  Data: 0.018 (1.655)
Train: 171 [ 350/1251 ( 28%)]  Loss:  4.217183 (4.4877)  Time: 0.587s, 1743.35/s  (2.275s,  450.16/s)  LR: 2.984e-05  Data: 0.019 (1.676)
Train: 171 [ 400/1251 ( 32%)]  Loss:  4.873340 (4.5306)  Time: 0.586s, 1746.10/s  (2.294s,  446.48/s)  LR: 2.984e-05  Data: 0.019 (1.697)
Train: 171 [ 450/1251 ( 36%)]  Loss:  4.779386 (4.5555)  Time: 0.585s, 1751.29/s  (2.288s,  447.57/s)  LR: 2.984e-05  Data: 0.023 (1.692)
Train: 171 [ 500/1251 ( 40%)]  Loss:  4.324041 (4.5344)  Time: 0.585s, 1749.97/s  (2.285s,  448.22/s)  LR: 2.984e-05  Data: 0.020 (1.687)
Train: 171 [ 550/1251 ( 44%)]  Loss:  4.812353 (4.5576)  Time: 0.583s, 1757.19/s  (2.268s,  451.44/s)  LR: 2.984e-05  Data: 0.021 (1.670)
Train: 171 [ 600/1251 ( 48%)]  Loss:  4.800162 (4.5762)  Time: 0.583s, 1756.73/s  (2.268s,  451.55/s)  LR: 2.984e-05  Data: 0.019 (1.669)
Train: 171 [ 650/1251 ( 52%)]  Loss:  5.006519 (4.6070)  Time: 3.399s,  301.28/s  (2.266s,  451.90/s)  LR: 2.984e-05  Data: 2.835 (1.668)
Train: 171 [ 700/1251 ( 56%)]  Loss:  4.821601 (4.6213)  Time: 0.585s, 1749.78/s  (2.295s,  446.12/s)  LR: 2.984e-05  Data: 0.019 (1.696)
Train: 171 [ 750/1251 ( 60%)]  Loss:  4.805607 (4.6328)  Time: 4.468s,  229.18/s  (2.299s,  445.48/s)  LR: 2.984e-05  Data: 3.860 (1.699)
Train: 171 [ 800/1251 ( 64%)]  Loss:  4.662312 (4.6345)  Time: 0.583s, 1755.03/s  (2.301s,  445.09/s)  LR: 2.984e-05  Data: 0.019 (1.702)
Train: 171 [ 850/1251 ( 68%)]  Loss:  4.527992 (4.6286)  Time: 5.847s,  175.14/s  (2.299s,  445.39/s)  LR: 2.984e-05  Data: 5.167 (1.700)
Train: 171 [ 900/1251 ( 72%)]  Loss:  4.505710 (4.6221)  Time: 0.587s, 1744.41/s  (2.291s,  447.00/s)  LR: 2.984e-05  Data: 0.021 (1.692)
Train: 171 [ 950/1251 ( 76%)]  Loss:  4.815017 (4.6318)  Time: 6.756s,  151.57/s  (2.288s,  447.50/s)  LR: 2.984e-05  Data: 6.099 (1.689)
Train: 171 [1000/1251 ( 80%)]  Loss:  3.987668 (4.6011)  Time: 0.586s, 1748.00/s  (2.279s,  449.35/s)  LR: 2.984e-05  Data: 0.021 (1.681)
Train: 171 [1050/1251 ( 84%)]  Loss:  4.228045 (4.5842)  Time: 4.386s,  233.45/s  (2.274s,  450.22/s)  LR: 2.984e-05  Data: 3.705 (1.676)
Train: 171 [1100/1251 ( 88%)]  Loss:  5.100059 (4.6066)  Time: 2.032s,  504.01/s  (2.286s,  447.88/s)  LR: 2.984e-05  Data: 1.469 (1.687)
Train: 171 [1150/1251 ( 92%)]  Loss:  4.484248 (4.6015)  Time: 2.254s,  454.25/s  (2.292s,  446.77/s)  LR: 2.984e-05  Data: 1.592 (1.691)
Train: 171 [1200/1251 ( 96%)]  Loss:  4.274607 (4.5884)  Time: 1.194s,  857.83/s  (2.294s,  446.29/s)  LR: 2.984e-05  Data: 0.631 (1.692)
Train: 171 [1250/1251 (100%)]  Loss:  4.360821 (4.5797)  Time: 0.563s, 1819.60/s  (2.292s,  446.81/s)  LR: 2.984e-05  Data: 0.000 (1.689)
Test: [   0/48]  Time: 13.813 (13.813)  Loss:  1.0366 (1.0366)  Acc@1: 78.3203 (78.3203)  Acc@5: 92.4805 (92.4805)
Test: [  48/48]  Time: 0.152 (3.147)  Loss:  1.0876 (1.9020)  Acc@1: 77.5943 (57.9600)  Acc@5: 90.8019 (81.6200)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 172 [   0/1251 (  0%)]  Loss:  4.180201 (4.1802)  Time: 10.525s,   97.29/s  (10.525s,   97.29/s)  LR: 2.759e-05  Data: 9.474 (9.474)
Train: 172 [  50/1251 (  4%)]  Loss:  4.448269 (4.3142)  Time: 0.589s, 1738.16/s  (2.217s,  461.80/s)  LR: 2.759e-05  Data: 0.022 (1.619)
Train: 172 [ 100/1251 (  8%)]  Loss:  4.569843 (4.3994)  Time: 1.637s,  625.39/s  (2.197s,  466.08/s)  LR: 2.759e-05  Data: 0.955 (1.589)
Train: 172 [ 150/1251 ( 12%)]  Loss:  4.722513 (4.4802)  Time: 0.589s, 1739.88/s  (2.268s,  451.52/s)  LR: 2.759e-05  Data: 0.018 (1.659)
Train: 172 [ 200/1251 ( 16%)]  Loss:  4.953335 (4.5748)  Time: 0.620s, 1651.09/s  (2.275s,  450.14/s)  LR: 2.759e-05  Data: 0.021 (1.665)
Train: 172 [ 250/1251 ( 20%)]  Loss:  4.822287 (4.6161)  Time: 0.585s, 1751.50/s  (2.265s,  452.07/s)  LR: 2.759e-05  Data: 0.019 (1.656)
Train: 172 [ 300/1251 ( 24%)]  Loss:  4.831609 (4.6469)  Time: 0.585s, 1749.69/s  (2.266s,  451.96/s)  LR: 2.759e-05  Data: 0.022 (1.657)
Train: 172 [ 350/1251 ( 28%)]  Loss:  4.576045 (4.6380)  Time: 0.584s, 1754.23/s  (2.254s,  454.31/s)  LR: 2.759e-05  Data: 0.019 (1.644)
Train: 172 [ 400/1251 ( 32%)]  Loss:  4.496701 (4.6223)  Time: 0.588s, 1740.77/s  (2.240s,  457.14/s)  LR: 2.759e-05  Data: 0.022 (1.628)
Train: 172 [ 450/1251 ( 36%)]  Loss:  4.893396 (4.6494)  Time: 0.585s, 1751.68/s  (2.227s,  459.78/s)  LR: 2.759e-05  Data: 0.022 (1.616)
Train: 172 [ 500/1251 ( 40%)]  Loss:  4.390630 (4.6259)  Time: 0.588s, 1740.28/s  (2.216s,  462.06/s)  LR: 2.759e-05  Data: 0.026 (1.606)
Train: 172 [ 550/1251 ( 44%)]  Loss:  4.114849 (4.5833)  Time: 0.583s, 1757.28/s  (2.241s,  456.95/s)  LR: 2.759e-05  Data: 0.019 (1.632)
Train: 172 [ 600/1251 ( 48%)]  Loss:  5.017799 (4.6167)  Time: 0.585s, 1751.89/s  (2.260s,  453.03/s)  LR: 2.759e-05  Data: 0.018 (1.653)
Train: 172 [ 650/1251 ( 52%)]  Loss:  4.311276 (4.5949)  Time: 0.586s, 1747.31/s  (2.279s,  449.33/s)  LR: 2.759e-05  Data: 0.019 (1.672)
Train: 172 [ 700/1251 ( 56%)]  Loss:  4.717317 (4.6031)  Time: 0.584s, 1753.68/s  (2.289s,  447.34/s)  LR: 2.759e-05  Data: 0.019 (1.684)
Train: 172 [ 750/1251 ( 60%)]  Loss:  3.844015 (4.5556)  Time: 0.587s, 1745.91/s  (2.284s,  448.36/s)  LR: 2.759e-05  Data: 0.019 (1.680)
Train: 172 [ 800/1251 ( 64%)]  Loss:  4.170005 (4.5329)  Time: 0.585s, 1750.01/s  (2.280s,  449.16/s)  LR: 2.759e-05  Data: 0.021 (1.676)
Train: 172 [ 850/1251 ( 68%)]  Loss:  4.056693 (4.5065)  Time: 0.584s, 1754.60/s  (2.269s,  451.25/s)  LR: 2.759e-05  Data: 0.018 (1.667)
Train: 172 [ 900/1251 ( 72%)]  Loss:  4.968194 (4.5308)  Time: 0.587s, 1743.05/s  (2.267s,  451.72/s)  LR: 2.759e-05  Data: 0.019 (1.665)
Train: 172 [ 950/1251 ( 76%)]  Loss:  4.618649 (4.5352)  Time: 0.587s, 1745.55/s  (2.277s,  449.78/s)  LR: 2.759e-05  Data: 0.020 (1.675)
Train: 172 [1000/1251 ( 80%)]  Loss:  4.570414 (4.5369)  Time: 0.584s, 1753.00/s  (2.278s,  449.50/s)  LR: 2.759e-05  Data: 0.017 (1.676)
Train: 172 [1050/1251 ( 84%)]  Loss:  4.093295 (4.5167)  Time: 2.096s,  488.59/s  (2.280s,  449.21/s)  LR: 2.759e-05  Data: 1.425 (1.677)
Train: 172 [1100/1251 ( 88%)]  Loss:  4.242476 (4.5048)  Time: 0.586s, 1746.34/s  (2.284s,  448.24/s)  LR: 2.759e-05  Data: 0.020 (1.681)
Train: 172 [1150/1251 ( 92%)]  Loss:  3.774565 (4.4743)  Time: 0.584s, 1751.99/s  (2.281s,  448.97/s)  LR: 2.759e-05  Data: 0.020 (1.679)
Train: 172 [1200/1251 ( 96%)]  Loss:  5.175437 (4.5024)  Time: 0.586s, 1746.55/s  (2.283s,  448.59/s)  LR: 2.759e-05  Data: 0.019 (1.682)
Train: 172 [1250/1251 (100%)]  Loss:  4.592528 (4.5059)  Time: 0.564s, 1816.58/s  (2.275s,  450.11/s)  LR: 2.759e-05  Data: 0.000 (1.674)
Test: [   0/48]  Time: 13.922 (13.922)  Loss:  1.0330 (1.0330)  Acc@1: 77.6367 (77.6367)  Acc@5: 93.0664 (93.0664)
Test: [  48/48]  Time: 0.149 (3.414)  Loss:  1.0940 (1.9117)  Acc@1: 77.5943 (57.9420)  Acc@5: 91.7453 (81.5440)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-172.pth.tar', 57.941999963378905)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 173 [   0/1251 (  0%)]  Loss:  4.664822 (4.6648)  Time: 12.802s,   79.98/s  (12.802s,   79.98/s)  LR: 2.547e-05  Data: 12.130 (12.130)
Train: 173 [  50/1251 (  4%)]  Loss:  4.723686 (4.6943)  Time: 0.582s, 1758.28/s  (2.698s,  379.59/s)  LR: 2.547e-05  Data: 0.018 (2.116)
Train: 173 [ 100/1251 (  8%)]  Loss:  5.063969 (4.8175)  Time: 0.589s, 1740.00/s  (2.667s,  383.99/s)  LR: 2.547e-05  Data: 0.021 (2.082)
Train: 173 [ 150/1251 ( 12%)]  Loss:  4.364207 (4.7042)  Time: 0.585s, 1750.45/s  (2.580s,  396.95/s)  LR: 2.547e-05  Data: 0.018 (1.991)
Train: 173 [ 200/1251 ( 16%)]  Loss:  4.735691 (4.7105)  Time: 0.584s, 1754.55/s  (2.548s,  401.87/s)  LR: 2.547e-05  Data: 0.021 (1.956)
Train: 173 [ 250/1251 ( 20%)]  Loss:  4.369694 (4.6537)  Time: 0.585s, 1750.48/s  (2.477s,  413.42/s)  LR: 2.547e-05  Data: 0.018 (1.886)
Train: 173 [ 300/1251 ( 24%)]  Loss:  4.596383 (4.6455)  Time: 0.582s, 1759.07/s  (2.444s,  418.96/s)  LR: 2.547e-05  Data: 0.019 (1.854)
Train: 173 [ 350/1251 ( 28%)]  Loss:  4.430785 (4.6187)  Time: 0.590s, 1736.59/s  (2.394s,  427.75/s)  LR: 2.547e-05  Data: 0.020 (1.802)
Train: 173 [ 400/1251 ( 32%)]  Loss:  4.726589 (4.6306)  Time: 0.581s, 1761.00/s  (2.415s,  424.03/s)  LR: 2.547e-05  Data: 0.019 (1.825)
Train: 173 [ 450/1251 ( 36%)]  Loss:  4.828600 (4.6504)  Time: 0.588s, 1742.97/s  (2.401s,  426.44/s)  LR: 2.547e-05  Data: 0.019 (1.813)
Train: 173 [ 500/1251 ( 40%)]  Loss:  4.086459 (4.5992)  Time: 0.583s, 1756.64/s  (2.395s,  427.48/s)  LR: 2.547e-05  Data: 0.019 (1.808)
Train: 173 [ 550/1251 ( 44%)]  Loss:  4.091199 (4.5568)  Time: 0.583s, 1756.45/s  (2.387s,  428.95/s)  LR: 2.547e-05  Data: 0.018 (1.799)
Train: 173 [ 600/1251 ( 48%)]  Loss:  4.169862 (4.5271)  Time: 0.583s, 1756.08/s  (2.395s,  427.56/s)  LR: 2.547e-05  Data: 0.020 (1.807)
Train: 173 [ 650/1251 ( 52%)]  Loss:  4.459085 (4.5222)  Time: 0.582s, 1758.26/s  (2.382s,  429.80/s)  LR: 2.547e-05  Data: 0.020 (1.795)
Train: 173 [ 700/1251 ( 56%)]  Loss:  4.946815 (4.5505)  Time: 0.584s, 1753.53/s  (2.375s,  431.19/s)  LR: 2.547e-05  Data: 0.019 (1.787)
Train: 173 [ 750/1251 ( 60%)]  Loss:  4.859378 (4.5698)  Time: 0.584s, 1754.42/s  (2.369s,  432.22/s)  LR: 2.547e-05  Data: 0.020 (1.782)
Train: 173 [ 800/1251 ( 64%)]  Loss:  4.400144 (4.5598)  Time: 0.583s, 1755.40/s  (2.364s,  433.25/s)  LR: 2.547e-05  Data: 0.017 (1.777)
Train: 173 [ 850/1251 ( 68%)]  Loss:  4.775156 (4.5718)  Time: 0.584s, 1754.53/s  (2.361s,  433.68/s)  LR: 2.547e-05  Data: 0.020 (1.773)
Train: 173 [ 900/1251 ( 72%)]  Loss:  4.575846 (4.5720)  Time: 0.584s, 1752.99/s  (2.359s,  434.06/s)  LR: 2.547e-05  Data: 0.018 (1.771)
Train: 173 [ 950/1251 ( 76%)]  Loss:  4.097607 (4.5483)  Time: 0.583s, 1755.24/s  (2.348s,  436.16/s)  LR: 2.547e-05  Data: 0.020 (1.760)
Train: 173 [1000/1251 ( 80%)]  Loss:  4.244830 (4.5338)  Time: 0.591s, 1733.24/s  (2.342s,  437.24/s)  LR: 2.547e-05  Data: 0.020 (1.754)
Train: 173 [1050/1251 ( 84%)]  Loss:  4.672880 (4.5402)  Time: 0.583s, 1757.60/s  (2.330s,  439.55/s)  LR: 2.547e-05  Data: 0.020 (1.741)
Train: 173 [1100/1251 ( 88%)]  Loss:  4.460106 (4.5367)  Time: 0.583s, 1755.34/s  (2.322s,  440.96/s)  LR: 2.547e-05  Data: 0.017 (1.734)
Train: 173 [1150/1251 ( 92%)]  Loss:  4.662910 (4.5419)  Time: 0.581s, 1763.69/s  (2.313s,  442.72/s)  LR: 2.547e-05  Data: 0.018 (1.725)
Train: 173 [1200/1251 ( 96%)]  Loss:  4.652472 (4.5464)  Time: 0.584s, 1754.43/s  (2.317s,  441.91/s)  LR: 2.547e-05  Data: 0.020 (1.729)
Train: 173 [1250/1251 (100%)]  Loss:  5.061610 (4.5662)  Time: 0.566s, 1810.00/s  (2.316s,  442.20/s)  LR: 2.547e-05  Data: 0.000 (1.728)
Test: [   0/48]  Time: 13.669 (13.669)  Loss:  1.0957 (1.0957)  Acc@1: 77.9297 (77.9297)  Acc@5: 92.2852 (92.2852)
Test: [  48/48]  Time: 0.149 (3.283)  Loss:  1.0905 (1.9283)  Acc@1: 78.4198 (57.9700)  Acc@5: 91.6274 (81.5220)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-172.pth.tar', 57.941999963378905)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 174 [   0/1251 (  0%)]  Loss:  4.517791 (4.5178)  Time: 10.397s,   98.49/s  (10.397s,   98.49/s)  LR: 2.348e-05  Data: 9.638 (9.638)
Train: 174 [  50/1251 (  4%)]  Loss:  4.972083 (4.7449)  Time: 0.582s, 1759.95/s  (2.330s,  439.45/s)  LR: 2.348e-05  Data: 0.018 (1.731)
Train: 174 [ 100/1251 (  8%)]  Loss:  4.802954 (4.7643)  Time: 0.590s, 1736.10/s  (2.252s,  454.63/s)  LR: 2.348e-05  Data: 0.023 (1.653)
Train: 174 [ 150/1251 ( 12%)]  Loss:  4.385834 (4.6697)  Time: 1.381s,  741.23/s  (2.187s,  468.20/s)  LR: 2.348e-05  Data: 0.699 (1.582)
Train: 174 [ 200/1251 ( 16%)]  Loss:  3.868778 (4.5095)  Time: 0.588s, 1741.61/s  (2.170s,  472.00/s)  LR: 2.348e-05  Data: 0.025 (1.559)
Train: 174 [ 250/1251 ( 20%)]  Loss:  4.889678 (4.5729)  Time: 0.586s, 1748.16/s  (2.208s,  463.73/s)  LR: 2.348e-05  Data: 0.021 (1.593)
Train: 174 [ 300/1251 ( 24%)]  Loss:  4.925980 (4.6233)  Time: 0.592s, 1728.67/s  (2.228s,  459.50/s)  LR: 2.348e-05  Data: 0.025 (1.614)
Train: 174 [ 350/1251 ( 28%)]  Loss:  4.551923 (4.6144)  Time: 3.433s,  298.31/s  (2.232s,  458.84/s)  LR: 2.348e-05  Data: 2.759 (1.619)
Train: 174 [ 400/1251 ( 32%)]  Loss:  4.313208 (4.5809)  Time: 3.522s,  290.78/s  (2.253s,  454.50/s)  LR: 2.348e-05  Data: 2.915 (1.640)
Train: 174 [ 450/1251 ( 36%)]  Loss:  4.519258 (4.5747)  Time: 3.436s,  298.03/s  (2.246s,  455.87/s)  LR: 2.348e-05  Data: 2.797 (1.635)
Train: 174 [ 500/1251 ( 40%)]  Loss:  5.202149 (4.6318)  Time: 1.528s,  669.96/s  (2.241s,  456.94/s)  LR: 2.348e-05  Data: 0.961 (1.628)
Train: 174 [ 550/1251 ( 44%)]  Loss:  4.806746 (4.6464)  Time: 6.679s,  153.31/s  (2.242s,  456.64/s)  LR: 2.348e-05  Data: 5.974 (1.631)
Train: 174 [ 600/1251 ( 48%)]  Loss:  4.070923 (4.6021)  Time: 2.091s,  489.61/s  (2.233s,  458.55/s)  LR: 2.348e-05  Data: 1.503 (1.622)
Train: 174 [ 650/1251 ( 52%)]  Loss:  4.463761 (4.5922)  Time: 4.793s,  213.67/s  (2.262s,  452.68/s)  LR: 2.348e-05  Data: 4.091 (1.650)
Train: 174 [ 700/1251 ( 56%)]  Loss:  4.320447 (4.5741)  Time: 2.269s,  451.35/s  (2.264s,  452.25/s)  LR: 2.348e-05  Data: 1.704 (1.654)
Train: 174 [ 750/1251 ( 60%)]  Loss:  4.342563 (4.5596)  Time: 5.164s,  198.29/s  (2.265s,  452.00/s)  LR: 2.348e-05  Data: 4.496 (1.655)
Train: 174 [ 800/1251 ( 64%)]  Loss:  4.897380 (4.5795)  Time: 1.773s,  577.67/s  (2.264s,  452.26/s)  LR: 2.348e-05  Data: 1.199 (1.655)
Train: 174 [ 850/1251 ( 68%)]  Loss:  4.537356 (4.5772)  Time: 6.245s,  163.97/s  (2.263s,  452.43/s)  LR: 2.348e-05  Data: 5.682 (1.655)
Train: 174 [ 900/1251 ( 72%)]  Loss:  4.615024 (4.5791)  Time: 0.893s, 1146.50/s  (2.254s,  454.29/s)  LR: 2.348e-05  Data: 0.325 (1.646)
Train: 174 [ 950/1251 ( 76%)]  Loss:  3.972858 (4.5488)  Time: 4.711s,  217.36/s  (2.248s,  455.57/s)  LR: 2.348e-05  Data: 4.148 (1.641)
Train: 174 [1000/1251 ( 80%)]  Loss:  4.432002 (4.5433)  Time: 2.712s,  377.55/s  (2.237s,  457.69/s)  LR: 2.348e-05  Data: 2.056 (1.630)
Train: 174 [1050/1251 ( 84%)]  Loss:  4.303932 (4.5324)  Time: 3.285s,  311.73/s  (2.247s,  455.67/s)  LR: 2.348e-05  Data: 2.695 (1.639)
Train: 174 [1100/1251 ( 88%)]  Loss:  5.102769 (4.5572)  Time: 4.734s,  216.30/s  (2.247s,  455.82/s)  LR: 2.348e-05  Data: 4.169 (1.638)
Train: 174 [1150/1251 ( 92%)]  Loss:  4.470454 (4.5536)  Time: 6.886s,  148.71/s  (2.246s,  455.86/s)  LR: 2.348e-05  Data: 6.300 (1.638)
Train: 174 [1200/1251 ( 96%)]  Loss:  4.850607 (4.5655)  Time: 1.517s,  675.01/s  (2.244s,  456.36/s)  LR: 2.348e-05  Data: 0.828 (1.635)
Train: 174 [1250/1251 (100%)]  Loss:  4.375387 (4.5581)  Time: 0.563s, 1818.66/s  (2.237s,  457.74/s)  LR: 2.348e-05  Data: 0.000 (1.628)
Test: [   0/48]  Time: 13.348 (13.348)  Loss:  1.0421 (1.0421)  Acc@1: 77.5391 (77.5391)  Acc@5: 93.0664 (93.0664)
Test: [  48/48]  Time: 0.149 (3.110)  Loss:  1.0624 (1.8981)  Acc@1: 77.4764 (58.1840)  Acc@5: 91.6274 (81.7320)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-172.pth.tar', 57.941999963378905)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 175 [   0/1251 (  0%)]  Loss:  4.628763 (4.6288)  Time: 10.201s,  100.38/s  (10.201s,  100.38/s)  LR: 2.163e-05  Data: 9.305 (9.305)
Train: 175 [  50/1251 (  4%)]  Loss:  4.388113 (4.5084)  Time: 0.585s, 1749.79/s  (2.229s,  459.43/s)  LR: 2.163e-05  Data: 0.019 (1.623)
Train: 175 [ 100/1251 (  8%)]  Loss:  3.982205 (4.3330)  Time: 0.581s, 1761.73/s  (2.163s,  473.48/s)  LR: 2.163e-05  Data: 0.018 (1.571)
Train: 175 [ 150/1251 ( 12%)]  Loss:  4.560501 (4.3899)  Time: 0.581s, 1762.91/s  (2.225s,  460.16/s)  LR: 2.163e-05  Data: 0.017 (1.629)
Train: 175 [ 200/1251 ( 16%)]  Loss:  4.402094 (4.3923)  Time: 0.585s, 1751.07/s  (2.238s,  457.64/s)  LR: 2.163e-05  Data: 0.020 (1.647)
Train: 175 [ 250/1251 ( 20%)]  Loss:  4.751682 (4.4522)  Time: 0.585s, 1750.86/s  (2.208s,  463.86/s)  LR: 2.163e-05  Data: 0.020 (1.614)
Train: 175 [ 300/1251 ( 24%)]  Loss:  4.291946 (4.4293)  Time: 1.427s,  717.58/s  (2.221s,  461.15/s)  LR: 2.163e-05  Data: 0.863 (1.630)
Train: 175 [ 350/1251 ( 28%)]  Loss:  5.015486 (4.5026)  Time: 0.584s, 1752.41/s  (2.194s,  466.78/s)  LR: 2.163e-05  Data: 0.021 (1.603)
Train: 175 [ 400/1251 ( 32%)]  Loss:  4.986696 (4.5564)  Time: 0.587s, 1743.91/s  (2.190s,  467.56/s)  LR: 2.163e-05  Data: 0.024 (1.596)
Train: 175 [ 450/1251 ( 36%)]  Loss:  4.284560 (4.5292)  Time: 0.583s, 1755.19/s  (2.176s,  470.64/s)  LR: 2.163e-05  Data: 0.019 (1.580)
Train: 175 [ 500/1251 ( 40%)]  Loss:  4.836804 (4.5572)  Time: 0.587s, 1744.05/s  (2.174s,  471.08/s)  LR: 2.163e-05  Data: 0.023 (1.577)
Train: 175 [ 550/1251 ( 44%)]  Loss:  3.934961 (4.5053)  Time: 2.515s,  407.16/s  (2.195s,  466.49/s)  LR: 2.163e-05  Data: 1.952 (1.598)
Train: 175 [ 600/1251 ( 48%)]  Loss:  4.917324 (4.5370)  Time: 0.589s, 1739.66/s  (2.204s,  464.51/s)  LR: 2.163e-05  Data: 0.026 (1.606)
Train: 175 [ 650/1251 ( 52%)]  Loss:  4.680760 (4.5473)  Time: 0.583s, 1757.86/s  (2.211s,  463.08/s)  LR: 2.163e-05  Data: 0.020 (1.613)
Train: 175 [ 700/1251 ( 56%)]  Loss:  4.805356 (4.5645)  Time: 0.667s, 1534.62/s  (2.225s,  460.25/s)  LR: 2.163e-05  Data: 0.033 (1.628)
Train: 175 [ 750/1251 ( 60%)]  Loss:  4.217446 (4.5428)  Time: 0.596s, 1718.63/s  (2.219s,  461.47/s)  LR: 2.163e-05  Data: 0.024 (1.622)
Train: 175 [ 800/1251 ( 64%)]  Loss:  4.680836 (4.5509)  Time: 0.583s, 1757.78/s  (2.219s,  461.53/s)  LR: 2.163e-05  Data: 0.019 (1.622)
Train: 175 [ 850/1251 ( 68%)]  Loss:  4.527661 (4.5496)  Time: 0.582s, 1760.34/s  (2.209s,  463.57/s)  LR: 2.163e-05  Data: 0.017 (1.614)
Train: 175 [ 900/1251 ( 72%)]  Loss:  3.884245 (4.5146)  Time: 0.584s, 1753.48/s  (2.206s,  464.18/s)  LR: 2.163e-05  Data: 0.020 (1.611)
Train: 175 [ 950/1251 ( 76%)]  Loss:  4.496341 (4.5137)  Time: 0.585s, 1750.04/s  (2.212s,  462.87/s)  LR: 2.163e-05  Data: 0.022 (1.618)
Train: 175 [1000/1251 ( 80%)]  Loss:  4.244724 (4.5009)  Time: 0.582s, 1758.57/s  (2.221s,  461.01/s)  LR: 2.163e-05  Data: 0.019 (1.627)
Train: 175 [1050/1251 ( 84%)]  Loss:  4.534180 (4.5024)  Time: 0.583s, 1755.54/s  (2.222s,  460.77/s)  LR: 2.163e-05  Data: 0.021 (1.628)
Train: 175 [1100/1251 ( 88%)]  Loss:  4.641268 (4.5084)  Time: 0.585s, 1751.13/s  (2.222s,  460.84/s)  LR: 2.163e-05  Data: 0.019 (1.628)
Train: 175 [1150/1251 ( 92%)]  Loss:  4.635397 (4.5137)  Time: 0.588s, 1742.08/s  (2.218s,  461.65/s)  LR: 2.163e-05  Data: 0.021 (1.624)
Train: 175 [1200/1251 ( 96%)]  Loss:  4.304661 (4.5054)  Time: 0.585s, 1750.46/s  (2.216s,  462.00/s)  LR: 2.163e-05  Data: 0.022 (1.622)
Train: 175 [1250/1251 (100%)]  Loss:  4.607607 (4.5093)  Time: 0.563s, 1819.43/s  (2.210s,  463.36/s)  LR: 2.163e-05  Data: 0.000 (1.616)
Test: [   0/48]  Time: 12.755 (12.755)  Loss:  1.0327 (1.0327)  Acc@1: 77.8320 (77.8320)  Acc@5: 93.1641 (93.1641)
Test: [  48/48]  Time: 0.149 (3.005)  Loss:  1.0554 (1.8843)  Acc@1: 78.5377 (58.3160)  Acc@5: 91.9811 (81.7960)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-172.pth.tar', 57.941999963378905)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-166.pth.tar', 57.69600001464844)

Train: 176 [   0/1251 (  0%)]  Loss:  4.437205 (4.4372)  Time: 10.189s,  100.50/s  (10.189s,  100.50/s)  LR: 1.992e-05  Data: 9.282 (9.282)
Train: 176 [  50/1251 (  4%)]  Loss:  4.577748 (4.5075)  Time: 0.584s, 1752.69/s  (2.501s,  409.44/s)  LR: 1.992e-05  Data: 0.021 (1.904)
Train: 176 [ 100/1251 (  8%)]  Loss:  4.582541 (4.5325)  Time: 3.694s,  277.22/s  (2.390s,  428.53/s)  LR: 1.992e-05  Data: 3.093 (1.793)
Train: 176 [ 150/1251 ( 12%)]  Loss:  3.988385 (4.3965)  Time: 0.584s, 1753.08/s  (2.306s,  444.11/s)  LR: 1.992e-05  Data: 0.019 (1.707)
Train: 176 [ 200/1251 ( 16%)]  Loss:  4.934402 (4.5041)  Time: 1.603s,  638.81/s  (2.285s,  448.16/s)  LR: 1.992e-05  Data: 1.030 (1.690)
Train: 176 [ 250/1251 ( 20%)]  Loss:  4.514541 (4.5058)  Time: 0.663s, 1544.37/s  (2.252s,  454.72/s)  LR: 1.992e-05  Data: 0.019 (1.654)
Train: 176 [ 300/1251 ( 24%)]  Loss:  4.819905 (4.5507)  Time: 5.331s,  192.08/s  (2.243s,  456.43/s)  LR: 1.992e-05  Data: 4.655 (1.644)
Train: 176 [ 350/1251 ( 28%)]  Loss:  3.847145 (4.4627)  Time: 0.583s, 1755.63/s  (2.211s,  463.06/s)  LR: 1.992e-05  Data: 0.020 (1.612)
Train: 176 [ 400/1251 ( 32%)]  Loss:  4.526591 (4.4698)  Time: 4.205s,  243.53/s  (2.197s,  466.05/s)  LR: 1.992e-05  Data: 3.526 (1.597)
Train: 176 [ 450/1251 ( 36%)]  Loss:  4.033093 (4.4262)  Time: 0.585s, 1749.09/s  (2.221s,  461.06/s)  LR: 1.992e-05  Data: 0.022 (1.622)
Train: 176 [ 500/1251 ( 40%)]  Loss:  4.734346 (4.4542)  Time: 4.946s,  207.04/s  (2.241s,  457.02/s)  LR: 1.992e-05  Data: 4.283 (1.639)
Train: 176 [ 550/1251 ( 44%)]  Loss:  4.443246 (4.4533)  Time: 0.588s, 1742.27/s  (2.240s,  457.11/s)  LR: 1.992e-05  Data: 0.021 (1.639)
Train: 176 [ 600/1251 ( 48%)]  Loss:  5.034243 (4.4980)  Time: 4.713s,  217.27/s  (2.245s,  456.06/s)  LR: 1.992e-05  Data: 4.034 (1.643)
Train: 176 [ 650/1251 ( 52%)]  Loss:  4.616881 (4.5064)  Time: 0.584s, 1752.00/s  (2.253s,  454.51/s)  LR: 1.992e-05  Data: 0.019 (1.650)
Train: 176 [ 700/1251 ( 56%)]  Loss:  4.394567 (4.4990)  Time: 4.323s,  236.87/s  (2.259s,  453.26/s)  LR: 1.992e-05  Data: 3.738 (1.655)
Train: 176 [ 750/1251 ( 60%)]  Loss:  4.525031 (4.5006)  Time: 0.584s, 1752.35/s  (2.250s,  455.17/s)  LR: 1.992e-05  Data: 0.020 (1.645)
Train: 176 [ 800/1251 ( 64%)]  Loss:  4.584311 (4.5055)  Time: 6.218s,  164.69/s  (2.245s,  456.13/s)  LR: 1.992e-05  Data: 5.641 (1.641)
Train: 176 [ 850/1251 ( 68%)]  Loss:  4.725664 (4.5178)  Time: 0.584s, 1752.54/s  (2.255s,  454.18/s)  LR: 1.992e-05  Data: 0.020 (1.652)
Train: 176 [ 900/1251 ( 72%)]  Loss:  4.717747 (4.5283)  Time: 8.959s,  114.29/s  (2.259s,  453.23/s)  LR: 1.992e-05  Data: 7.687 (1.657)
Train: 176 [ 950/1251 ( 76%)]  Loss:  4.135918 (4.5087)  Time: 0.584s, 1754.82/s  (2.254s,  454.30/s)  LR: 1.992e-05  Data: 0.021 (1.653)
Train: 176 [1000/1251 ( 80%)]  Loss:  4.518388 (4.5091)  Time: 6.862s,  149.23/s  (2.255s,  454.09/s)  LR: 1.992e-05  Data: 6.299 (1.655)
Train: 176 [1050/1251 ( 84%)]  Loss:  4.411738 (4.5047)  Time: 0.582s, 1759.85/s  (2.247s,  455.80/s)  LR: 1.992e-05  Data: 0.017 (1.647)
Train: 176 [1100/1251 ( 88%)]  Loss:  4.214034 (4.4921)  Time: 6.824s,  150.05/s  (2.243s,  456.50/s)  LR: 1.992e-05  Data: 6.161 (1.644)
Train: 176 [1150/1251 ( 92%)]  Loss:  4.418518 (4.4890)  Time: 0.585s, 1750.05/s  (2.230s,  459.12/s)  LR: 1.992e-05  Data: 0.022 (1.631)
Train: 176 [1200/1251 ( 96%)]  Loss:  4.637158 (4.4949)  Time: 6.393s,  160.17/s  (2.227s,  459.71/s)  LR: 1.992e-05  Data: 5.747 (1.627)
Train: 176 [1250/1251 (100%)]  Loss:  4.617518 (4.4996)  Time: 0.566s, 1809.58/s  (2.230s,  459.24/s)  LR: 1.992e-05  Data: 0.000 (1.630)
Test: [   0/48]  Time: 13.248 (13.248)  Loss:  1.0399 (1.0399)  Acc@1: 78.1250 (78.1250)  Acc@5: 93.0664 (93.0664)
Test: [  48/48]  Time: 0.149 (3.170)  Loss:  1.0411 (1.8939)  Acc@1: 78.3019 (58.3360)  Acc@5: 92.3349 (81.9160)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-172.pth.tar', 57.941999963378905)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-167.pth.tar', 57.77600006835937)

Train: 177 [   0/1251 (  0%)]  Loss:  4.726489 (4.7265)  Time: 9.964s,  102.76/s  (9.964s,  102.76/s)  LR: 1.834e-05  Data: 9.052 (9.052)
Train: 177 [  50/1251 (  4%)]  Loss:  4.494343 (4.6104)  Time: 0.585s, 1749.01/s  (2.344s,  436.86/s)  LR: 1.834e-05  Data: 0.022 (1.753)
Train: 177 [ 100/1251 (  8%)]  Loss:  4.685685 (4.6355)  Time: 1.398s,  732.54/s  (2.244s,  456.37/s)  LR: 1.834e-05  Data: 0.768 (1.652)
Train: 177 [ 150/1251 ( 12%)]  Loss:  4.894822 (4.7003)  Time: 0.586s, 1748.50/s  (2.172s,  471.50/s)  LR: 1.834e-05  Data: 0.019 (1.575)
Train: 177 [ 200/1251 ( 16%)]  Loss:  4.365193 (4.6333)  Time: 0.892s, 1147.45/s  (2.153s,  475.69/s)  LR: 1.834e-05  Data: 0.329 (1.555)
Train: 177 [ 250/1251 ( 20%)]  Loss:  4.213479 (4.5633)  Time: 0.583s, 1757.70/s  (2.116s,  484.02/s)  LR: 1.834e-05  Data: 0.018 (1.520)
Train: 177 [ 300/1251 ( 24%)]  Loss:  3.904584 (4.4692)  Time: 0.586s, 1747.57/s  (2.122s,  482.54/s)  LR: 1.834e-05  Data: 0.022 (1.527)
Train: 177 [ 350/1251 ( 28%)]  Loss:  4.696024 (4.4976)  Time: 0.584s, 1754.29/s  (2.151s,  476.10/s)  LR: 1.834e-05  Data: 0.021 (1.557)
Train: 177 [ 400/1251 ( 32%)]  Loss:  4.723055 (4.5226)  Time: 0.581s, 1762.43/s  (2.182s,  469.34/s)  LR: 1.834e-05  Data: 0.017 (1.590)
Train: 177 [ 450/1251 ( 36%)]  Loss:  4.744295 (4.5448)  Time: 0.582s, 1758.51/s  (2.185s,  468.59/s)  LR: 1.834e-05  Data: 0.019 (1.594)
Train: 177 [ 500/1251 ( 40%)]  Loss:  4.760377 (4.5644)  Time: 0.584s, 1754.55/s  (2.189s,  467.82/s)  LR: 1.834e-05  Data: 0.020 (1.599)
Train: 177 [ 550/1251 ( 44%)]  Loss:  4.495326 (4.5586)  Time: 0.583s, 1757.27/s  (2.178s,  470.06/s)  LR: 1.834e-05  Data: 0.020 (1.589)
Train: 177 [ 600/1251 ( 48%)]  Loss:  4.431197 (4.5488)  Time: 0.584s, 1752.05/s  (2.178s,  470.21/s)  LR: 1.834e-05  Data: 0.020 (1.588)
Train: 177 [ 650/1251 ( 52%)]  Loss:  4.648591 (4.5560)  Time: 0.588s, 1741.97/s  (2.168s,  472.37/s)  LR: 1.834e-05  Data: 0.021 (1.579)
Train: 177 [ 700/1251 ( 56%)]  Loss:  4.393726 (4.5451)  Time: 0.583s, 1756.93/s  (2.167s,  472.46/s)  LR: 1.834e-05  Data: 0.020 (1.576)
Train: 177 [ 750/1251 ( 60%)]  Loss:  4.412045 (4.5368)  Time: 0.584s, 1752.83/s  (2.178s,  470.19/s)  LR: 1.834e-05  Data: 0.021 (1.587)
Train: 177 [ 800/1251 ( 64%)]  Loss:  4.364452 (4.5267)  Time: 0.583s, 1756.86/s  (2.174s,  471.11/s)  LR: 1.834e-05  Data: 0.020 (1.582)
Train: 177 [ 850/1251 ( 68%)]  Loss:  4.141391 (4.5053)  Time: 0.584s, 1752.85/s  (2.179s,  469.91/s)  LR: 1.834e-05  Data: 0.021 (1.588)
Train: 177 [ 900/1251 ( 72%)]  Loss:  3.867149 (4.4717)  Time: 0.587s, 1743.57/s  (2.184s,  468.96/s)  LR: 1.834e-05  Data: 0.018 (1.592)
Train: 177 [ 950/1251 ( 76%)]  Loss:  4.429568 (4.4696)  Time: 0.583s, 1755.10/s  (2.180s,  469.65/s)  LR: 1.834e-05  Data: 0.020 (1.589)
Train: 177 [1000/1251 ( 80%)]  Loss:  4.046077 (4.4494)  Time: 0.586s, 1748.40/s  (2.176s,  470.69/s)  LR: 1.834e-05  Data: 0.019 (1.585)
Train: 177 [1050/1251 ( 84%)]  Loss:  4.711962 (4.4614)  Time: 0.586s, 1747.30/s  (2.169s,  472.01/s)  LR: 1.834e-05  Data: 0.021 (1.578)
Train: 177 [1100/1251 ( 88%)]  Loss:  4.474352 (4.4619)  Time: 0.583s, 1757.34/s  (2.166s,  472.80/s)  LR: 1.834e-05  Data: 0.018 (1.575)
Train: 177 [1150/1251 ( 92%)]  Loss:  4.615470 (4.4683)  Time: 0.585s, 1751.52/s  (2.157s,  474.76/s)  LR: 1.834e-05  Data: 0.019 (1.566)
Train: 177 [1200/1251 ( 96%)]  Loss:  4.404335 (4.4658)  Time: 0.582s, 1758.95/s  (2.168s,  472.22/s)  LR: 1.834e-05  Data: 0.020 (1.577)
Train: 177 [1250/1251 (100%)]  Loss:  4.223218 (4.4564)  Time: 0.566s, 1809.64/s  (2.171s,  471.64/s)  LR: 1.834e-05  Data: 0.000 (1.580)
Test: [   0/48]  Time: 14.629 (14.629)  Loss:  1.0369 (1.0369)  Acc@1: 78.0273 (78.0273)  Acc@5: 93.0664 (93.0664)
Test: [  48/48]  Time: 0.149 (3.160)  Loss:  1.0565 (1.8991)  Acc@1: 79.0094 (58.4100)  Acc@5: 92.2170 (81.8180)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-172.pth.tar', 57.941999963378905)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-169.pth.tar', 57.93400001220703)

Train: 178 [   0/1251 (  0%)]  Loss:  4.630874 (4.6309)  Time: 10.327s,   99.16/s  (10.327s,   99.16/s)  LR: 1.690e-05  Data: 9.514 (9.514)
Train: 178 [  50/1251 (  4%)]  Loss:  4.193889 (4.4124)  Time: 0.586s, 1748.04/s  (2.246s,  455.87/s)  LR: 1.690e-05  Data: 0.020 (1.660)
Train: 178 [ 100/1251 (  8%)]  Loss:  4.584393 (4.4697)  Time: 0.583s, 1755.17/s  (2.177s,  470.34/s)  LR: 1.690e-05  Data: 0.019 (1.585)
Train: 178 [ 150/1251 ( 12%)]  Loss:  4.285075 (4.4236)  Time: 0.584s, 1753.29/s  (2.129s,  480.97/s)  LR: 1.690e-05  Data: 0.019 (1.536)
Train: 178 [ 200/1251 ( 16%)]  Loss:  4.821867 (4.5032)  Time: 0.584s, 1754.28/s  (2.098s,  488.13/s)  LR: 1.690e-05  Data: 0.021 (1.504)
Train: 178 [ 250/1251 ( 20%)]  Loss:  4.516102 (4.5054)  Time: 0.584s, 1754.37/s  (2.090s,  489.90/s)  LR: 1.690e-05  Data: 0.019 (1.498)
Train: 178 [ 300/1251 ( 24%)]  Loss:  5.012981 (4.5779)  Time: 0.585s, 1749.32/s  (2.116s,  483.95/s)  LR: 1.690e-05  Data: 0.020 (1.523)
Train: 178 [ 350/1251 ( 28%)]  Loss:  4.812259 (4.6072)  Time: 1.512s,  677.22/s  (2.139s,  478.76/s)  LR: 1.690e-05  Data: 0.915 (1.544)
Train: 178 [ 400/1251 ( 32%)]  Loss:  4.765836 (4.6248)  Time: 0.587s, 1745.44/s  (2.156s,  475.00/s)  LR: 1.690e-05  Data: 0.023 (1.559)
Train: 178 [ 450/1251 ( 36%)]  Loss:  4.680422 (4.6304)  Time: 2.043s,  501.28/s  (2.147s,  476.87/s)  LR: 1.690e-05  Data: 1.480 (1.551)
Train: 178 [ 500/1251 ( 40%)]  Loss:  4.360869 (4.6059)  Time: 0.586s, 1748.46/s  (2.144s,  477.70/s)  LR: 1.690e-05  Data: 0.020 (1.547)
Train: 178 [ 550/1251 ( 44%)]  Loss:  4.200186 (4.5721)  Time: 1.209s,  847.18/s  (2.129s,  480.95/s)  LR: 1.690e-05  Data: 0.644 (1.533)
Train: 178 [ 600/1251 ( 48%)]  Loss:  4.476695 (4.5647)  Time: 0.586s, 1746.14/s  (2.128s,  481.14/s)  LR: 1.690e-05  Data: 0.023 (1.532)
Train: 178 [ 650/1251 ( 52%)]  Loss:  4.440766 (4.5559)  Time: 0.583s, 1756.53/s  (2.120s,  483.08/s)  LR: 1.690e-05  Data: 0.020 (1.524)
Train: 178 [ 700/1251 ( 56%)]  Loss:  4.368042 (4.5434)  Time: 0.584s, 1752.42/s  (2.152s,  475.79/s)  LR: 1.690e-05  Data: 0.021 (1.557)
Train: 178 [ 750/1251 ( 60%)]  Loss:  4.662176 (4.5508)  Time: 0.584s, 1754.01/s  (2.154s,  475.50/s)  LR: 1.690e-05  Data: 0.019 (1.559)
Train: 178 [ 800/1251 ( 64%)]  Loss:  4.182455 (4.5291)  Time: 0.587s, 1743.56/s  (2.159s,  474.39/s)  LR: 1.690e-05  Data: 0.025 (1.565)
Train: 178 [ 850/1251 ( 68%)]  Loss:  4.663578 (4.5366)  Time: 0.586s, 1748.37/s  (2.155s,  475.28/s)  LR: 1.690e-05  Data: 0.022 (1.561)
Train: 178 [ 900/1251 ( 72%)]  Loss:  4.019864 (4.5094)  Time: 0.587s, 1744.95/s  (2.159s,  474.30/s)  LR: 1.690e-05  Data: 0.024 (1.566)
Train: 178 [ 950/1251 ( 76%)]  Loss:  4.404222 (4.5041)  Time: 0.584s, 1752.36/s  (2.154s,  475.50/s)  LR: 1.690e-05  Data: 0.020 (1.562)
Train: 178 [1000/1251 ( 80%)]  Loss:  4.558710 (4.5067)  Time: 0.588s, 1742.17/s  (2.152s,  475.77/s)  LR: 1.690e-05  Data: 0.024 (1.561)
Train: 178 [1050/1251 ( 84%)]  Loss:  4.531145 (4.5078)  Time: 0.591s, 1732.24/s  (2.143s,  477.74/s)  LR: 1.690e-05  Data: 0.021 (1.553)
Train: 178 [1100/1251 ( 88%)]  Loss:  4.674847 (4.5151)  Time: 0.586s, 1747.85/s  (2.155s,  475.13/s)  LR: 1.690e-05  Data: 0.021 (1.565)
Train: 178 [1150/1251 ( 92%)]  Loss:  4.574863 (4.5176)  Time: 0.583s, 1757.24/s  (2.153s,  475.71/s)  LR: 1.690e-05  Data: 0.019 (1.562)
Train: 178 [1200/1251 ( 96%)]  Loss:  4.349012 (4.5108)  Time: 0.591s, 1733.79/s  (2.155s,  475.13/s)  LR: 1.690e-05  Data: 0.022 (1.565)
Train: 178 [1250/1251 (100%)]  Loss:  4.843178 (4.5236)  Time: 0.563s, 1819.14/s  (2.153s,  475.56/s)  LR: 1.690e-05  Data: 0.000 (1.563)
Test: [   0/48]  Time: 13.025 (13.025)  Loss:  1.0302 (1.0302)  Acc@1: 78.2227 (78.2227)  Acc@5: 92.8711 (92.8711)
Test: [  48/48]  Time: 0.149 (3.044)  Loss:  1.0530 (1.8834)  Acc@1: 77.9481 (58.4680)  Acc@5: 91.8632 (81.7520)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-172.pth.tar', 57.941999963378905)

Train: 179 [   0/1251 (  0%)]  Loss:  4.841294 (4.8413)  Time: 9.783s,  104.68/s  (9.783s,  104.68/s)  LR: 1.559e-05  Data: 9.047 (9.047)
Train: 179 [  50/1251 (  4%)]  Loss:  4.710850 (4.7761)  Time: 0.587s, 1745.63/s  (2.143s,  477.91/s)  LR: 1.559e-05  Data: 0.021 (1.558)
Train: 179 [ 100/1251 (  8%)]  Loss:  4.164667 (4.5723)  Time: 0.582s, 1758.99/s  (2.094s,  489.01/s)  LR: 1.559e-05  Data: 0.019 (1.493)
Train: 179 [ 150/1251 ( 12%)]  Loss:  4.335443 (4.5131)  Time: 0.585s, 1750.48/s  (2.048s,  500.02/s)  LR: 1.559e-05  Data: 0.021 (1.452)
Train: 179 [ 200/1251 ( 16%)]  Loss:  4.272968 (4.4650)  Time: 0.585s, 1748.96/s  (2.116s,  483.97/s)  LR: 1.559e-05  Data: 0.019 (1.515)
Train: 179 [ 250/1251 ( 20%)]  Loss:  4.079811 (4.4008)  Time: 2.585s,  396.08/s  (2.113s,  484.71/s)  LR: 1.559e-05  Data: 1.497 (1.510)
Train: 179 [ 300/1251 ( 24%)]  Loss:  4.023692 (4.3470)  Time: 0.586s, 1746.35/s  (2.148s,  476.71/s)  LR: 1.559e-05  Data: 0.020 (1.546)
Train: 179 [ 350/1251 ( 28%)]  Loss:  4.545629 (4.3718)  Time: 0.586s, 1746.33/s  (2.164s,  473.14/s)  LR: 1.559e-05  Data: 0.024 (1.561)
Train: 179 [ 400/1251 ( 32%)]  Loss:  4.871535 (4.4273)  Time: 0.601s, 1704.05/s  (2.167s,  472.50/s)  LR: 1.559e-05  Data: 0.028 (1.565)
Train: 179 [ 450/1251 ( 36%)]  Loss:  4.961522 (4.4807)  Time: 0.585s, 1751.51/s  (2.155s,  475.16/s)  LR: 1.559e-05  Data: 0.020 (1.554)
Train: 179 [ 500/1251 ( 40%)]  Loss:  4.537146 (4.4859)  Time: 0.584s, 1753.93/s  (2.153s,  475.53/s)  LR: 1.559e-05  Data: 0.019 (1.553)
Train: 179 [ 550/1251 ( 44%)]  Loss:  4.664407 (4.5007)  Time: 0.584s, 1751.99/s  (2.139s,  478.68/s)  LR: 1.559e-05  Data: 0.021 (1.541)
Train: 179 [ 600/1251 ( 48%)]  Loss:  4.202823 (4.4778)  Time: 0.583s, 1755.46/s  (2.160s,  474.07/s)  LR: 1.559e-05  Data: 0.019 (1.561)
Train: 179 [ 650/1251 ( 52%)]  Loss:  4.680604 (4.4923)  Time: 0.593s, 1726.57/s  (2.172s,  471.55/s)  LR: 1.559e-05  Data: 0.020 (1.573)
Train: 179 [ 700/1251 ( 56%)]  Loss:  4.200009 (4.4728)  Time: 0.584s, 1753.05/s  (2.187s,  468.18/s)  LR: 1.559e-05  Data: 0.019 (1.589)
Train: 179 [ 750/1251 ( 60%)]  Loss:  5.026199 (4.5074)  Time: 0.581s, 1760.98/s  (2.187s,  468.12/s)  LR: 1.559e-05  Data: 0.020 (1.589)
Train: 179 [ 800/1251 ( 64%)]  Loss:  4.505614 (4.5073)  Time: 0.696s, 1470.62/s  (2.189s,  467.88/s)  LR: 1.559e-05  Data: 0.019 (1.591)
Train: 179 [ 850/1251 ( 68%)]  Loss:  4.678317 (4.5168)  Time: 0.588s, 1742.93/s  (2.184s,  468.97/s)  LR: 1.559e-05  Data: 0.019 (1.585)
Train: 179 [ 900/1251 ( 72%)]  Loss:  4.427073 (4.5121)  Time: 0.590s, 1736.87/s  (2.180s,  469.76/s)  LR: 1.559e-05  Data: 0.019 (1.581)
Train: 179 [ 950/1251 ( 76%)]  Loss:  5.002467 (4.5366)  Time: 0.595s, 1721.79/s  (2.172s,  471.46/s)  LR: 1.559e-05  Data: 0.019 (1.572)
Train: 179 [1000/1251 ( 80%)]  Loss:  4.589436 (4.5391)  Time: 0.585s, 1750.41/s  (2.167s,  472.64/s)  LR: 1.559e-05  Data: 0.019 (1.567)
Train: 179 [1050/1251 ( 84%)]  Loss:  4.677912 (4.5454)  Time: 0.586s, 1747.00/s  (2.173s,  471.32/s)  LR: 1.559e-05  Data: 0.020 (1.573)
Train: 179 [1100/1251 ( 88%)]  Loss:  5.004931 (4.5654)  Time: 0.587s, 1745.22/s  (2.181s,  469.59/s)  LR: 1.559e-05  Data: 0.017 (1.582)
Train: 179 [1150/1251 ( 92%)]  Loss:  4.594091 (4.5666)  Time: 0.585s, 1751.79/s  (2.182s,  469.24/s)  LR: 1.559e-05  Data: 0.022 (1.584)
Train: 179 [1200/1251 ( 96%)]  Loss:  4.845254 (4.5777)  Time: 0.587s, 1745.66/s  (2.187s,  468.31/s)  LR: 1.559e-05  Data: 0.024 (1.589)
Train: 179 [1250/1251 (100%)]  Loss:  4.753638 (4.5845)  Time: 0.563s, 1819.98/s  (2.181s,  469.45/s)  LR: 1.559e-05  Data: 0.000 (1.584)
Test: [   0/48]  Time: 14.005 (14.005)  Loss:  1.0246 (1.0246)  Acc@1: 79.1992 (79.1992)  Acc@5: 93.2617 (93.2617)
Test: [  48/48]  Time: 0.149 (3.908)  Loss:  1.0655 (1.8785)  Acc@1: 78.1840 (58.5600)  Acc@5: 91.3915 (82.0160)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-171.pth.tar', 57.960000092773434)

Train: 180 [   0/1251 (  0%)]  Loss:  4.719493 (4.7195)  Time: 9.878s,  103.66/s  (9.878s,  103.66/s)  LR: 1.442e-05  Data: 9.315 (9.315)
Train: 180 [  50/1251 (  4%)]  Loss:  4.275809 (4.4977)  Time: 0.587s, 1743.05/s  (2.190s,  467.54/s)  LR: 1.442e-05  Data: 0.021 (1.610)
Train: 180 [ 100/1251 (  8%)]  Loss:  4.701137 (4.5655)  Time: 1.052s,  972.97/s  (2.312s,  442.98/s)  LR: 1.442e-05  Data: 0.375 (1.717)
Train: 180 [ 150/1251 ( 12%)]  Loss:  4.440817 (4.5343)  Time: 0.586s, 1747.83/s  (2.261s,  452.80/s)  LR: 1.442e-05  Data: 0.020 (1.668)
Train: 180 [ 200/1251 ( 16%)]  Loss:  4.550157 (4.5375)  Time: 0.585s, 1751.20/s  (2.274s,  450.37/s)  LR: 1.442e-05  Data: 0.019 (1.683)
Train: 180 [ 250/1251 ( 20%)]  Loss:  4.613464 (4.5501)  Time: 0.584s, 1753.31/s  (2.263s,  452.49/s)  LR: 1.442e-05  Data: 0.021 (1.674)
Train: 180 [ 300/1251 ( 24%)]  Loss:  4.727426 (4.5755)  Time: 0.584s, 1752.51/s  (2.261s,  452.84/s)  LR: 1.442e-05  Data: 0.021 (1.672)
Train: 180 [ 350/1251 ( 28%)]  Loss:  4.535164 (4.5704)  Time: 0.585s, 1750.24/s  (2.228s,  459.58/s)  LR: 1.442e-05  Data: 0.020 (1.637)
Train: 180 [ 400/1251 ( 32%)]  Loss:  4.900744 (4.6071)  Time: 0.586s, 1747.26/s  (2.214s,  462.58/s)  LR: 1.442e-05  Data: 0.019 (1.622)
Train: 180 [ 450/1251 ( 36%)]  Loss:  4.975760 (4.6440)  Time: 0.585s, 1751.26/s  (2.186s,  468.35/s)  LR: 1.442e-05  Data: 0.021 (1.597)
Train: 180 [ 500/1251 ( 40%)]  Loss:  4.686592 (4.6479)  Time: 0.584s, 1753.88/s  (2.210s,  463.34/s)  LR: 1.442e-05  Data: 0.018 (1.619)
Train: 180 [ 550/1251 ( 44%)]  Loss:  4.894604 (4.6684)  Time: 0.584s, 1752.47/s  (2.204s,  464.51/s)  LR: 1.442e-05  Data: 0.018 (1.612)
Train: 180 [ 600/1251 ( 48%)]  Loss:  4.375473 (4.6459)  Time: 0.589s, 1737.92/s  (2.215s,  462.28/s)  LR: 1.442e-05  Data: 0.018 (1.622)
Train: 180 [ 650/1251 ( 52%)]  Loss:  4.770824 (4.6548)  Time: 0.590s, 1736.35/s  (2.225s,  460.24/s)  LR: 1.442e-05  Data: 0.019 (1.632)
Train: 180 [ 700/1251 ( 56%)]  Loss:  4.676517 (4.6563)  Time: 0.585s, 1751.75/s  (2.234s,  458.31/s)  LR: 1.442e-05  Data: 0.019 (1.642)
Train: 180 [ 750/1251 ( 60%)]  Loss:  4.448825 (4.6433)  Time: 0.585s, 1751.23/s  (2.225s,  460.17/s)  LR: 1.442e-05  Data: 0.022 (1.633)
Train: 180 [ 800/1251 ( 64%)]  Loss:  4.786835 (4.6517)  Time: 0.586s, 1748.12/s  (2.220s,  461.34/s)  LR: 1.442e-05  Data: 0.020 (1.628)
Train: 180 [ 850/1251 ( 68%)]  Loss:  4.097354 (4.6209)  Time: 0.583s, 1755.40/s  (2.208s,  463.73/s)  LR: 1.442e-05  Data: 0.018 (1.615)
Train: 180 [ 900/1251 ( 72%)]  Loss:  4.211629 (4.5994)  Time: 1.810s,  565.85/s  (2.218s,  461.74/s)  LR: 1.442e-05  Data: 1.212 (1.623)
Train: 180 [ 950/1251 ( 76%)]  Loss:  4.888160 (4.6138)  Time: 0.584s, 1754.36/s  (2.272s,  450.70/s)  LR: 1.442e-05  Data: 0.020 (1.677)
Train: 180 [1000/1251 ( 80%)]  Loss:  4.496772 (4.6083)  Time: 2.347s,  436.28/s  (2.272s,  450.62/s)  LR: 1.442e-05  Data: 1.770 (1.677)
Train: 180 [1050/1251 ( 84%)]  Loss:  4.501059 (4.6034)  Time: 0.586s, 1747.13/s  (2.271s,  450.99/s)  LR: 1.442e-05  Data: 0.018 (1.675)
Train: 180 [1100/1251 ( 88%)]  Loss:  4.708334 (4.6080)  Time: 0.582s, 1760.79/s  (2.264s,  452.34/s)  LR: 1.442e-05  Data: 0.019 (1.669)
Train: 180 [1150/1251 ( 92%)]  Loss:  4.981718 (4.6235)  Time: 0.590s, 1734.91/s  (2.259s,  453.27/s)  LR: 1.442e-05  Data: 0.017 (1.664)
Train: 180 [1200/1251 ( 96%)]  Loss:  4.604721 (4.6228)  Time: 0.583s, 1757.33/s  (2.251s,  454.85/s)  LR: 1.442e-05  Data: 0.020 (1.657)
Train: 180 [1250/1251 (100%)]  Loss:  4.571391 (4.6208)  Time: 0.566s, 1809.06/s  (2.243s,  456.61/s)  LR: 1.442e-05  Data: 0.000 (1.649)
Test: [   0/48]  Time: 12.838 (12.838)  Loss:  1.0082 (1.0082)  Acc@1: 79.0039 (79.0039)  Acc@5: 93.2617 (93.2617)
Test: [  48/48]  Time: 0.149 (3.154)  Loss:  1.0445 (1.8665)  Acc@1: 78.3019 (58.5780)  Acc@5: 91.9811 (82.0580)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-173.pth.tar', 57.97000006347656)

Train: 181 [   0/1251 (  0%)]  Loss:  4.580877 (4.5809)  Time: 9.257s,  110.62/s  (9.257s,  110.62/s)  LR: 1.338e-05  Data: 8.234 (8.234)
Train: 181 [  50/1251 (  4%)]  Loss:  4.684054 (4.6325)  Time: 0.590s, 1736.70/s  (2.257s,  453.60/s)  LR: 1.338e-05  Data: 0.018 (1.661)
Train: 181 [ 100/1251 (  8%)]  Loss:  4.463702 (4.5762)  Time: 0.589s, 1737.98/s  (2.176s,  470.67/s)  LR: 1.338e-05  Data: 0.022 (1.573)
Train: 181 [ 150/1251 ( 12%)]  Loss:  4.974443 (4.6758)  Time: 0.584s, 1752.17/s  (2.151s,  476.10/s)  LR: 1.338e-05  Data: 0.018 (1.551)
Train: 181 [ 200/1251 ( 16%)]  Loss:  4.877304 (4.7161)  Time: 0.585s, 1749.18/s  (2.161s,  473.95/s)  LR: 1.338e-05  Data: 0.020 (1.564)
Train: 181 [ 250/1251 ( 20%)]  Loss:  4.429859 (4.6684)  Time: 0.585s, 1750.58/s  (2.131s,  480.44/s)  LR: 1.338e-05  Data: 0.020 (1.538)
Train: 181 [ 300/1251 ( 24%)]  Loss:  4.700340 (4.6729)  Time: 0.584s, 1753.72/s  (2.114s,  484.39/s)  LR: 1.338e-05  Data: 0.021 (1.522)
Train: 181 [ 350/1251 ( 28%)]  Loss:  4.135517 (4.6058)  Time: 0.584s, 1754.51/s  (2.076s,  493.16/s)  LR: 1.338e-05  Data: 0.021 (1.487)
Train: 181 [ 400/1251 ( 32%)]  Loss:  4.926181 (4.6414)  Time: 0.583s, 1755.79/s  (2.113s,  484.63/s)  LR: 1.338e-05  Data: 0.021 (1.524)
Train: 181 [ 450/1251 ( 36%)]  Loss:  4.096640 (4.5869)  Time: 0.584s, 1753.90/s  (2.091s,  489.80/s)  LR: 1.338e-05  Data: 0.021 (1.501)
Train: 181 [ 500/1251 ( 40%)]  Loss:  4.010720 (4.5345)  Time: 0.584s, 1753.83/s  (2.100s,  487.55/s)  LR: 1.338e-05  Data: 0.020 (1.510)
Train: 181 [ 550/1251 ( 44%)]  Loss:  4.198400 (4.5065)  Time: 0.584s, 1754.45/s  (2.090s,  489.97/s)  LR: 1.338e-05  Data: 0.018 (1.499)
Train: 181 [ 600/1251 ( 48%)]  Loss:  4.757169 (4.5258)  Time: 2.437s,  420.18/s  (2.157s,  474.81/s)  LR: 1.338e-05  Data: 1.786 (1.563)
Train: 181 [ 650/1251 ( 52%)]  Loss:  4.695129 (4.5379)  Time: 0.588s, 1740.77/s  (2.157s,  474.77/s)  LR: 1.338e-05  Data: 0.019 (1.563)
Train: 181 [ 700/1251 ( 56%)]  Loss:  4.412443 (4.5295)  Time: 4.665s,  219.49/s  (2.155s,  475.15/s)  LR: 1.338e-05  Data: 4.102 (1.562)
Train: 181 [ 750/1251 ( 60%)]  Loss:  3.811500 (4.4846)  Time: 0.586s, 1748.13/s  (2.146s,  477.16/s)  LR: 1.338e-05  Data: 0.023 (1.553)
Train: 181 [ 800/1251 ( 64%)]  Loss:  4.484144 (4.4846)  Time: 8.076s,  126.79/s  (2.160s,  474.10/s)  LR: 1.338e-05  Data: 7.336 (1.567)
Train: 181 [ 850/1251 ( 68%)]  Loss:  4.864820 (4.5057)  Time: 0.589s, 1737.86/s  (2.149s,  476.61/s)  LR: 1.338e-05  Data: 0.025 (1.556)
Train: 181 [ 900/1251 ( 72%)]  Loss:  4.362114 (4.4982)  Time: 6.919s,  148.00/s  (2.153s,  475.57/s)  LR: 1.338e-05  Data: 6.263 (1.561)
Train: 181 [ 950/1251 ( 76%)]  Loss:  4.807392 (4.5136)  Time: 0.586s, 1746.33/s  (2.143s,  477.92/s)  LR: 1.338e-05  Data: 0.023 (1.551)
Train: 181 [1000/1251 ( 80%)]  Loss:  4.737754 (4.5243)  Time: 6.421s,  159.47/s  (2.142s,  477.98/s)  LR: 1.338e-05  Data: 5.800 (1.551)
Train: 181 [1050/1251 ( 84%)]  Loss:  4.195371 (4.5094)  Time: 0.585s, 1749.31/s  (2.133s,  479.97/s)  LR: 1.338e-05  Data: 0.021 (1.543)
Train: 181 [1100/1251 ( 88%)]  Loss:  4.338867 (4.5019)  Time: 5.984s,  171.14/s  (2.129s,  480.98/s)  LR: 1.338e-05  Data: 5.281 (1.538)
Train: 181 [1150/1251 ( 92%)]  Loss:  4.613780 (4.5066)  Time: 0.584s, 1752.81/s  (2.121s,  482.76/s)  LR: 1.338e-05  Data: 0.021 (1.530)
Train: 181 [1200/1251 ( 96%)]  Loss:  4.486513 (4.5058)  Time: 4.767s,  214.81/s  (2.116s,  483.96/s)  LR: 1.338e-05  Data: 4.187 (1.524)
Train: 181 [1250/1251 (100%)]  Loss:  4.275424 (4.4969)  Time: 0.563s, 1819.49/s  (2.123s,  482.34/s)  LR: 1.338e-05  Data: 0.000 (1.530)
Test: [   0/48]  Time: 13.200 (13.200)  Loss:  1.0208 (1.0208)  Acc@1: 78.4180 (78.4180)  Acc@5: 92.9688 (92.9688)
Test: [  48/48]  Time: 0.149 (3.069)  Loss:  1.0349 (1.8774)  Acc@1: 77.9481 (58.5120)  Acc@5: 92.0991 (82.0900)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-181.pth.tar', 58.5120001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-168.pth.tar', 57.98600006591797)

Train: 182 [   0/1251 (  0%)]  Loss:  3.705388 (3.7054)  Time: 11.117s,   92.11/s  (11.117s,   92.11/s)  LR: 1.249e-05  Data: 10.155 (10.155)
Train: 182 [  50/1251 (  4%)]  Loss:  4.139687 (3.9225)  Time: 0.585s, 1751.00/s  (2.177s,  470.47/s)  LR: 1.249e-05  Data: 0.019 (1.585)
Train: 182 [ 100/1251 (  8%)]  Loss:  4.587176 (4.1441)  Time: 0.586s, 1747.46/s  (2.154s,  475.47/s)  LR: 1.249e-05  Data: 0.021 (1.568)
Train: 182 [ 150/1251 ( 12%)]  Loss:  4.741995 (4.2936)  Time: 0.587s, 1743.61/s  (2.123s,  482.43/s)  LR: 1.249e-05  Data: 0.021 (1.535)
Train: 182 [ 200/1251 ( 16%)]  Loss:  4.302501 (4.2953)  Time: 0.583s, 1755.08/s  (2.126s,  481.76/s)  LR: 1.249e-05  Data: 0.021 (1.531)
Train: 182 [ 250/1251 ( 20%)]  Loss:  4.344543 (4.3035)  Time: 0.582s, 1758.60/s  (2.245s,  456.13/s)  LR: 1.249e-05  Data: 0.019 (1.645)
Train: 182 [ 300/1251 ( 24%)]  Loss:  4.775196 (4.3709)  Time: 0.591s, 1732.87/s  (2.245s,  456.07/s)  LR: 1.249e-05  Data: 0.018 (1.645)
Train: 182 [ 350/1251 ( 28%)]  Loss:  4.812396 (4.4261)  Time: 0.590s, 1735.46/s  (2.254s,  454.36/s)  LR: 1.249e-05  Data: 0.020 (1.652)
Train: 182 [ 400/1251 ( 32%)]  Loss:  4.190961 (4.4000)  Time: 0.583s, 1757.22/s  (2.232s,  458.87/s)  LR: 1.249e-05  Data: 0.019 (1.633)
Train: 182 [ 450/1251 ( 36%)]  Loss:  4.333884 (4.3934)  Time: 0.584s, 1754.55/s  (2.213s,  462.80/s)  LR: 1.249e-05  Data: 0.019 (1.615)
Train: 182 [ 500/1251 ( 40%)]  Loss:  4.248688 (4.3802)  Time: 0.584s, 1753.60/s  (2.200s,  465.49/s)  LR: 1.249e-05  Data: 0.019 (1.604)
Train: 182 [ 550/1251 ( 44%)]  Loss:  4.658596 (4.4034)  Time: 0.583s, 1757.05/s  (2.180s,  469.81/s)  LR: 1.249e-05  Data: 0.018 (1.584)
Train: 182 [ 600/1251 ( 48%)]  Loss:  4.566695 (4.4160)  Time: 0.587s, 1745.54/s  (2.172s,  471.46/s)  LR: 1.249e-05  Data: 0.018 (1.577)
Train: 182 [ 650/1251 ( 52%)]  Loss:  4.543321 (4.4251)  Time: 0.585s, 1750.07/s  (2.162s,  473.72/s)  LR: 1.249e-05  Data: 0.019 (1.567)
Train: 182 [ 700/1251 ( 56%)]  Loss:  4.383397 (4.4223)  Time: 0.584s, 1752.75/s  (2.158s,  474.57/s)  LR: 1.249e-05  Data: 0.020 (1.564)
Train: 182 [ 750/1251 ( 60%)]  Loss:  4.288142 (4.4139)  Time: 0.586s, 1746.28/s  (2.166s,  472.82/s)  LR: 1.249e-05  Data: 0.021 (1.572)
Train: 182 [ 800/1251 ( 64%)]  Loss:  4.212037 (4.4020)  Time: 0.585s, 1749.87/s  (2.160s,  474.16/s)  LR: 1.249e-05  Data: 0.022 (1.566)
Train: 182 [ 850/1251 ( 68%)]  Loss:  4.554957 (4.4105)  Time: 0.586s, 1746.02/s  (2.156s,  475.02/s)  LR: 1.249e-05  Data: 0.021 (1.563)
Train: 182 [ 900/1251 ( 72%)]  Loss:  4.462030 (4.4132)  Time: 0.585s, 1751.57/s  (2.154s,  475.41/s)  LR: 1.249e-05  Data: 0.020 (1.562)
Train: 182 [ 950/1251 ( 76%)]  Loss:  4.478806 (4.4165)  Time: 0.586s, 1748.05/s  (2.147s,  477.02/s)  LR: 1.249e-05  Data: 0.023 (1.555)
Train: 182 [1000/1251 ( 80%)]  Loss:  4.130108 (4.4029)  Time: 0.585s, 1749.56/s  (2.143s,  477.88/s)  LR: 1.249e-05  Data: 0.019 (1.552)
Train: 182 [1050/1251 ( 84%)]  Loss:  4.790156 (4.4205)  Time: 0.585s, 1750.37/s  (2.135s,  479.53/s)  LR: 1.249e-05  Data: 0.022 (1.545)
Train: 182 [1100/1251 ( 88%)]  Loss:  4.705269 (4.4329)  Time: 0.584s, 1753.29/s  (2.130s,  480.64/s)  LR: 1.249e-05  Data: 0.019 (1.541)
Train: 182 [1150/1251 ( 92%)]  Loss:  4.251051 (4.4253)  Time: 0.583s, 1755.46/s  (2.121s,  482.75/s)  LR: 1.249e-05  Data: 0.020 (1.531)
Train: 182 [1200/1251 ( 96%)]  Loss:  4.547813 (4.4302)  Time: 0.587s, 1745.25/s  (2.134s,  479.79/s)  LR: 1.249e-05  Data: 0.020 (1.544)
Train: 182 [1250/1251 (100%)]  Loss:  4.435480 (4.4304)  Time: 0.563s, 1818.75/s  (2.157s,  474.80/s)  LR: 1.249e-05  Data: 0.000 (1.565)
Test: [   0/48]  Time: 16.893 (16.893)  Loss:  1.0081 (1.0081)  Acc@1: 78.5156 (78.5156)  Acc@5: 93.1641 (93.1641)
Test: [  48/48]  Time: 0.149 (3.234)  Loss:  1.0423 (1.8610)  Acc@1: 78.1840 (58.7320)  Acc@5: 91.7453 (82.2380)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-182.pth.tar', 58.7319999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-181.pth.tar', 58.5120001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-170.pth.tar', 58.129999990234374)

Train: 183 [   0/1251 (  0%)]  Loss:  4.529408 (4.5294)  Time: 11.091s,   92.33/s  (11.091s,   92.33/s)  LR: 1.173e-05  Data: 10.117 (10.117)
Train: 183 [  50/1251 (  4%)]  Loss:  4.542479 (4.5359)  Time: 0.586s, 1748.43/s  (2.254s,  454.21/s)  LR: 1.173e-05  Data: 0.021 (1.665)
Train: 183 [ 100/1251 (  8%)]  Loss:  4.869586 (4.6472)  Time: 0.590s, 1735.84/s  (2.219s,  461.57/s)  LR: 1.173e-05  Data: 0.024 (1.627)
Train: 183 [ 150/1251 ( 12%)]  Loss:  4.367796 (4.5773)  Time: 0.585s, 1751.21/s  (2.154s,  475.35/s)  LR: 1.173e-05  Data: 0.020 (1.566)
Train: 183 [ 200/1251 ( 16%)]  Loss:  4.965036 (4.6549)  Time: 0.586s, 1747.52/s  (2.143s,  477.80/s)  LR: 1.173e-05  Data: 0.021 (1.552)
Train: 183 [ 250/1251 ( 20%)]  Loss:  4.074322 (4.5581)  Time: 0.585s, 1750.66/s  (2.140s,  478.51/s)  LR: 1.173e-05  Data: 0.022 (1.549)
Train: 183 [ 300/1251 ( 24%)]  Loss:  4.675522 (4.5749)  Time: 2.255s,  454.12/s  (2.157s,  474.65/s)  LR: 1.173e-05  Data: 1.566 (1.567)
Train: 183 [ 350/1251 ( 28%)]  Loss:  4.541589 (4.5707)  Time: 0.582s, 1760.02/s  (2.148s,  476.70/s)  LR: 1.173e-05  Data: 0.019 (1.556)
Train: 183 [ 400/1251 ( 32%)]  Loss:  5.001502 (4.6186)  Time: 2.258s,  453.52/s  (2.150s,  476.21/s)  LR: 1.173e-05  Data: 1.535 (1.559)
Train: 183 [ 450/1251 ( 36%)]  Loss:  4.069498 (4.5637)  Time: 0.586s, 1747.20/s  (2.138s,  478.92/s)  LR: 1.173e-05  Data: 0.019 (1.547)
Train: 183 [ 500/1251 ( 40%)]  Loss:  4.269025 (4.5369)  Time: 0.908s, 1127.17/s  (2.138s,  478.88/s)  LR: 1.173e-05  Data: 0.316 (1.546)
Train: 183 [ 550/1251 ( 44%)]  Loss:  4.587306 (4.5411)  Time: 0.584s, 1752.93/s  (2.128s,  481.22/s)  LR: 1.173e-05  Data: 0.022 (1.536)
Train: 183 [ 600/1251 ( 48%)]  Loss:  4.606888 (4.5462)  Time: 1.230s,  832.50/s  (2.130s,  480.81/s)  LR: 1.173e-05  Data: 0.664 (1.536)
Train: 183 [ 650/1251 ( 52%)]  Loss:  4.110353 (4.5150)  Time: 0.585s, 1749.69/s  (2.124s,  482.12/s)  LR: 1.173e-05  Data: 0.020 (1.530)
Train: 183 [ 700/1251 ( 56%)]  Loss:  4.062255 (4.4848)  Time: 3.214s,  318.62/s  (2.160s,  474.01/s)  LR: 1.173e-05  Data: 2.556 (1.565)
Train: 183 [ 750/1251 ( 60%)]  Loss:  4.466597 (4.4837)  Time: 0.584s, 1754.20/s  (2.149s,  476.57/s)  LR: 1.173e-05  Data: 0.020 (1.554)
Train: 183 [ 800/1251 ( 64%)]  Loss:  4.893440 (4.5078)  Time: 3.687s,  277.71/s  (2.161s,  473.88/s)  LR: 1.173e-05  Data: 3.121 (1.565)
Train: 183 [ 850/1251 ( 68%)]  Loss:  4.518682 (4.5084)  Time: 0.585s, 1751.70/s  (2.155s,  475.27/s)  LR: 1.173e-05  Data: 0.018 (1.558)
Train: 183 [ 900/1251 ( 72%)]  Loss:  4.942666 (4.5313)  Time: 2.134s,  479.91/s  (2.203s,  464.73/s)  LR: 1.173e-05  Data: 1.564 (1.605)
Train: 183 [ 950/1251 ( 76%)]  Loss:  4.438544 (4.5266)  Time: 0.588s, 1740.80/s  (2.199s,  465.73/s)  LR: 1.173e-05  Data: 0.018 (1.599)
Train: 183 [1000/1251 ( 80%)]  Loss:  5.001398 (4.5492)  Time: 0.876s, 1169.21/s  (2.191s,  467.31/s)  LR: 1.173e-05  Data: 0.157 (1.589)
Train: 183 [1050/1251 ( 84%)]  Loss:  4.099213 (4.5288)  Time: 0.584s, 1754.40/s  (2.183s,  469.10/s)  LR: 1.173e-05  Data: 0.020 (1.581)
Train: 183 [1100/1251 ( 88%)]  Loss:  3.982543 (4.5050)  Time: 0.583s, 1757.02/s  (2.197s,  466.07/s)  LR: 1.173e-05  Data: 0.020 (1.594)
Train: 183 [1150/1251 ( 92%)]  Loss:  4.506465 (4.5051)  Time: 0.587s, 1744.58/s  (2.186s,  468.40/s)  LR: 1.173e-05  Data: 0.020 (1.583)
Train: 183 [1200/1251 ( 96%)]  Loss:  4.216832 (4.4936)  Time: 0.586s, 1747.26/s  (2.194s,  466.66/s)  LR: 1.173e-05  Data: 0.019 (1.592)
Train: 183 [1250/1251 (100%)]  Loss:  4.957623 (4.5114)  Time: 0.565s, 1813.48/s  (2.186s,  468.49/s)  LR: 1.173e-05  Data: 0.000 (1.584)
Test: [   0/48]  Time: 14.163 (14.163)  Loss:  0.9943 (0.9943)  Acc@1: 79.1992 (79.1992)  Acc@5: 93.2617 (93.2617)
Test: [  48/48]  Time: 0.149 (3.119)  Loss:  1.0595 (1.8660)  Acc@1: 78.0660 (58.7060)  Acc@5: 91.6274 (82.1820)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-182.pth.tar', 58.7319999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-183.pth.tar', 58.7060000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-181.pth.tar', 58.5120001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-174.pth.tar', 58.18400004150391)

Train: 184 [   0/1251 (  0%)]  Loss:  4.951211 (4.9512)  Time: 9.318s,  109.90/s  (9.318s,  109.90/s)  LR: 1.111e-05  Data: 8.755 (8.755)
Train: 184 [  50/1251 (  4%)]  Loss:  4.791930 (4.8716)  Time: 0.588s, 1742.73/s  (2.163s,  473.42/s)  LR: 1.111e-05  Data: 0.019 (1.575)
Train: 184 [ 100/1251 (  8%)]  Loss:  4.950692 (4.8979)  Time: 5.823s,  175.84/s  (2.123s,  482.26/s)  LR: 1.111e-05  Data: 5.231 (1.525)
Train: 184 [ 150/1251 ( 12%)]  Loss:  4.832986 (4.8817)  Time: 0.582s, 1760.10/s  (2.042s,  501.35/s)  LR: 1.111e-05  Data: 0.018 (1.447)
Train: 184 [ 200/1251 ( 16%)]  Loss:  4.846336 (4.8746)  Time: 6.399s,  160.02/s  (2.139s,  478.79/s)  LR: 1.111e-05  Data: 5.836 (1.542)
Train: 184 [ 250/1251 ( 20%)]  Loss:  4.376807 (4.7917)  Time: 0.584s, 1753.61/s  (2.082s,  491.92/s)  LR: 1.111e-05  Data: 0.019 (1.487)
Train: 184 [ 300/1251 ( 24%)]  Loss:  4.708768 (4.7798)  Time: 6.643s,  154.16/s  (2.118s,  483.53/s)  LR: 1.111e-05  Data: 6.079 (1.524)
Train: 184 [ 350/1251 ( 28%)]  Loss:  4.704700 (4.7704)  Time: 0.586s, 1748.19/s  (2.085s,  491.19/s)  LR: 1.111e-05  Data: 0.021 (1.492)
Train: 184 [ 400/1251 ( 32%)]  Loss:  4.550089 (4.7459)  Time: 6.283s,  162.98/s  (2.091s,  489.72/s)  LR: 1.111e-05  Data: 5.592 (1.498)
Train: 184 [ 450/1251 ( 36%)]  Loss:  4.758187 (4.7472)  Time: 0.584s, 1752.06/s  (2.074s,  493.74/s)  LR: 1.111e-05  Data: 0.021 (1.483)
Train: 184 [ 500/1251 ( 40%)]  Loss:  4.763475 (4.7487)  Time: 5.815s,  176.10/s  (2.067s,  495.47/s)  LR: 1.111e-05  Data: 5.242 (1.477)
Train: 184 [ 550/1251 ( 44%)]  Loss:  4.353929 (4.7158)  Time: 0.584s, 1752.64/s  (2.051s,  499.18/s)  LR: 1.111e-05  Data: 0.020 (1.462)
Train: 184 [ 600/1251 ( 48%)]  Loss:  4.519130 (4.7006)  Time: 7.369s,  138.96/s  (2.138s,  478.97/s)  LR: 1.111e-05  Data: 6.801 (1.549)
Train: 184 [ 650/1251 ( 52%)]  Loss:  3.693544 (4.6287)  Time: 0.582s, 1759.87/s  (2.134s,  479.90/s)  LR: 1.111e-05  Data: 0.018 (1.545)
Train: 184 [ 700/1251 ( 56%)]  Loss:  4.830153 (4.6421)  Time: 6.538s,  156.63/s  (2.144s,  477.56/s)  LR: 1.111e-05  Data: 5.953 (1.556)
Train: 184 [ 750/1251 ( 60%)]  Loss:  4.290899 (4.6202)  Time: 0.584s, 1753.82/s  (2.136s,  479.42/s)  LR: 1.111e-05  Data: 0.021 (1.548)
Train: 184 [ 800/1251 ( 64%)]  Loss:  4.723127 (4.6262)  Time: 6.911s,  148.17/s  (2.138s,  478.98/s)  LR: 1.111e-05  Data: 6.348 (1.549)
Train: 184 [ 850/1251 ( 68%)]  Loss:  5.018555 (4.6480)  Time: 0.590s, 1736.83/s  (2.132s,  480.21/s)  LR: 1.111e-05  Data: 0.019 (1.544)
Train: 184 [ 900/1251 ( 72%)]  Loss:  4.761345 (4.6540)  Time: 6.591s,  155.37/s  (2.130s,  480.85/s)  LR: 1.111e-05  Data: 6.028 (1.541)
Train: 184 [ 950/1251 ( 76%)]  Loss:  4.416959 (4.6421)  Time: 0.588s, 1740.82/s  (2.122s,  482.65/s)  LR: 1.111e-05  Data: 0.020 (1.533)
Train: 184 [1000/1251 ( 80%)]  Loss:  4.155006 (4.6189)  Time: 6.066s,  168.80/s  (2.116s,  483.88/s)  LR: 1.111e-05  Data: 5.419 (1.528)
Train: 184 [1050/1251 ( 84%)]  Loss:  4.430933 (4.6104)  Time: 0.588s, 1740.67/s  (2.128s,  481.27/s)  LR: 1.111e-05  Data: 0.019 (1.540)
Train: 184 [1100/1251 ( 88%)]  Loss:  4.908113 (4.6233)  Time: 7.873s,  130.07/s  (2.126s,  481.63/s)  LR: 1.111e-05  Data: 7.309 (1.538)
Train: 184 [1150/1251 ( 92%)]  Loss:  4.795726 (4.6305)  Time: 0.581s, 1761.20/s  (2.130s,  480.68/s)  LR: 1.111e-05  Data: 0.019 (1.543)
Train: 184 [1200/1251 ( 96%)]  Loss:  4.655863 (4.6315)  Time: 7.126s,  143.69/s  (2.130s,  480.84/s)  LR: 1.111e-05  Data: 6.545 (1.542)
Train: 184 [1250/1251 (100%)]  Loss:  4.903640 (4.6420)  Time: 0.563s, 1818.73/s  (2.128s,  481.30/s)  LR: 1.111e-05  Data: 0.000 (1.540)
Test: [   0/48]  Time: 12.984 (12.984)  Loss:  0.9953 (0.9953)  Acc@1: 79.1016 (79.1016)  Acc@5: 92.9688 (92.9688)
Test: [  48/48]  Time: 0.149 (3.045)  Loss:  1.0473 (1.8637)  Acc@1: 77.9481 (58.6940)  Acc@5: 91.8632 (82.1280)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-182.pth.tar', 58.7319999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-183.pth.tar', 58.7060000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-184.pth.tar', 58.69399998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-181.pth.tar', 58.5120001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-175.pth.tar', 58.31599998535156)

Train: 185 [   0/1251 (  0%)]  Loss:  4.883394 (4.8834)  Time: 9.748s,  105.05/s  (9.748s,  105.05/s)  LR: 1.062e-05  Data: 9.168 (9.168)
Train: 185 [  50/1251 (  4%)]  Loss:  4.750772 (4.8171)  Time: 0.584s, 1754.05/s  (2.158s,  474.41/s)  LR: 1.062e-05  Data: 0.020 (1.572)
Train: 185 [ 100/1251 (  8%)]  Loss:  4.328014 (4.6541)  Time: 0.582s, 1758.42/s  (2.117s,  483.78/s)  LR: 1.062e-05  Data: 0.018 (1.535)
Train: 185 [ 150/1251 ( 12%)]  Loss:  4.475641 (4.6095)  Time: 0.584s, 1752.22/s  (2.191s,  467.27/s)  LR: 1.062e-05  Data: 0.022 (1.605)
Train: 185 [ 200/1251 ( 16%)]  Loss:  4.003575 (4.4883)  Time: 1.250s,  818.96/s  (2.149s,  476.55/s)  LR: 1.062e-05  Data: 0.666 (1.562)
Train: 185 [ 250/1251 ( 20%)]  Loss:  4.544376 (4.4976)  Time: 0.583s, 1757.62/s  (2.275s,  450.06/s)  LR: 1.062e-05  Data: 0.021 (1.687)
Train: 185 [ 300/1251 ( 24%)]  Loss:  3.858770 (4.4064)  Time: 0.584s, 1752.71/s  (2.331s,  439.28/s)  LR: 1.062e-05  Data: 0.020 (1.739)
Train: 185 [ 350/1251 ( 28%)]  Loss:  4.852846 (4.4622)  Time: 0.584s, 1754.65/s  (2.279s,  449.29/s)  LR: 1.062e-05  Data: 0.021 (1.689)
Train: 185 [ 400/1251 ( 32%)]  Loss:  4.911294 (4.5121)  Time: 0.584s, 1753.88/s  (2.262s,  452.68/s)  LR: 1.062e-05  Data: 0.019 (1.672)
Train: 185 [ 450/1251 ( 36%)]  Loss:  4.242775 (4.4851)  Time: 0.586s, 1746.72/s  (2.230s,  459.14/s)  LR: 1.062e-05  Data: 0.022 (1.637)
Train: 185 [ 500/1251 ( 40%)]  Loss:  4.030987 (4.4439)  Time: 0.589s, 1737.62/s  (2.218s,  461.72/s)  LR: 1.062e-05  Data: 0.023 (1.624)
Train: 185 [ 550/1251 ( 44%)]  Loss:  4.762258 (4.4704)  Time: 0.583s, 1755.36/s  (2.237s,  457.75/s)  LR: 1.062e-05  Data: 0.021 (1.644)
Train: 185 [ 600/1251 ( 48%)]  Loss:  4.885002 (4.5023)  Time: 0.585s, 1750.38/s  (2.227s,  459.78/s)  LR: 1.062e-05  Data: 0.022 (1.635)
Train: 185 [ 650/1251 ( 52%)]  Loss:  4.670700 (4.5143)  Time: 0.584s, 1752.59/s  (2.237s,  457.75/s)  LR: 1.062e-05  Data: 0.020 (1.645)
Train: 185 [ 700/1251 ( 56%)]  Loss:  5.109955 (4.5540)  Time: 0.745s, 1374.79/s  (2.238s,  457.58/s)  LR: 1.062e-05  Data: 0.144 (1.644)
Train: 185 [ 750/1251 ( 60%)]  Loss:  4.264119 (4.5359)  Time: 0.585s, 1750.79/s  (2.229s,  459.42/s)  LR: 1.062e-05  Data: 0.023 (1.636)
Train: 185 [ 800/1251 ( 64%)]  Loss:  4.777975 (4.5501)  Time: 0.584s, 1752.47/s  (2.222s,  460.86/s)  LR: 1.062e-05  Data: 0.020 (1.630)
Train: 185 [ 850/1251 ( 68%)]  Loss:  4.526494 (4.5488)  Time: 0.584s, 1754.02/s  (2.208s,  463.86/s)  LR: 1.062e-05  Data: 0.020 (1.616)
Train: 185 [ 900/1251 ( 72%)]  Loss:  4.191714 (4.5300)  Time: 0.583s, 1757.78/s  (2.201s,  465.16/s)  LR: 1.062e-05  Data: 0.018 (1.610)
Train: 185 [ 950/1251 ( 76%)]  Loss:  4.576494 (4.5324)  Time: 0.637s, 1608.37/s  (2.210s,  463.30/s)  LR: 1.062e-05  Data: 0.018 (1.619)
Train: 185 [1000/1251 ( 80%)]  Loss:  4.920398 (4.5508)  Time: 0.586s, 1748.93/s  (2.202s,  465.07/s)  LR: 1.062e-05  Data: 0.019 (1.611)
Train: 185 [1050/1251 ( 84%)]  Loss:  4.156306 (4.5329)  Time: 0.587s, 1743.91/s  (2.202s,  465.12/s)  LR: 1.062e-05  Data: 0.022 (1.611)
Train: 185 [1100/1251 ( 88%)]  Loss:  4.683281 (4.5394)  Time: 0.585s, 1749.32/s  (2.197s,  466.08/s)  LR: 1.062e-05  Data: 0.022 (1.607)
Train: 185 [1150/1251 ( 92%)]  Loss:  3.826452 (4.5097)  Time: 0.587s, 1744.08/s  (2.192s,  467.12/s)  LR: 1.062e-05  Data: 0.024 (1.602)
Train: 185 [1200/1251 ( 96%)]  Loss:  4.460977 (4.5078)  Time: 0.585s, 1749.74/s  (2.198s,  465.89/s)  LR: 1.062e-05  Data: 0.020 (1.608)
Train: 185 [1250/1251 (100%)]  Loss:  4.821979 (4.5199)  Time: 0.565s, 1812.86/s  (2.216s,  462.07/s)  LR: 1.062e-05  Data: 0.000 (1.626)
Test: [   0/48]  Time: 13.261 (13.261)  Loss:  1.0019 (1.0019)  Acc@1: 78.3203 (78.3203)  Acc@5: 93.3594 (93.3594)
Test: [  48/48]  Time: 0.149 (3.243)  Loss:  1.0452 (1.8661)  Acc@1: 78.0660 (58.8420)  Acc@5: 91.9811 (82.1920)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-185.pth.tar', 58.8420000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-182.pth.tar', 58.7319999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-183.pth.tar', 58.7060000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-184.pth.tar', 58.69399998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-181.pth.tar', 58.5120001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-176.pth.tar', 58.33600001220703)

Train: 186 [   0/1251 (  0%)]  Loss:  4.139226 (4.1392)  Time: 16.379s,   62.52/s  (16.379s,   62.52/s)  LR: 1.028e-05  Data: 15.200 (15.200)
Train: 186 [  50/1251 (  4%)]  Loss:  4.696158 (4.4177)  Time: 0.587s, 1743.93/s  (2.469s,  414.66/s)  LR: 1.028e-05  Data: 0.019 (1.865)
Train: 186 [ 100/1251 (  8%)]  Loss:  4.546267 (4.4606)  Time: 0.591s, 1733.69/s  (2.409s,  425.14/s)  LR: 1.028e-05  Data: 0.021 (1.810)
Train: 186 [ 150/1251 ( 12%)]  Loss:  4.931604 (4.5783)  Time: 0.587s, 1743.84/s  (2.247s,  455.75/s)  LR: 1.028e-05  Data: 0.018 (1.653)
Train: 186 [ 200/1251 ( 16%)]  Loss:  5.037045 (4.6701)  Time: 0.586s, 1746.63/s  (2.169s,  472.14/s)  LR: 1.028e-05  Data: 0.020 (1.572)
Train: 186 [ 250/1251 ( 20%)]  Loss:  4.376205 (4.6211)  Time: 0.582s, 1758.20/s  (2.125s,  481.84/s)  LR: 1.028e-05  Data: 0.018 (1.528)
Train: 186 [ 300/1251 ( 24%)]  Loss:  4.345645 (4.5817)  Time: 0.588s, 1740.55/s  (2.112s,  484.89/s)  LR: 1.028e-05  Data: 0.023 (1.513)
Train: 186 [ 350/1251 ( 28%)]  Loss:  4.870106 (4.6178)  Time: 1.048s,  976.68/s  (2.087s,  490.62/s)  LR: 1.028e-05  Data: 0.485 (1.489)
Train: 186 [ 400/1251 ( 32%)]  Loss:  4.606072 (4.6165)  Time: 0.591s, 1731.52/s  (2.073s,  494.04/s)  LR: 1.028e-05  Data: 0.019 (1.473)
Train: 186 [ 450/1251 ( 36%)]  Loss:  3.938375 (4.5487)  Time: 0.588s, 1740.84/s  (2.100s,  487.72/s)  LR: 1.028e-05  Data: 0.022 (1.501)
Train: 186 [ 500/1251 ( 40%)]  Loss:  4.431509 (4.5380)  Time: 0.586s, 1747.73/s  (2.101s,  487.42/s)  LR: 1.028e-05  Data: 0.020 (1.502)
Train: 186 [ 550/1251 ( 44%)]  Loss:  4.570283 (4.5407)  Time: 0.588s, 1740.05/s  (2.075s,  493.45/s)  LR: 1.028e-05  Data: 0.019 (1.477)
Train: 186 [ 600/1251 ( 48%)]  Loss:  4.832985 (4.5632)  Time: 1.004s, 1020.16/s  (2.075s,  493.55/s)  LR: 1.028e-05  Data: 0.321 (1.477)
Train: 186 [ 650/1251 ( 52%)]  Loss:  4.246985 (4.5406)  Time: 0.586s, 1748.61/s  (2.088s,  490.45/s)  LR: 1.028e-05  Data: 0.019 (1.489)
Train: 186 [ 700/1251 ( 56%)]  Loss:  4.628835 (4.5465)  Time: 0.584s, 1752.33/s  (2.091s,  489.63/s)  LR: 1.028e-05  Data: 0.021 (1.493)
Train: 186 [ 750/1251 ( 60%)]  Loss:  4.617357 (4.5509)  Time: 1.242s,  824.21/s  (2.081s,  492.17/s)  LR: 1.028e-05  Data: 0.657 (1.483)
Train: 186 [ 800/1251 ( 64%)]  Loss:  5.112400 (4.5839)  Time: 0.584s, 1753.63/s  (2.084s,  491.34/s)  LR: 1.028e-05  Data: 0.020 (1.486)
Train: 186 [ 850/1251 ( 68%)]  Loss:  4.621156 (4.5860)  Time: 1.800s,  568.88/s  (2.079s,  492.65/s)  LR: 1.028e-05  Data: 1.123 (1.481)
Train: 186 [ 900/1251 ( 72%)]  Loss:  3.953604 (4.5527)  Time: 0.587s, 1745.81/s  (2.170s,  471.95/s)  LR: 1.028e-05  Data: 0.021 (1.571)
Train: 186 [ 950/1251 ( 76%)]  Loss:  4.319794 (4.5411)  Time: 0.584s, 1752.54/s  (2.165s,  473.02/s)  LR: 1.028e-05  Data: 0.021 (1.567)
Train: 186 [1000/1251 ( 80%)]  Loss:  4.749740 (4.5510)  Time: 0.582s, 1758.42/s  (2.160s,  474.08/s)  LR: 1.028e-05  Data: 0.019 (1.562)
Train: 186 [1050/1251 ( 84%)]  Loss:  4.189987 (4.5346)  Time: 0.584s, 1752.08/s  (2.152s,  475.94/s)  LR: 1.028e-05  Data: 0.020 (1.555)
Train: 186 [1100/1251 ( 88%)]  Loss:  4.535171 (4.5346)  Time: 0.583s, 1756.39/s  (2.152s,  475.84/s)  LR: 1.028e-05  Data: 0.019 (1.556)
Train: 186 [1150/1251 ( 92%)]  Loss:  4.301606 (4.5249)  Time: 0.585s, 1751.57/s  (2.142s,  478.06/s)  LR: 1.028e-05  Data: 0.021 (1.547)
Train: 186 [1200/1251 ( 96%)]  Loss:  4.783700 (4.5353)  Time: 0.584s, 1752.93/s  (2.138s,  478.90/s)  LR: 1.028e-05  Data: 0.021 (1.543)
Train: 186 [1250/1251 (100%)]  Loss:  4.844671 (4.5472)  Time: 0.563s, 1818.13/s  (2.133s,  480.15/s)  LR: 1.028e-05  Data: 0.000 (1.538)
Test: [   0/48]  Time: 16.668 (16.668)  Loss:  1.0031 (1.0031)  Acc@1: 78.6133 (78.6133)  Acc@5: 93.3594 (93.3594)
Test: [  48/48]  Time: 0.149 (3.303)  Loss:  1.0431 (1.8620)  Acc@1: 78.4198 (58.7940)  Acc@5: 91.7453 (82.1180)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-185.pth.tar', 58.8420000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-186.pth.tar', 58.79400006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-182.pth.tar', 58.7319999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-183.pth.tar', 58.7060000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-184.pth.tar', 58.69399998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-181.pth.tar', 58.5120001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-177.pth.tar', 58.40999993164063)

Train: 187 [   0/1251 (  0%)]  Loss:  4.838742 (4.8387)  Time: 10.011s,  102.29/s  (10.011s,  102.29/s)  LR: 1.007e-05  Data: 8.898 (8.898)
Train: 187 [  50/1251 (  4%)]  Loss:  4.631597 (4.7352)  Time: 0.585s, 1750.64/s  (2.162s,  473.58/s)  LR: 1.007e-05  Data: 0.022 (1.572)
Train: 187 [ 100/1251 (  8%)]  Loss:  4.582105 (4.6841)  Time: 0.582s, 1758.41/s  (2.144s,  477.56/s)  LR: 1.007e-05  Data: 0.019 (1.559)
Train: 187 [ 150/1251 ( 12%)]  Loss:  4.724548 (4.6942)  Time: 0.584s, 1754.58/s  (2.068s,  495.13/s)  LR: 1.007e-05  Data: 0.021 (1.482)
Train: 187 [ 200/1251 ( 16%)]  Loss:  4.229638 (4.6013)  Time: 0.585s, 1751.83/s  (2.066s,  495.54/s)  LR: 1.007e-05  Data: 0.018 (1.479)
Train: 187 [ 250/1251 ( 20%)]  Loss:  4.559329 (4.5943)  Time: 0.583s, 1756.21/s  (2.057s,  497.81/s)  LR: 1.007e-05  Data: 0.020 (1.469)
Train: 187 [ 300/1251 ( 24%)]  Loss:  4.602346 (4.5955)  Time: 0.585s, 1750.29/s  (2.069s,  494.83/s)  LR: 1.007e-05  Data: 0.020 (1.483)
Train: 187 [ 350/1251 ( 28%)]  Loss:  4.462718 (4.5789)  Time: 0.586s, 1747.93/s  (2.051s,  499.31/s)  LR: 1.007e-05  Data: 0.023 (1.464)
Train: 187 [ 400/1251 ( 32%)]  Loss:  4.720101 (4.5946)  Time: 0.584s, 1752.30/s  (2.114s,  484.47/s)  LR: 1.007e-05  Data: 0.021 (1.528)
Train: 187 [ 450/1251 ( 36%)]  Loss:  4.804689 (4.6156)  Time: 0.585s, 1751.55/s  (2.097s,  488.21/s)  LR: 1.007e-05  Data: 0.021 (1.511)
Train: 187 [ 500/1251 ( 40%)]  Loss:  4.222005 (4.5798)  Time: 0.585s, 1751.65/s  (2.089s,  490.11/s)  LR: 1.007e-05  Data: 0.020 (1.504)
Train: 187 [ 550/1251 ( 44%)]  Loss:  4.617565 (4.5829)  Time: 0.590s, 1736.12/s  (2.153s,  475.59/s)  LR: 1.007e-05  Data: 0.025 (1.568)
Train: 187 [ 600/1251 ( 48%)]  Loss:  4.917122 (4.6087)  Time: 0.587s, 1744.01/s  (2.199s,  465.74/s)  LR: 1.007e-05  Data: 0.022 (1.612)
Train: 187 [ 650/1251 ( 52%)]  Loss:  4.081134 (4.5710)  Time: 0.590s, 1736.76/s  (2.194s,  466.73/s)  LR: 1.007e-05  Data: 0.016 (1.607)
Train: 187 [ 700/1251 ( 56%)]  Loss:  4.377630 (4.5581)  Time: 0.582s, 1760.51/s  (2.192s,  467.16/s)  LR: 1.007e-05  Data: 0.019 (1.605)
Train: 187 [ 750/1251 ( 60%)]  Loss:  4.546275 (4.5573)  Time: 0.588s, 1741.40/s  (2.186s,  468.47/s)  LR: 1.007e-05  Data: 0.019 (1.599)
Train: 187 [ 800/1251 ( 64%)]  Loss:  4.813650 (4.5724)  Time: 0.586s, 1748.46/s  (2.211s,  463.15/s)  LR: 1.007e-05  Data: 0.022 (1.624)
Train: 187 [ 850/1251 ( 68%)]  Loss:  3.814771 (4.5303)  Time: 0.587s, 1744.26/s  (2.199s,  465.73/s)  LR: 1.007e-05  Data: 0.019 (1.612)
Train: 187 [ 900/1251 ( 72%)]  Loss:  3.738348 (4.4886)  Time: 0.584s, 1753.55/s  (2.193s,  467.02/s)  LR: 1.007e-05  Data: 0.019 (1.606)
Train: 187 [ 950/1251 ( 76%)]  Loss:  4.312926 (4.4799)  Time: 0.587s, 1745.38/s  (2.192s,  467.16/s)  LR: 1.007e-05  Data: 0.021 (1.606)
Train: 187 [1000/1251 ( 80%)]  Loss:  4.722166 (4.4914)  Time: 0.583s, 1755.18/s  (2.189s,  467.71/s)  LR: 1.007e-05  Data: 0.018 (1.603)
Train: 187 [1050/1251 ( 84%)]  Loss:  4.795783 (4.5052)  Time: 0.584s, 1753.42/s  (2.178s,  470.25/s)  LR: 1.007e-05  Data: 0.021 (1.592)
Train: 187 [1100/1251 ( 88%)]  Loss:  4.556209 (4.5075)  Time: 0.584s, 1753.00/s  (2.174s,  471.09/s)  LR: 1.007e-05  Data: 0.020 (1.588)
Train: 187 [1150/1251 ( 92%)]  Loss:  4.647161 (4.5133)  Time: 0.585s, 1750.58/s  (2.168s,  472.37/s)  LR: 1.007e-05  Data: 0.019 (1.582)
Train: 187 [1200/1251 ( 96%)]  Loss:  4.748678 (4.5227)  Time: 0.589s, 1738.00/s  (2.184s,  468.86/s)  LR: 1.007e-05  Data: 0.026 (1.598)
Train: 187 [1250/1251 (100%)]  Loss:  4.708371 (4.5298)  Time: 0.566s, 1809.10/s  (2.179s,  469.98/s)  LR: 1.007e-05  Data: 0.000 (1.593)
Test: [   0/48]  Time: 12.973 (12.973)  Loss:  1.0048 (1.0048)  Acc@1: 78.9062 (78.9062)  Acc@5: 93.6523 (93.6523)
Test: [  48/48]  Time: 0.149 (3.190)  Loss:  1.0434 (1.8642)  Acc@1: 78.5377 (58.9480)  Acc@5: 91.6274 (82.2020)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-187.pth.tar', 58.947999985351565)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-185.pth.tar', 58.8420000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-186.pth.tar', 58.79400006347656)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-182.pth.tar', 58.7319999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-183.pth.tar', 58.7060000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-184.pth.tar', 58.69399998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-180.pth.tar', 58.578000012207035)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-179.pth.tar', 58.5599999609375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-181.pth.tar', 58.5120001171875)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-178.pth.tar', 58.4680001171875)

*** Best metric: 58.947999985351565 (epoch 187)

wandb: Waiting for W&B process to finish, PID 17130
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210604_151251-PreTraining_vit_deit_tiny_patch16_224_1k/logs/debug.log
wandb: Find internal logs for this run at: /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210604_151251-PreTraining_vit_deit_tiny_patch16_224_1k/logs/debug-internal.log
wandb: Run summary:
wandb:    eval_top5 82.202
wandb:   _timestamp 1622851540
wandb:   train_loss 4.52983
wandb:        _step 187
wandb:        epoch 187
wandb:     _runtime 590495
wandb:    eval_loss 1.86419
wandb:    eval_top1 58.948
wandb: Run history:
wandb:        epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   train_loss ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÑ
wandb:    eval_loss ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:    eval_top1 ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:    eval_top5 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà
wandb:     _runtime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   _timestamp ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:        _step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced PreTraining_vit_deit_tiny_patch16_224_1k: https://wandb.ai/gyama_x/pytorch-image-models/runs/PreTraining_vit_deit_tiny_patch16_224_1k
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
--End--
Sat Jun 5 09:05:50 JST 2021
