--Start--
Tue May 25 14:02:35 JST 2021
Added key: store_based_barrier_key:1 to store for rank: 0
Added key: store_based_barrier_key:1 to store for rank: 1
Added key: store_based_barrier_key:1 to store for rank: 2
Added key: store_based_barrier_key:1 to store for rank: 3
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
wandb: Currently logged in as: gyama_x (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.10.30 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
wandb: Tracking run with wandb version 0.10.27
wandb: Resuming run PreTraining_vit_deit_tiny_patch16_224_1k
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gyama_x/pytorch-image-models
wandb: üöÄ View run at https://wandb.ai/gyama_x/pytorch-image-models/runs/PreTraining_vit_deit_tiny_patch16_224_1k
wandb: Run data is saved locally in /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210525_140351-PreTraining_vit_deit_tiny_patch16_224_1k
wandb: Run `wandb offline` to turn off syncing.

Loaded state_dict from checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar'
Model vit_deit_tiny_patch16_224 created, param count:5717416
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.9
AMP not enabled. Training in float32.
Restoring model state from checkpoint...
Restoring optimizer state from checkpoint...
Loaded checkpoint '/gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/train_result/PreTraining_vit_deit_tiny_patch16_224_1k/last.pth.tar' (epoch 43)
Using native Torch DistributedDataParallel.
Scheduled epochs: 66
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Train: 44 [   0/1251 (  0%)]  Loss:  5.062360 (5.0624)  Time: 15.719s,   65.14/s  (15.719s,   65.14/s)  LR: 2.575e-04  Data: 14.392 (14.392)
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Train: 44 [  50/1251 (  4%)]  Loss:  5.156003 (5.1092)  Time: 0.585s, 1750.05/s  (2.666s,  384.03/s)  LR: 2.575e-04  Data: 0.018 (2.065)
Train: 44 [ 100/1251 (  8%)]  Loss:  5.036415 (5.0849)  Time: 0.586s, 1748.69/s  (2.555s,  400.80/s)  LR: 2.575e-04  Data: 0.018 (1.957)
Train: 44 [ 150/1251 ( 12%)]  Loss:  4.781427 (5.0091)  Time: 0.587s, 1745.90/s  (2.482s,  412.62/s)  LR: 2.575e-04  Data: 0.018 (1.890)
Train: 44 [ 200/1251 ( 16%)]  Loss:  4.773507 (4.9619)  Time: 0.584s, 1752.39/s  (2.466s,  415.17/s)  LR: 2.575e-04  Data: 0.018 (1.876)
Train: 44 [ 250/1251 ( 20%)]  Loss:  4.593274 (4.9005)  Time: 0.584s, 1752.06/s  (2.461s,  416.14/s)  LR: 2.575e-04  Data: 0.017 (1.866)
Train: 44 [ 300/1251 ( 24%)]  Loss:  5.312532 (4.9594)  Time: 2.053s,  498.69/s  (2.467s,  415.04/s)  LR: 2.575e-04  Data: 1.467 (1.866)
Train: 44 [ 350/1251 ( 28%)]  Loss:  4.691674 (4.9259)  Time: 0.588s, 1742.72/s  (2.458s,  416.67/s)  LR: 2.575e-04  Data: 0.018 (1.855)
Train: 44 [ 400/1251 ( 32%)]  Loss:  5.246621 (4.9615)  Time: 1.423s,  719.59/s  (2.456s,  416.94/s)  LR: 2.575e-04  Data: 0.861 (1.851)
Train: 44 [ 450/1251 ( 36%)]  Loss:  4.700695 (4.9355)  Time: 0.581s, 1762.07/s  (2.461s,  416.07/s)  LR: 2.575e-04  Data: 0.018 (1.858)
Train: 44 [ 500/1251 ( 40%)]  Loss:  4.861745 (4.9288)  Time: 0.707s, 1448.34/s  (2.443s,  419.13/s)  LR: 2.575e-04  Data: 0.121 (1.842)
Train: 44 [ 550/1251 ( 44%)]  Loss:  4.890690 (4.9256)  Time: 0.585s, 1750.70/s  (2.435s,  420.55/s)  LR: 2.575e-04  Data: 0.019 (1.833)
Train: 44 [ 600/1251 ( 48%)]  Loss:  5.626120 (4.9795)  Time: 0.583s, 1756.90/s  (2.423s,  422.70/s)  LR: 2.575e-04  Data: 0.019 (1.821)
Train: 44 [ 650/1251 ( 52%)]  Loss:  4.912246 (4.9747)  Time: 0.586s, 1747.07/s  (2.441s,  419.51/s)  LR: 2.575e-04  Data: 0.021 (1.839)
Train: 44 [ 700/1251 ( 56%)]  Loss:  5.049616 (4.9797)  Time: 0.585s, 1750.65/s  (2.464s,  415.57/s)  LR: 2.575e-04  Data: 0.019 (1.864)
Train: 44 [ 750/1251 ( 60%)]  Loss:  5.477682 (5.0108)  Time: 0.591s, 1734.10/s  (2.480s,  412.87/s)  LR: 2.575e-04  Data: 0.017 (1.879)
Train: 44 [ 800/1251 ( 64%)]  Loss:  4.832680 (5.0003)  Time: 0.584s, 1753.98/s  (2.497s,  410.09/s)  LR: 2.575e-04  Data: 0.019 (1.896)
Train: 44 [ 850/1251 ( 68%)]  Loss:  4.941282 (4.9970)  Time: 0.586s, 1748.64/s  (2.502s,  409.32/s)  LR: 2.575e-04  Data: 0.021 (1.900)
Train: 44 [ 900/1251 ( 72%)]  Loss:  5.176835 (5.0065)  Time: 0.583s, 1757.18/s  (2.505s,  408.74/s)  LR: 2.575e-04  Data: 0.017 (1.903)
Train: 44 [ 950/1251 ( 76%)]  Loss:  4.775415 (4.9949)  Time: 0.585s, 1749.96/s  (2.508s,  408.33/s)  LR: 2.575e-04  Data: 0.019 (1.905)
Train: 44 [1000/1251 ( 80%)]  Loss:  4.441989 (4.9686)  Time: 0.584s, 1752.88/s  (2.529s,  404.92/s)  LR: 2.575e-04  Data: 0.017 (1.924)
Train: 44 [1050/1251 ( 84%)]  Loss:  4.936141 (4.9671)  Time: 0.585s, 1751.71/s  (2.542s,  402.90/s)  LR: 2.575e-04  Data: 0.018 (1.936)
Train: 44 [1100/1251 ( 88%)]  Loss:  4.850382 (4.9621)  Time: 0.584s, 1753.42/s  (2.550s,  401.57/s)  LR: 2.575e-04  Data: 0.018 (1.944)
Train: 44 [1150/1251 ( 92%)]  Loss:  4.469527 (4.9415)  Time: 0.586s, 1746.04/s  (2.552s,  401.28/s)  LR: 2.575e-04  Data: 0.021 (1.946)
Train: 44 [1200/1251 ( 96%)]  Loss:  4.637610 (4.9294)  Time: 0.587s, 1743.80/s  (2.553s,  401.14/s)  LR: 2.575e-04  Data: 0.023 (1.948)
Train: 44 [1250/1251 (100%)]  Loss:  4.928927 (4.9294)  Time: 0.564s, 1814.98/s  (2.552s,  401.19/s)  LR: 2.575e-04  Data: 0.000 (1.948)
Test: [   0/48]  Time: 17.281 (17.281)  Loss:  1.5801 (1.5801)  Acc@1: 67.5781 (67.5781)  Acc@5: 87.2070 (87.2070)
Test: [  48/48]  Time: 0.893 (3.998)  Loss:  1.4767 (2.5169)  Acc@1: 70.6368 (46.7420)  Acc@5: 85.7311 (71.8340)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 45 [   0/1251 (  0%)]  Loss:  4.907287 (4.9073)  Time: 10.579s,   96.80/s  (10.579s,   96.80/s)  LR: 2.374e-04  Data: 8.976 (8.976)
Train: 45 [  50/1251 (  4%)]  Loss:  4.785699 (4.8465)  Time: 0.585s, 1749.36/s  (2.719s,  376.67/s)  LR: 2.374e-04  Data: 0.019 (2.101)
Train: 45 [ 100/1251 (  8%)]  Loss:  5.161829 (4.9516)  Time: 0.587s, 1742.99/s  (2.670s,  383.59/s)  LR: 2.374e-04  Data: 0.019 (2.053)
Train: 45 [ 150/1251 ( 12%)]  Loss:  4.757421 (4.9031)  Time: 0.583s, 1755.81/s  (2.644s,  387.33/s)  LR: 2.374e-04  Data: 0.019 (2.039)
Train: 45 [ 200/1251 ( 16%)]  Loss:  4.785922 (4.8796)  Time: 0.583s, 1755.27/s  (2.658s,  385.25/s)  LR: 2.374e-04  Data: 0.018 (2.058)
Train: 45 [ 250/1251 ( 20%)]  Loss:  4.453467 (4.8086)  Time: 0.585s, 1750.46/s  (2.619s,  390.97/s)  LR: 2.374e-04  Data: 0.019 (2.020)
Train: 45 [ 300/1251 ( 24%)]  Loss:  5.502117 (4.9077)  Time: 0.583s, 1754.93/s  (2.600s,  393.85/s)  LR: 2.374e-04  Data: 0.016 (2.002)
Train: 45 [ 350/1251 ( 28%)]  Loss:  4.663207 (4.8771)  Time: 0.583s, 1756.35/s  (2.621s,  390.68/s)  LR: 2.374e-04  Data: 0.019 (2.025)
Train: 45 [ 400/1251 ( 32%)]  Loss:  4.861551 (4.8754)  Time: 0.583s, 1754.96/s  (2.648s,  386.65/s)  LR: 2.374e-04  Data: 0.017 (2.052)
Train: 45 [ 450/1251 ( 36%)]  Loss:  5.330579 (4.9209)  Time: 0.583s, 1756.36/s  (2.641s,  387.73/s)  LR: 2.374e-04  Data: 0.019 (2.045)
Train: 45 [ 500/1251 ( 40%)]  Loss:  4.555853 (4.8877)  Time: 0.583s, 1757.46/s  (2.647s,  386.81/s)  LR: 2.374e-04  Data: 0.018 (2.052)
Train: 45 [ 550/1251 ( 44%)]  Loss:  5.171235 (4.9113)  Time: 0.582s, 1758.94/s  (2.637s,  388.34/s)  LR: 2.374e-04  Data: 0.018 (2.042)
Train: 45 [ 600/1251 ( 48%)]  Loss:  5.179822 (4.9320)  Time: 0.584s, 1751.95/s  (2.643s,  387.40/s)  LR: 2.374e-04  Data: 0.019 (2.049)
Train: 45 [ 650/1251 ( 52%)]  Loss:  5.242611 (4.9542)  Time: 0.583s, 1757.55/s  (2.647s,  386.81/s)  LR: 2.374e-04  Data: 0.019 (2.054)
Train: 45 [ 700/1251 ( 56%)]  Loss:  4.843215 (4.9468)  Time: 2.592s,  394.99/s  (2.667s,  384.02/s)  LR: 2.374e-04  Data: 2.010 (2.073)
Train: 45 [ 750/1251 ( 60%)]  Loss:  5.244059 (4.9654)  Time: 0.585s, 1750.66/s  (2.662s,  384.75/s)  LR: 2.374e-04  Data: 0.022 (2.066)
Train: 45 [ 800/1251 ( 64%)]  Loss:  5.533178 (4.9988)  Time: 4.153s,  246.57/s  (2.663s,  384.56/s)  LR: 2.374e-04  Data: 3.584 (2.065)
Train: 45 [ 850/1251 ( 68%)]  Loss:  4.868904 (4.9916)  Time: 0.583s, 1755.96/s  (2.659s,  385.06/s)  LR: 2.374e-04  Data: 0.018 (2.059)
Train: 45 [ 900/1251 ( 72%)]  Loss:  5.011888 (4.9926)  Time: 10.271s,   99.70/s  (2.673s,  383.02/s)  LR: 2.374e-04  Data: 9.489 (2.074)
Train: 45 [ 950/1251 ( 76%)]  Loss:  4.893653 (4.9877)  Time: 0.588s, 1741.44/s  (2.681s,  382.00/s)  LR: 2.374e-04  Data: 0.016 (2.079)
Train: 45 [1000/1251 ( 80%)]  Loss:  5.020877 (4.9893)  Time: 2.116s,  484.02/s  (2.712s,  377.55/s)  LR: 2.374e-04  Data: 1.424 (2.109)
Train: 45 [1050/1251 ( 84%)]  Loss:  5.262827 (5.0017)  Time: 0.588s, 1742.59/s  (2.740s,  373.72/s)  LR: 2.374e-04  Data: 0.021 (2.135)
Train: 45 [1100/1251 ( 88%)]  Loss:  5.327787 (5.0159)  Time: 1.862s,  549.82/s  (2.761s,  370.89/s)  LR: 2.374e-04  Data: 0.549 (2.155)
Train: 45 [1150/1251 ( 92%)]  Loss:  5.457394 (5.0343)  Time: 0.725s, 1412.94/s  (2.778s,  368.64/s)  LR: 2.374e-04  Data: 0.138 (2.172)
Train: 45 [1200/1251 ( 96%)]  Loss:  5.131446 (5.0382)  Time: 4.014s,  255.08/s  (2.782s,  368.06/s)  LR: 2.374e-04  Data: 3.452 (2.175)
Train: 45 [1250/1251 (100%)]  Loss:  5.063688 (5.0391)  Time: 0.567s, 1807.59/s  (2.790s,  367.01/s)  LR: 2.374e-04  Data: 0.000 (2.182)
Test: [   0/48]  Time: 27.278 (27.278)  Loss:  1.5219 (1.5219)  Acc@1: 69.3359 (69.3359)  Acc@5: 88.1836 (88.1836)
Test: [  48/48]  Time: 0.148 (4.718)  Loss:  1.4849 (2.4905)  Acc@1: 70.4009 (47.2860)  Acc@5: 85.2594 (72.2180)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 46 [   0/1251 (  0%)]  Loss:  5.092406 (5.0924)  Time: 13.658s,   74.97/s  (13.658s,   74.97/s)  LR: 2.179e-04  Data: 12.941 (12.941)
Train: 46 [  50/1251 (  4%)]  Loss:  4.623028 (4.8577)  Time: 0.585s, 1751.36/s  (2.806s,  364.97/s)  LR: 2.179e-04  Data: 0.018 (2.222)
Train: 46 [ 100/1251 (  8%)]  Loss:  4.773140 (4.8295)  Time: 0.586s, 1748.86/s  (2.712s,  377.63/s)  LR: 2.179e-04  Data: 0.023 (2.124)
Train: 46 [ 150/1251 ( 12%)]  Loss:  5.279785 (4.9421)  Time: 0.584s, 1752.01/s  (2.639s,  387.96/s)  LR: 2.179e-04  Data: 0.019 (2.047)
Train: 46 [ 200/1251 ( 16%)]  Loss:  5.252491 (5.0042)  Time: 0.586s, 1747.73/s  (2.623s,  390.43/s)  LR: 2.179e-04  Data: 0.024 (2.030)
Train: 46 [ 250/1251 ( 20%)]  Loss:  5.321568 (5.0571)  Time: 0.585s, 1750.94/s  (2.576s,  397.56/s)  LR: 2.179e-04  Data: 0.019 (1.986)
Train: 46 [ 300/1251 ( 24%)]  Loss:  5.147095 (5.0699)  Time: 0.588s, 1742.82/s  (2.642s,  387.65/s)  LR: 2.179e-04  Data: 0.020 (2.049)
Train: 46 [ 350/1251 ( 28%)]  Loss:  5.064907 (5.0693)  Time: 0.585s, 1751.75/s  (2.627s,  389.77/s)  LR: 2.179e-04  Data: 0.020 (2.036)
Train: 46 [ 400/1251 ( 32%)]  Loss:  4.984016 (5.0598)  Time: 1.506s,  680.13/s  (2.636s,  388.52/s)  LR: 2.179e-04  Data: 0.922 (2.041)
Train: 46 [ 450/1251 ( 36%)]  Loss:  5.121010 (5.0659)  Time: 0.585s, 1751.83/s  (2.623s,  390.41/s)  LR: 2.179e-04  Data: 0.019 (2.030)
Train: 46 [ 500/1251 ( 40%)]  Loss:  4.788913 (5.0408)  Time: 0.586s, 1747.23/s  (2.629s,  389.57/s)  LR: 2.179e-04  Data: 0.019 (2.037)
Train: 46 [ 550/1251 ( 44%)]  Loss:  4.665959 (5.0095)  Time: 0.583s, 1756.62/s  (2.612s,  392.06/s)  LR: 2.179e-04  Data: 0.019 (2.020)
Train: 46 [ 600/1251 ( 48%)]  Loss:  4.769195 (4.9910)  Time: 0.587s, 1744.68/s  (2.613s,  391.93/s)  LR: 2.179e-04  Data: 0.020 (2.021)
Train: 46 [ 650/1251 ( 52%)]  Loss:  4.486353 (4.9550)  Time: 0.584s, 1754.88/s  (2.644s,  387.27/s)  LR: 2.179e-04  Data: 0.018 (2.052)
Train: 46 [ 700/1251 ( 56%)]  Loss:  4.745313 (4.9410)  Time: 0.586s, 1748.56/s  (2.660s,  385.02/s)  LR: 2.179e-04  Data: 0.021 (2.068)
Train: 46 [ 750/1251 ( 60%)]  Loss:  5.315337 (4.9644)  Time: 0.583s, 1755.35/s  (2.655s,  385.65/s)  LR: 2.179e-04  Data: 0.018 (2.062)
Train: 46 [ 800/1251 ( 64%)]  Loss:  4.889386 (4.9600)  Time: 0.586s, 1748.89/s  (2.654s,  385.76/s)  LR: 2.179e-04  Data: 0.021 (2.061)
Train: 46 [ 850/1251 ( 68%)]  Loss:  4.163027 (4.9157)  Time: 0.587s, 1744.20/s  (2.648s,  386.75/s)  LR: 2.179e-04  Data: 0.019 (2.053)
Train: 46 [ 900/1251 ( 72%)]  Loss:  5.175829 (4.9294)  Time: 5.050s,  202.79/s  (2.646s,  386.93/s)  LR: 2.179e-04  Data: 4.395 (2.050)
Train: 46 [ 950/1251 ( 76%)]  Loss:  5.273998 (4.9466)  Time: 0.586s, 1748.89/s  (2.652s,  386.16/s)  LR: 2.179e-04  Data: 0.020 (2.054)
Train: 46 [1000/1251 ( 80%)]  Loss:  4.846793 (4.9419)  Time: 9.493s,  107.87/s  (2.659s,  385.13/s)  LR: 2.179e-04  Data: 8.826 (2.062)
Train: 46 [1050/1251 ( 84%)]  Loss:  4.841178 (4.9373)  Time: 0.584s, 1754.32/s  (2.658s,  385.25/s)  LR: 2.179e-04  Data: 0.021 (2.061)
Train: 46 [1100/1251 ( 88%)]  Loss:  5.059574 (4.9426)  Time: 9.384s,  109.12/s  (2.663s,  384.49/s)  LR: 2.179e-04  Data: 8.452 (2.066)
Train: 46 [1150/1251 ( 92%)]  Loss:  4.663641 (4.9310)  Time: 0.588s, 1741.59/s  (2.657s,  385.39/s)  LR: 2.179e-04  Data: 0.021 (2.060)
Train: 46 [1200/1251 ( 96%)]  Loss:  4.922926 (4.9307)  Time: 8.744s,  117.10/s  (2.654s,  385.78/s)  LR: 2.179e-04  Data: 8.049 (2.057)
Train: 46 [1250/1251 (100%)]  Loss:  4.943427 (4.9312)  Time: 0.565s, 1811.53/s  (2.647s,  386.85/s)  LR: 2.179e-04  Data: 0.000 (2.050)
Test: [   0/48]  Time: 14.934 (14.934)  Loss:  1.4016 (1.4016)  Acc@1: 71.0938 (71.0938)  Acc@5: 89.4531 (89.4531)
Test: [  48/48]  Time: 0.148 (3.960)  Loss:  1.3666 (2.4467)  Acc@1: 70.9906 (47.7520)  Acc@5: 87.7359 (73.0080)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 47 [   0/1251 (  0%)]  Loss:  4.866811 (4.8668)  Time: 14.815s,   69.12/s  (14.815s,   69.12/s)  LR: 1.990e-04  Data: 13.535 (13.535)
Train: 47 [  50/1251 (  4%)]  Loss:  4.661648 (4.7642)  Time: 0.585s, 1750.47/s  (2.809s,  364.56/s)  LR: 1.990e-04  Data: 0.020 (2.201)
Train: 47 [ 100/1251 (  8%)]  Loss:  5.074657 (4.8677)  Time: 2.499s,  409.76/s  (2.730s,  375.14/s)  LR: 1.990e-04  Data: 1.856 (2.117)
Train: 47 [ 150/1251 ( 12%)]  Loss:  5.171688 (4.9437)  Time: 2.417s,  423.60/s  (2.662s,  384.72/s)  LR: 1.990e-04  Data: 1.855 (2.054)
Train: 47 [ 200/1251 ( 16%)]  Loss:  4.750858 (4.9051)  Time: 0.585s, 1751.41/s  (2.636s,  388.52/s)  LR: 1.990e-04  Data: 0.020 (2.032)
Train: 47 [ 250/1251 ( 20%)]  Loss:  5.179369 (4.9508)  Time: 4.839s,  211.62/s  (2.605s,  393.12/s)  LR: 1.990e-04  Data: 4.161 (1.999)
Train: 47 [ 300/1251 ( 24%)]  Loss:  5.133944 (4.9770)  Time: 0.584s, 1753.24/s  (2.563s,  399.60/s)  LR: 1.990e-04  Data: 0.019 (1.957)
Train: 47 [ 350/1251 ( 28%)]  Loss:  5.082838 (4.9902)  Time: 5.604s,  182.72/s  (2.618s,  391.20/s)  LR: 1.990e-04  Data: 5.013 (2.014)
Train: 47 [ 400/1251 ( 32%)]  Loss:  4.984128 (4.9895)  Time: 2.969s,  344.85/s  (2.632s,  389.02/s)  LR: 1.990e-04  Data: 2.379 (2.028)
Train: 47 [ 450/1251 ( 36%)]  Loss:  4.413537 (4.9319)  Time: 6.047s,  169.35/s  (2.630s,  389.29/s)  LR: 1.990e-04  Data: 5.471 (2.027)
Train: 47 [ 500/1251 ( 40%)]  Loss:  5.508297 (4.9843)  Time: 1.270s,  806.47/s  (2.621s,  390.72/s)  LR: 1.990e-04  Data: 0.573 (2.018)
Train: 47 [ 550/1251 ( 44%)]  Loss:  5.103169 (4.9942)  Time: 4.355s,  235.14/s  (2.624s,  390.19/s)  LR: 1.990e-04  Data: 3.793 (2.019)
Train: 47 [ 600/1251 ( 48%)]  Loss:  5.297113 (5.0175)  Time: 9.346s,  109.56/s  (2.636s,  388.43/s)  LR: 1.990e-04  Data: 8.784 (2.031)
Train: 47 [ 650/1251 ( 52%)]  Loss:  5.159430 (5.0277)  Time: 0.585s, 1750.79/s  (2.653s,  385.92/s)  LR: 1.990e-04  Data: 0.017 (2.050)
Train: 47 [ 700/1251 ( 56%)]  Loss:  5.302805 (5.0460)  Time: 7.816s,  131.01/s  (2.673s,  383.07/s)  LR: 1.990e-04  Data: 7.091 (2.068)
Train: 47 [ 750/1251 ( 60%)]  Loss:  5.102579 (5.0496)  Time: 0.592s, 1730.17/s  (2.670s,  383.57/s)  LR: 1.990e-04  Data: 0.023 (2.063)
Train: 47 [ 800/1251 ( 64%)]  Loss:  5.135660 (5.0546)  Time: 7.000s,  146.29/s  (2.670s,  383.51/s)  LR: 1.990e-04  Data: 6.351 (2.064)
Train: 47 [ 850/1251 ( 68%)]  Loss:  4.381746 (5.0172)  Time: 0.583s, 1756.57/s  (2.659s,  385.05/s)  LR: 1.990e-04  Data: 0.018 (2.053)
Train: 47 [ 900/1251 ( 72%)]  Loss:  4.497821 (4.9899)  Time: 7.925s,  129.21/s  (2.659s,  385.15/s)  LR: 1.990e-04  Data: 7.173 (2.053)
Train: 47 [ 950/1251 ( 76%)]  Loss:  4.647120 (4.9728)  Time: 0.586s, 1746.99/s  (2.646s,  386.97/s)  LR: 1.990e-04  Data: 0.020 (2.042)
Train: 47 [1000/1251 ( 80%)]  Loss:  4.671502 (4.9584)  Time: 6.945s,  147.45/s  (2.667s,  383.89/s)  LR: 1.990e-04  Data: 6.269 (2.062)
Train: 47 [1050/1251 ( 84%)]  Loss:  5.210073 (4.9699)  Time: 0.587s, 1743.50/s  (2.671s,  383.44/s)  LR: 1.990e-04  Data: 0.018 (2.064)
Train: 47 [1100/1251 ( 88%)]  Loss:  5.088025 (4.9750)  Time: 8.901s,  115.04/s  (2.677s,  382.56/s)  LR: 1.990e-04  Data: 8.278 (2.071)
Train: 47 [1150/1251 ( 92%)]  Loss:  5.156407 (4.9826)  Time: 1.342s,  762.82/s  (2.671s,  383.32/s)  LR: 1.990e-04  Data: 0.725 (2.067)
Train: 47 [1200/1251 ( 96%)]  Loss:  4.547313 (4.9651)  Time: 8.502s,  120.44/s  (2.675s,  382.83/s)  LR: 1.990e-04  Data: 7.886 (2.071)
Train: 47 [1250/1251 (100%)]  Loss:  4.706069 (4.9552)  Time: 0.565s, 1811.05/s  (2.665s,  384.24/s)  LR: 1.990e-04  Data: 0.000 (2.061)
Test: [   0/48]  Time: 14.742 (14.742)  Loss:  1.4780 (1.4780)  Acc@1: 70.4102 (70.4102)  Acc@5: 87.5977 (87.5977)
Test: [  48/48]  Time: 0.148 (3.844)  Loss:  1.4123 (2.4381)  Acc@1: 71.6981 (48.2220)  Acc@5: 87.1462 (73.2480)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 48 [   0/1251 (  0%)]  Loss:  4.906775 (4.9068)  Time: 15.911s,   64.36/s  (15.911s,   64.36/s)  LR: 1.808e-04  Data: 15.067 (15.067)
Train: 48 [  50/1251 (  4%)]  Loss:  4.492933 (4.6999)  Time: 0.587s, 1744.38/s  (2.824s,  362.60/s)  LR: 1.808e-04  Data: 0.019 (2.215)
Train: 48 [ 100/1251 (  8%)]  Loss:  5.402170 (4.9340)  Time: 4.080s,  250.95/s  (2.811s,  364.35/s)  LR: 1.808e-04  Data: 3.497 (2.186)
Train: 48 [ 150/1251 ( 12%)]  Loss:  4.211571 (4.7534)  Time: 0.585s, 1748.95/s  (2.728s,  375.30/s)  LR: 1.808e-04  Data: 0.019 (2.111)
Train: 48 [ 200/1251 ( 16%)]  Loss:  5.189967 (4.8407)  Time: 5.766s,  177.59/s  (2.697s,  379.71/s)  LR: 1.808e-04  Data: 5.114 (2.082)
Train: 48 [ 250/1251 ( 20%)]  Loss:  5.343980 (4.9246)  Time: 0.584s, 1753.17/s  (2.646s,  387.05/s)  LR: 1.808e-04  Data: 0.021 (2.030)
Train: 48 [ 300/1251 ( 24%)]  Loss:  5.049302 (4.9424)  Time: 7.153s,  143.15/s  (2.629s,  389.48/s)  LR: 1.808e-04  Data: 6.497 (2.017)
Train: 48 [ 350/1251 ( 28%)]  Loss:  4.553076 (4.8937)  Time: 0.589s, 1739.38/s  (2.651s,  386.30/s)  LR: 1.808e-04  Data: 0.022 (2.038)
Train: 48 [ 400/1251 ( 32%)]  Loss:  5.601660 (4.9724)  Time: 7.116s,  143.89/s  (2.671s,  383.34/s)  LR: 1.808e-04  Data: 6.493 (2.062)
Train: 48 [ 450/1251 ( 36%)]  Loss:  4.620091 (4.9372)  Time: 0.586s, 1747.43/s  (2.660s,  384.96/s)  LR: 1.808e-04  Data: 0.022 (2.050)
Train: 48 [ 500/1251 ( 40%)]  Loss:  4.767005 (4.9217)  Time: 9.710s,  105.45/s  (2.665s,  384.22/s)  LR: 1.808e-04  Data: 9.075 (2.057)
Train: 48 [ 550/1251 ( 44%)]  Loss:  4.690788 (4.9024)  Time: 0.585s, 1750.27/s  (2.650s,  386.46/s)  LR: 1.808e-04  Data: 0.018 (2.045)
Train: 48 [ 600/1251 ( 48%)]  Loss:  5.195581 (4.9250)  Time: 6.367s,  160.82/s  (2.660s,  385.03/s)  LR: 1.808e-04  Data: 5.290 (2.052)
Train: 48 [ 650/1251 ( 52%)]  Loss:  4.697028 (4.9087)  Time: 0.584s, 1754.51/s  (2.650s,  386.45/s)  LR: 1.808e-04  Data: 0.019 (2.042)
Train: 48 [ 700/1251 ( 56%)]  Loss:  4.675214 (4.8931)  Time: 4.955s,  206.67/s  (2.683s,  381.70/s)  LR: 1.808e-04  Data: 4.393 (2.075)
Train: 48 [ 750/1251 ( 60%)]  Loss:  5.056239 (4.9033)  Time: 0.587s, 1745.32/s  (2.687s,  381.09/s)  LR: 1.808e-04  Data: 0.018 (2.079)
Train: 48 [ 800/1251 ( 64%)]  Loss:  4.831616 (4.8991)  Time: 3.664s,  279.44/s  (2.693s,  380.30/s)  LR: 1.808e-04  Data: 2.843 (2.084)
Train: 48 [ 850/1251 ( 68%)]  Loss:  4.864310 (4.8972)  Time: 0.583s, 1757.68/s  (2.680s,  382.04/s)  LR: 1.808e-04  Data: 0.017 (2.073)
Train: 48 [ 900/1251 ( 72%)]  Loss:  4.540518 (4.8784)  Time: 1.164s,  879.74/s  (2.678s,  382.38/s)  LR: 1.808e-04  Data: 0.513 (2.071)
Train: 48 [ 950/1251 ( 76%)]  Loss:  5.002079 (4.8846)  Time: 0.584s, 1753.28/s  (2.666s,  384.12/s)  LR: 1.808e-04  Data: 0.017 (2.060)
Train: 48 [1000/1251 ( 80%)]  Loss:  5.114395 (4.8955)  Time: 2.247s,  455.74/s  (2.678s,  382.38/s)  LR: 1.808e-04  Data: 1.659 (2.073)
Train: 48 [1050/1251 ( 84%)]  Loss:  4.280333 (4.8676)  Time: 0.586s, 1747.33/s  (2.678s,  382.34/s)  LR: 1.808e-04  Data: 0.019 (2.073)
Train: 48 [1100/1251 ( 88%)]  Loss:  4.736212 (4.8619)  Time: 0.583s, 1756.46/s  (2.686s,  381.24/s)  LR: 1.808e-04  Data: 0.019 (2.081)
Train: 48 [1150/1251 ( 92%)]  Loss:  5.348670 (4.8821)  Time: 0.586s, 1746.56/s  (2.686s,  381.26/s)  LR: 1.808e-04  Data: 0.021 (2.082)
Train: 48 [1200/1251 ( 96%)]  Loss:  5.495037 (4.9067)  Time: 0.588s, 1740.99/s  (2.687s,  381.05/s)  LR: 1.808e-04  Data: 0.021 (2.084)
Train: 48 [1250/1251 (100%)]  Loss:  5.017238 (4.9109)  Time: 0.565s, 1813.79/s  (2.680s,  382.02/s)  LR: 1.808e-04  Data: 0.000 (2.078)
Test: [   0/48]  Time: 15.808 (15.808)  Loss:  1.4034 (1.4034)  Acc@1: 70.5078 (70.5078)  Acc@5: 88.6719 (88.6719)
Test: [  48/48]  Time: 0.149 (3.595)  Loss:  1.3813 (2.4092)  Acc@1: 71.8160 (48.3840)  Acc@5: 87.1462 (73.5380)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 49 [   0/1251 (  0%)]  Loss:  5.022200 (5.0222)  Time: 11.727s,   87.32/s  (11.727s,   87.32/s)  LR: 1.634e-04  Data: 10.586 (10.586)
Train: 49 [  50/1251 (  4%)]  Loss:  5.299526 (5.1609)  Time: 0.586s, 1747.48/s  (3.116s,  328.64/s)  LR: 1.634e-04  Data: 0.018 (2.498)
Train: 49 [ 100/1251 (  8%)]  Loss:  4.717417 (5.0130)  Time: 2.190s,  467.54/s  (2.907s,  352.28/s)  LR: 1.634e-04  Data: 1.201 (2.279)
Train: 49 [ 150/1251 ( 12%)]  Loss:  4.943702 (4.9957)  Time: 0.584s, 1753.35/s  (2.844s,  360.01/s)  LR: 1.634e-04  Data: 0.019 (2.218)
Train: 49 [ 200/1251 ( 16%)]  Loss:  5.096430 (5.0159)  Time: 0.588s, 1740.08/s  (2.774s,  369.18/s)  LR: 1.634e-04  Data: 0.023 (2.154)
Train: 49 [ 250/1251 ( 20%)]  Loss:  5.080139 (5.0266)  Time: 0.588s, 1741.22/s  (2.745s,  373.10/s)  LR: 1.634e-04  Data: 0.019 (2.128)
Train: 49 [ 300/1251 ( 24%)]  Loss:  4.666473 (4.9751)  Time: 0.588s, 1742.24/s  (2.696s,  379.89/s)  LR: 1.634e-04  Data: 0.021 (2.079)
Train: 49 [ 350/1251 ( 28%)]  Loss:  4.753145 (4.9474)  Time: 0.591s, 1733.70/s  (2.705s,  378.50/s)  LR: 1.634e-04  Data: 0.020 (2.092)
Train: 49 [ 400/1251 ( 32%)]  Loss:  5.347640 (4.9919)  Time: 0.586s, 1748.44/s  (2.717s,  376.94/s)  LR: 1.634e-04  Data: 0.019 (2.104)
Train: 49 [ 450/1251 ( 36%)]  Loss:  5.162709 (5.0089)  Time: 0.588s, 1742.44/s  (2.729s,  375.17/s)  LR: 1.634e-04  Data: 0.021 (2.115)
Train: 49 [ 500/1251 ( 40%)]  Loss:  4.612248 (4.9729)  Time: 0.590s, 1736.80/s  (2.721s,  376.32/s)  LR: 1.634e-04  Data: 0.021 (2.108)
Train: 49 [ 550/1251 ( 44%)]  Loss:  5.272619 (4.9979)  Time: 0.588s, 1742.11/s  (2.724s,  375.96/s)  LR: 1.634e-04  Data: 0.022 (2.113)
Train: 49 [ 600/1251 ( 48%)]  Loss:  5.201944 (5.0136)  Time: 0.587s, 1744.77/s  (2.719s,  376.66/s)  LR: 1.634e-04  Data: 0.021 (2.110)
Train: 49 [ 650/1251 ( 52%)]  Loss:  5.232232 (5.0292)  Time: 0.585s, 1750.96/s  (2.722s,  376.16/s)  LR: 1.634e-04  Data: 0.022 (2.115)
Train: 49 [ 700/1251 ( 56%)]  Loss:  5.358644 (5.0511)  Time: 0.584s, 1751.99/s  (2.739s,  373.89/s)  LR: 1.634e-04  Data: 0.022 (2.133)
Train: 49 [ 750/1251 ( 60%)]  Loss:  5.207804 (5.0609)  Time: 0.584s, 1753.12/s  (2.741s,  373.59/s)  LR: 1.634e-04  Data: 0.021 (2.137)
Train: 49 [ 800/1251 ( 64%)]  Loss:  5.068186 (5.0614)  Time: 0.586s, 1748.24/s  (2.731s,  374.98/s)  LR: 1.634e-04  Data: 0.020 (2.127)
Train: 49 [ 850/1251 ( 68%)]  Loss:  5.059156 (5.0612)  Time: 0.586s, 1746.17/s  (2.728s,  375.42/s)  LR: 1.634e-04  Data: 0.022 (2.125)
Train: 49 [ 900/1251 ( 72%)]  Loss:  4.970545 (5.0565)  Time: 0.584s, 1753.99/s  (2.716s,  377.05/s)  LR: 1.634e-04  Data: 0.021 (2.113)
Train: 49 [ 950/1251 ( 76%)]  Loss:  5.183722 (5.0628)  Time: 0.584s, 1752.00/s  (2.710s,  377.92/s)  LR: 1.634e-04  Data: 0.020 (2.106)
Train: 49 [1000/1251 ( 80%)]  Loss:  4.307673 (5.0269)  Time: 0.591s, 1732.93/s  (2.698s,  379.61/s)  LR: 1.634e-04  Data: 0.028 (2.095)
Train: 49 [1050/1251 ( 84%)]  Loss:  4.556992 (5.0055)  Time: 0.587s, 1745.59/s  (2.712s,  377.51/s)  LR: 1.634e-04  Data: 0.021 (2.109)
Train: 49 [1100/1251 ( 88%)]  Loss:  5.421291 (5.0236)  Time: 0.585s, 1751.11/s  (2.713s,  377.45/s)  LR: 1.634e-04  Data: 0.022 (2.110)
Train: 49 [1150/1251 ( 92%)]  Loss:  4.791648 (5.0139)  Time: 0.585s, 1751.16/s  (2.720s,  376.50/s)  LR: 1.634e-04  Data: 0.022 (2.117)
Train: 49 [1200/1251 ( 96%)]  Loss:  4.704846 (5.0016)  Time: 0.584s, 1753.34/s  (2.716s,  377.08/s)  LR: 1.634e-04  Data: 0.022 (2.113)
Train: 49 [1250/1251 (100%)]  Loss:  4.705869 (4.9902)  Time: 0.565s, 1811.04/s  (2.714s,  377.35/s)  LR: 1.634e-04  Data: 0.000 (2.111)
Test: [   0/48]  Time: 15.261 (15.261)  Loss:  1.3928 (1.3928)  Acc@1: 71.4844 (71.4844)  Acc@5: 89.4531 (89.4531)
Test: [  48/48]  Time: 0.149 (3.527)  Loss:  1.3142 (2.3833)  Acc@1: 73.5849 (49.0620)  Acc@5: 88.3255 (74.0100)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 50 [   0/1251 (  0%)]  Loss:  4.642104 (4.6421)  Time: 12.156s,   84.24/s  (12.156s,   84.24/s)  LR: 1.468e-04  Data: 10.941 (10.941)
Train: 50 [  50/1251 (  4%)]  Loss:  4.920541 (4.7813)  Time: 0.589s, 1738.54/s  (3.140s,  326.14/s)  LR: 1.468e-04  Data: 0.019 (2.530)
Train: 50 [ 100/1251 (  8%)]  Loss:  4.911728 (4.8248)  Time: 0.595s, 1722.09/s  (2.984s,  343.12/s)  LR: 1.468e-04  Data: 0.020 (2.387)
Train: 50 [ 150/1251 ( 12%)]  Loss:  5.127688 (4.9005)  Time: 0.599s, 1710.90/s  (2.838s,  360.87/s)  LR: 1.468e-04  Data: 0.020 (2.245)
Train: 50 [ 200/1251 ( 16%)]  Loss:  5.220808 (4.9646)  Time: 0.582s, 1757.96/s  (2.807s,  364.79/s)  LR: 1.468e-04  Data: 0.021 (2.211)
Train: 50 [ 250/1251 ( 20%)]  Loss:  5.075392 (4.9830)  Time: 0.585s, 1751.90/s  (2.767s,  370.03/s)  LR: 1.468e-04  Data: 0.019 (2.172)
Train: 50 [ 300/1251 ( 24%)]  Loss:  5.320061 (5.0312)  Time: 0.589s, 1739.70/s  (2.728s,  375.38/s)  LR: 1.468e-04  Data: 0.018 (2.131)
Train: 50 [ 350/1251 ( 28%)]  Loss:  4.850445 (5.0086)  Time: 0.587s, 1744.78/s  (2.697s,  379.71/s)  LR: 1.468e-04  Data: 0.021 (2.098)
Train: 50 [ 400/1251 ( 32%)]  Loss:  4.895813 (4.9961)  Time: 0.587s, 1745.59/s  (2.725s,  375.84/s)  LR: 1.468e-04  Data: 0.020 (2.124)
Train: 50 [ 450/1251 ( 36%)]  Loss:  5.220523 (5.0185)  Time: 0.586s, 1748.54/s  (2.752s,  372.10/s)  LR: 1.468e-04  Data: 0.022 (2.152)
Train: 50 [ 500/1251 ( 40%)]  Loss:  4.710336 (4.9905)  Time: 0.583s, 1757.79/s  (2.736s,  374.26/s)  LR: 1.468e-04  Data: 0.020 (2.137)
Train: 50 [ 550/1251 ( 44%)]  Loss:  4.476276 (4.9476)  Time: 0.587s, 1744.71/s  (2.739s,  373.91/s)  LR: 1.468e-04  Data: 0.021 (2.142)
Train: 50 [ 600/1251 ( 48%)]  Loss:  5.282273 (4.9734)  Time: 0.588s, 1742.00/s  (2.734s,  374.49/s)  LR: 1.468e-04  Data: 0.023 (2.137)
Train: 50 [ 650/1251 ( 52%)]  Loss:  4.842345 (4.9640)  Time: 0.589s, 1737.99/s  (2.731s,  374.97/s)  LR: 1.468e-04  Data: 0.021 (2.134)
Train: 50 [ 700/1251 ( 56%)]  Loss:  5.162731 (4.9773)  Time: 0.585s, 1749.97/s  (2.743s,  373.38/s)  LR: 1.468e-04  Data: 0.023 (2.147)
Train: 50 [ 750/1251 ( 60%)]  Loss:  4.349326 (4.9380)  Time: 0.586s, 1746.18/s  (2.750s,  372.41/s)  LR: 1.468e-04  Data: 0.020 (2.152)
Train: 50 [ 800/1251 ( 64%)]  Loss:  4.630897 (4.9200)  Time: 0.588s, 1741.05/s  (2.740s,  373.68/s)  LR: 1.468e-04  Data: 0.023 (2.143)
Train: 50 [ 850/1251 ( 68%)]  Loss:  4.385708 (4.8903)  Time: 0.586s, 1747.53/s  (2.737s,  374.07/s)  LR: 1.468e-04  Data: 0.020 (2.139)
Train: 50 [ 900/1251 ( 72%)]  Loss:  5.431536 (4.9188)  Time: 1.180s,  868.14/s  (2.728s,  375.31/s)  LR: 1.468e-04  Data: 0.508 (2.130)
Train: 50 [ 950/1251 ( 76%)]  Loss:  4.979008 (4.9218)  Time: 0.587s, 1745.40/s  (2.716s,  377.07/s)  LR: 1.468e-04  Data: 0.024 (2.116)
Train: 50 [1000/1251 ( 80%)]  Loss:  4.939637 (4.9226)  Time: 2.281s,  448.92/s  (2.707s,  378.31/s)  LR: 1.468e-04  Data: 1.447 (2.106)
Train: 50 [1050/1251 ( 84%)]  Loss:  4.537122 (4.9051)  Time: 2.554s,  400.97/s  (2.716s,  377.06/s)  LR: 1.468e-04  Data: 1.772 (2.113)
Train: 50 [1100/1251 ( 88%)]  Loss:  4.527668 (4.8887)  Time: 1.311s,  781.24/s  (2.716s,  377.01/s)  LR: 1.468e-04  Data: 0.721 (2.112)
Train: 50 [1150/1251 ( 92%)]  Loss:  4.179186 (4.8591)  Time: 3.011s,  340.05/s  (2.720s,  376.52/s)  LR: 1.468e-04  Data: 2.449 (2.116)
Train: 50 [1200/1251 ( 96%)]  Loss:  5.327064 (4.8778)  Time: 0.587s, 1743.64/s  (2.716s,  377.05/s)  LR: 1.468e-04  Data: 0.019 (2.111)
Train: 50 [1250/1251 (100%)]  Loss:  5.144518 (4.8881)  Time: 0.565s, 1813.07/s  (2.710s,  377.83/s)  LR: 1.468e-04  Data: 0.000 (2.105)
Test: [   0/48]  Time: 16.176 (16.176)  Loss:  1.4272 (1.4272)  Acc@1: 72.0703 (72.0703)  Acc@5: 89.2578 (89.2578)
Test: [  48/48]  Time: 0.149 (3.510)  Loss:  1.3235 (2.3889)  Acc@1: 73.5849 (49.4660)  Acc@5: 88.3255 (74.3640)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 51 [   0/1251 (  0%)]  Loss:  5.195355 (5.1954)  Time: 12.499s,   81.93/s  (12.499s,   81.93/s)  LR: 1.309e-04  Data: 11.445 (11.445)
Train: 51 [  50/1251 (  4%)]  Loss:  4.945712 (5.0705)  Time: 2.419s,  423.34/s  (3.091s,  331.25/s)  LR: 1.309e-04  Data: 1.856 (2.475)
Train: 51 [ 100/1251 (  8%)]  Loss:  5.347051 (5.1627)  Time: 3.927s,  260.74/s  (2.984s,  343.16/s)  LR: 1.309e-04  Data: 3.255 (2.366)
Train: 51 [ 150/1251 ( 12%)]  Loss:  4.751723 (5.0600)  Time: 2.761s,  370.82/s  (2.881s,  355.46/s)  LR: 1.309e-04  Data: 2.200 (2.266)
Train: 51 [ 200/1251 ( 16%)]  Loss:  5.142876 (5.0765)  Time: 4.732s,  216.40/s  (2.813s,  364.07/s)  LR: 1.309e-04  Data: 4.015 (2.196)
Train: 51 [ 250/1251 ( 20%)]  Loss:  4.600199 (4.9972)  Time: 3.902s,  262.40/s  (2.763s,  370.63/s)  LR: 1.309e-04  Data: 3.170 (2.143)
Train: 51 [ 300/1251 ( 24%)]  Loss:  4.900605 (4.9834)  Time: 6.341s,  161.48/s  (2.730s,  375.09/s)  LR: 1.309e-04  Data: 5.779 (2.117)
Train: 51 [ 350/1251 ( 28%)]  Loss:  4.890841 (4.9718)  Time: 0.587s, 1744.67/s  (2.686s,  381.22/s)  LR: 1.309e-04  Data: 0.019 (2.070)
Train: 51 [ 400/1251 ( 32%)]  Loss:  4.972273 (4.9718)  Time: 8.722s,  117.40/s  (2.744s,  373.23/s)  LR: 1.309e-04  Data: 7.941 (2.127)
Train: 51 [ 450/1251 ( 36%)]  Loss:  5.281993 (5.0029)  Time: 0.585s, 1750.95/s  (2.742s,  373.42/s)  LR: 1.309e-04  Data: 0.021 (2.126)
Train: 51 [ 500/1251 ( 40%)]  Loss:  4.438339 (4.9515)  Time: 5.276s,  194.08/s  (2.731s,  374.92/s)  LR: 1.309e-04  Data: 4.690 (2.115)
Train: 51 [ 550/1251 ( 44%)]  Loss:  4.575642 (4.9202)  Time: 0.586s, 1746.31/s  (2.727s,  375.51/s)  LR: 1.309e-04  Data: 0.021 (2.112)
Train: 51 [ 600/1251 ( 48%)]  Loss:  4.495001 (4.8875)  Time: 1.827s,  560.58/s  (2.717s,  376.90/s)  LR: 1.309e-04  Data: 1.151 (2.103)
Train: 51 [ 650/1251 ( 52%)]  Loss:  4.751423 (4.8778)  Time: 4.168s,  245.67/s  (2.714s,  377.32/s)  LR: 1.309e-04  Data: 3.536 (2.100)
Train: 51 [ 700/1251 ( 56%)]  Loss:  5.146832 (4.8957)  Time: 0.585s, 1750.24/s  (2.699s,  379.43/s)  LR: 1.309e-04  Data: 0.020 (2.085)
Train: 51 [ 750/1251 ( 60%)]  Loss:  5.211402 (4.9155)  Time: 3.466s,  295.48/s  (2.726s,  375.59/s)  LR: 1.309e-04  Data: 2.804 (2.114)
Train: 51 [ 800/1251 ( 64%)]  Loss:  4.844408 (4.9113)  Time: 0.582s, 1757.95/s  (2.719s,  376.65/s)  LR: 1.309e-04  Data: 0.019 (2.107)
Train: 51 [ 850/1251 ( 68%)]  Loss:  5.158542 (4.9250)  Time: 2.662s,  384.73/s  (2.713s,  377.42/s)  LR: 1.309e-04  Data: 2.034 (2.101)
Train: 51 [ 900/1251 ( 72%)]  Loss:  5.042852 (4.9312)  Time: 0.585s, 1749.83/s  (2.703s,  378.84/s)  LR: 1.309e-04  Data: 0.021 (2.091)
Train: 51 [ 950/1251 ( 76%)]  Loss:  4.421713 (4.9057)  Time: 0.587s, 1743.46/s  (2.702s,  379.00/s)  LR: 1.309e-04  Data: 0.019 (2.091)
Train: 51 [1000/1251 ( 80%)]  Loss:  4.736688 (4.8977)  Time: 0.584s, 1754.70/s  (2.686s,  381.30/s)  LR: 1.309e-04  Data: 0.018 (2.075)
Train: 51 [1050/1251 ( 84%)]  Loss:  5.075366 (4.9058)  Time: 1.545s,  662.60/s  (2.705s,  378.56/s)  LR: 1.309e-04  Data: 0.855 (2.094)
Train: 51 [1100/1251 ( 88%)]  Loss:  4.896741 (4.9054)  Time: 0.584s, 1752.98/s  (2.699s,  379.43/s)  LR: 1.309e-04  Data: 0.017 (2.088)
Train: 51 [1150/1251 ( 92%)]  Loss:  4.978889 (4.9084)  Time: 9.069s,  112.91/s  (2.702s,  378.97/s)  LR: 1.309e-04  Data: 8.502 (2.092)
Train: 51 [1200/1251 ( 96%)]  Loss:  4.960256 (4.9105)  Time: 0.584s, 1754.20/s  (2.695s,  379.92/s)  LR: 1.309e-04  Data: 0.020 (2.086)
Train: 51 [1250/1251 (100%)]  Loss:  5.405878 (4.9296)  Time: 0.565s, 1813.92/s  (2.690s,  380.67/s)  LR: 1.309e-04  Data: 0.000 (2.081)
Test: [   0/48]  Time: 15.170 (15.170)  Loss:  1.4226 (1.4226)  Acc@1: 72.5586 (72.5586)  Acc@5: 88.5742 (88.5742)
Test: [  48/48]  Time: 0.148 (3.497)  Loss:  1.3227 (2.3714)  Acc@1: 74.2925 (49.8660)  Acc@5: 88.6792 (74.6160)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 52 [   0/1251 (  0%)]  Loss:  4.970988 (4.9710)  Time: 12.404s,   82.56/s  (12.404s,   82.56/s)  LR: 1.159e-04  Data: 11.218 (11.218)
Train: 52 [  50/1251 (  4%)]  Loss:  5.261756 (5.1164)  Time: 0.586s, 1746.43/s  (2.609s,  392.54/s)  LR: 1.159e-04  Data: 0.024 (1.989)
Train: 52 [ 100/1251 (  8%)]  Loss:  5.190598 (5.1411)  Time: 1.860s,  550.66/s  (2.877s,  355.89/s)  LR: 1.159e-04  Data: 1.180 (2.249)
Train: 52 [ 150/1251 ( 12%)]  Loss:  4.820343 (5.0609)  Time: 0.584s, 1752.60/s  (2.828s,  362.07/s)  LR: 1.159e-04  Data: 0.022 (2.206)
Train: 52 [ 200/1251 ( 16%)]  Loss:  4.172113 (4.8832)  Time: 4.669s,  219.33/s  (2.810s,  364.45/s)  LR: 1.159e-04  Data: 4.103 (2.190)
Train: 52 [ 250/1251 ( 20%)]  Loss:  5.256288 (4.9453)  Time: 0.587s, 1744.23/s  (2.753s,  371.96/s)  LR: 1.159e-04  Data: 0.022 (2.133)
Train: 52 [ 300/1251 ( 24%)]  Loss:  5.133629 (4.9722)  Time: 7.101s,  144.21/s  (2.741s,  373.62/s)  LR: 1.159e-04  Data: 6.521 (2.120)
Train: 52 [ 350/1251 ( 28%)]  Loss:  5.089152 (4.9869)  Time: 4.100s,  249.78/s  (2.700s,  379.21/s)  LR: 1.159e-04  Data: 3.393 (2.076)
Train: 52 [ 400/1251 ( 32%)]  Loss:  4.784292 (4.9644)  Time: 3.908s,  262.01/s  (2.730s,  375.12/s)  LR: 1.159e-04  Data: 3.220 (2.103)
Train: 52 [ 450/1251 ( 36%)]  Loss:  4.901567 (4.9581)  Time: 0.589s, 1738.45/s  (2.729s,  375.19/s)  LR: 1.159e-04  Data: 0.026 (2.099)
Train: 52 [ 500/1251 ( 40%)]  Loss:  5.440131 (5.0019)  Time: 4.201s,  243.74/s  (2.751s,  372.29/s)  LR: 1.159e-04  Data: 3.608 (2.120)
Train: 52 [ 550/1251 ( 44%)]  Loss:  5.173341 (5.0162)  Time: 0.593s, 1727.03/s  (2.741s,  373.63/s)  LR: 1.159e-04  Data: 0.027 (2.113)
Train: 52 [ 600/1251 ( 48%)]  Loss:  4.378726 (4.9671)  Time: 3.828s,  267.48/s  (2.754s,  371.85/s)  LR: 1.159e-04  Data: 3.266 (2.126)
Train: 52 [ 650/1251 ( 52%)]  Loss:  4.745648 (4.9513)  Time: 0.592s, 1728.80/s  (2.750s,  372.42/s)  LR: 1.159e-04  Data: 0.023 (2.123)
Train: 52 [ 700/1251 ( 56%)]  Loss:  4.795168 (4.9409)  Time: 5.931s,  172.64/s  (2.737s,  374.19/s)  LR: 1.159e-04  Data: 5.366 (2.112)
Train: 52 [ 750/1251 ( 60%)]  Loss:  4.683352 (4.9248)  Time: 0.587s, 1744.23/s  (2.761s,  370.88/s)  LR: 1.159e-04  Data: 0.024 (2.137)
Train: 52 [ 800/1251 ( 64%)]  Loss:  5.293254 (4.9465)  Time: 2.904s,  352.59/s  (2.771s,  369.60/s)  LR: 1.159e-04  Data: 2.343 (2.147)
Train: 52 [ 850/1251 ( 68%)]  Loss:  4.736886 (4.9348)  Time: 0.587s, 1744.61/s  (2.758s,  371.27/s)  LR: 1.159e-04  Data: 0.018 (2.136)
Train: 52 [ 900/1251 ( 72%)]  Loss:  4.902700 (4.9332)  Time: 0.585s, 1750.24/s  (2.757s,  371.41/s)  LR: 1.159e-04  Data: 0.021 (2.137)
Train: 52 [ 950/1251 ( 76%)]  Loss:  4.669231 (4.9200)  Time: 0.587s, 1743.85/s  (2.746s,  372.85/s)  LR: 1.159e-04  Data: 0.022 (2.128)
Train: 52 [1000/1251 ( 80%)]  Loss:  4.938581 (4.9208)  Time: 0.587s, 1743.35/s  (2.735s,  374.41/s)  LR: 1.159e-04  Data: 0.023 (2.116)
Train: 52 [1050/1251 ( 84%)]  Loss:  4.711740 (4.9113)  Time: 0.586s, 1747.47/s  (2.737s,  374.07/s)  LR: 1.159e-04  Data: 0.019 (2.119)
Train: 52 [1100/1251 ( 88%)]  Loss:  5.412864 (4.9331)  Time: 2.961s,  345.87/s  (2.749s,  372.49/s)  LR: 1.159e-04  Data: 2.399 (2.131)
Train: 52 [1150/1251 ( 92%)]  Loss:  4.793958 (4.9273)  Time: 0.588s, 1742.24/s  (2.750s,  372.32/s)  LR: 1.159e-04  Data: 0.018 (2.133)
Train: 52 [1200/1251 ( 96%)]  Loss:  5.209338 (4.9386)  Time: 0.586s, 1747.00/s  (2.752s,  372.05/s)  LR: 1.159e-04  Data: 0.018 (2.134)
Train: 52 [1250/1251 (100%)]  Loss:  4.838840 (4.9348)  Time: 0.564s, 1814.20/s  (2.746s,  372.89/s)  LR: 1.159e-04  Data: 0.000 (2.129)
Test: [   0/48]  Time: 16.363 (16.363)  Loss:  1.3725 (1.3725)  Acc@1: 72.3633 (72.3633)  Acc@5: 89.1602 (89.1602)
Test: [  48/48]  Time: 0.149 (3.589)  Loss:  1.2995 (2.3185)  Acc@1: 73.1132 (50.6600)  Acc@5: 88.6792 (75.3060)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 53 [   0/1251 (  0%)]  Loss:  4.906364 (4.9064)  Time: 11.500s,   89.04/s  (11.500s,   89.04/s)  LR: 1.018e-04  Data: 10.820 (10.820)
Train: 53 [  50/1251 (  4%)]  Loss:  4.585595 (4.7460)  Time: 0.822s, 1245.88/s  (2.628s,  389.61/s)  LR: 1.018e-04  Data: 0.257 (2.031)
Train: 53 [ 100/1251 (  8%)]  Loss:  4.265828 (4.5859)  Time: 0.592s, 1728.29/s  (2.909s,  351.96/s)  LR: 1.018e-04  Data: 0.021 (2.305)
Train: 53 [ 150/1251 ( 12%)]  Loss:  4.887222 (4.6613)  Time: 2.363s,  433.43/s  (2.821s,  362.94/s)  LR: 1.018e-04  Data: 1.801 (2.216)
Train: 53 [ 200/1251 ( 16%)]  Loss:  4.527501 (4.6345)  Time: 0.810s, 1264.64/s  (2.775s,  369.03/s)  LR: 1.018e-04  Data: 0.248 (2.159)
Train: 53 [ 250/1251 ( 20%)]  Loss:  5.042927 (4.7026)  Time: 2.158s,  474.44/s  (2.766s,  370.26/s)  LR: 1.018e-04  Data: 1.595 (2.151)
Train: 53 [ 300/1251 ( 24%)]  Loss:  4.611696 (4.6896)  Time: 0.586s, 1748.45/s  (2.735s,  374.47/s)  LR: 1.018e-04  Data: 0.020 (2.121)
Train: 53 [ 350/1251 ( 28%)]  Loss:  5.275623 (4.7628)  Time: 4.935s,  207.50/s  (2.725s,  375.78/s)  LR: 1.018e-04  Data: 4.320 (2.110)
Train: 53 [ 400/1251 ( 32%)]  Loss:  5.267666 (4.8189)  Time: 0.587s, 1745.82/s  (2.749s,  372.53/s)  LR: 1.018e-04  Data: 0.022 (2.135)
Train: 53 [ 450/1251 ( 36%)]  Loss:  4.631531 (4.8002)  Time: 8.167s,  125.38/s  (2.760s,  371.07/s)  LR: 1.018e-04  Data: 7.495 (2.147)
Train: 53 [ 500/1251 ( 40%)]  Loss:  5.086936 (4.8263)  Time: 1.542s,  663.94/s  (2.745s,  372.98/s)  LR: 1.018e-04  Data: 0.979 (2.135)
Train: 53 [ 550/1251 ( 44%)]  Loss:  4.323940 (4.7844)  Time: 3.983s,  257.09/s  (2.743s,  373.30/s)  LR: 1.018e-04  Data: 3.376 (2.132)
Train: 53 [ 600/1251 ( 48%)]  Loss:  5.290326 (4.8233)  Time: 0.585s, 1750.92/s  (2.738s,  374.04/s)  LR: 1.018e-04  Data: 0.020 (2.127)
Train: 53 [ 650/1251 ( 52%)]  Loss:  5.053448 (4.8398)  Time: 5.719s,  179.05/s  (2.744s,  373.24/s)  LR: 1.018e-04  Data: 5.073 (2.133)
Train: 53 [ 700/1251 ( 56%)]  Loss:  5.233937 (4.8660)  Time: 0.586s, 1748.31/s  (2.724s,  375.85/s)  LR: 1.018e-04  Data: 0.021 (2.116)
Train: 53 [ 750/1251 ( 60%)]  Loss:  4.630001 (4.8513)  Time: 4.101s,  249.67/s  (2.746s,  372.93/s)  LR: 1.018e-04  Data: 3.533 (2.137)
Train: 53 [ 800/1251 ( 64%)]  Loss:  5.013147 (4.8608)  Time: 0.584s, 1752.27/s  (2.742s,  373.42/s)  LR: 1.018e-04  Data: 0.021 (2.133)
Train: 53 [ 850/1251 ( 68%)]  Loss:  4.967555 (4.8667)  Time: 4.673s,  219.11/s  (2.740s,  373.74/s)  LR: 1.018e-04  Data: 4.112 (2.130)
Train: 53 [ 900/1251 ( 72%)]  Loss:  4.229687 (4.8332)  Time: 0.587s, 1745.18/s  (2.726s,  375.69/s)  LR: 1.018e-04  Data: 0.023 (2.117)
Train: 53 [ 950/1251 ( 76%)]  Loss:  4.670537 (4.8251)  Time: 0.588s, 1740.73/s  (2.724s,  375.98/s)  LR: 1.018e-04  Data: 0.022 (2.115)
Train: 53 [1000/1251 ( 80%)]  Loss:  4.569285 (4.8129)  Time: 0.585s, 1751.31/s  (2.711s,  377.76/s)  LR: 1.018e-04  Data: 0.020 (2.103)
Train: 53 [1050/1251 ( 84%)]  Loss:  4.861805 (4.8151)  Time: 3.628s,  282.25/s  (2.722s,  376.14/s)  LR: 1.018e-04  Data: 3.066 (2.116)
Train: 53 [1100/1251 ( 88%)]  Loss:  4.846298 (4.8165)  Time: 0.585s, 1751.40/s  (2.722s,  376.25/s)  LR: 1.018e-04  Data: 0.018 (2.115)
Train: 53 [1150/1251 ( 92%)]  Loss:  4.926799 (4.8211)  Time: 0.587s, 1744.11/s  (2.729s,  375.18/s)  LR: 1.018e-04  Data: 0.024 (2.124)
Train: 53 [1200/1251 ( 96%)]  Loss:  4.716866 (4.8169)  Time: 0.584s, 1752.47/s  (2.724s,  375.98/s)  LR: 1.018e-04  Data: 0.022 (2.118)
Train: 53 [1250/1251 (100%)]  Loss:  4.819877 (4.8170)  Time: 0.566s, 1810.22/s  (2.722s,  376.17/s)  LR: 1.018e-04  Data: 0.000 (2.117)
Test: [   0/48]  Time: 16.677 (16.677)  Loss:  1.3526 (1.3526)  Acc@1: 72.5586 (72.5586)  Acc@5: 90.0391 (90.0391)
Test: [  48/48]  Time: 0.149 (3.634)  Loss:  1.2855 (2.2931)  Acc@1: 73.9387 (50.7540)  Acc@5: 88.7972 (75.5980)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-44.pth.tar', 46.74200004394531)

Train: 54 [   0/1251 (  0%)]  Loss:  4.906153 (4.9062)  Time: 12.609s,   81.21/s  (12.609s,   81.21/s)  LR: 8.858e-05  Data: 11.320 (11.320)
Train: 54 [  50/1251 (  4%)]  Loss:  4.887500 (4.8968)  Time: 0.583s, 1756.38/s  (2.529s,  404.89/s)  LR: 8.858e-05  Data: 0.020 (1.932)
Train: 54 [ 100/1251 (  8%)]  Loss:  4.958240 (4.9173)  Time: 0.977s, 1048.36/s  (2.752s,  372.14/s)  LR: 8.858e-05  Data: 0.396 (2.151)
Train: 54 [ 150/1251 ( 12%)]  Loss:  4.388155 (4.7850)  Time: 0.587s, 1744.73/s  (2.729s,  375.23/s)  LR: 8.858e-05  Data: 0.020 (2.119)
Train: 54 [ 200/1251 ( 16%)]  Loss:  5.099441 (4.8479)  Time: 3.800s,  269.51/s  (2.727s,  375.45/s)  LR: 8.858e-05  Data: 3.208 (2.119)
Train: 54 [ 250/1251 ( 20%)]  Loss:  4.717472 (4.8262)  Time: 0.584s, 1754.84/s  (2.682s,  381.75/s)  LR: 8.858e-05  Data: 0.020 (2.076)
Train: 54 [ 300/1251 ( 24%)]  Loss:  5.277286 (4.8906)  Time: 0.586s, 1747.13/s  (2.671s,  383.31/s)  LR: 8.858e-05  Data: 0.019 (2.067)
Train: 54 [ 350/1251 ( 28%)]  Loss:  4.257456 (4.8115)  Time: 0.586s, 1746.46/s  (2.637s,  388.38/s)  LR: 8.858e-05  Data: 0.021 (2.033)
Train: 54 [ 400/1251 ( 32%)]  Loss:  4.840784 (4.8147)  Time: 0.586s, 1747.62/s  (2.649s,  386.49/s)  LR: 8.858e-05  Data: 0.021 (2.049)
Train: 54 [ 450/1251 ( 36%)]  Loss:  4.322813 (4.7655)  Time: 0.585s, 1749.97/s  (2.665s,  384.29/s)  LR: 8.858e-05  Data: 0.021 (2.064)
Train: 54 [ 500/1251 ( 40%)]  Loss:  5.115823 (4.7974)  Time: 0.589s, 1738.64/s  (2.684s,  381.49/s)  LR: 8.858e-05  Data: 0.018 (2.083)
Train: 54 [ 550/1251 ( 44%)]  Loss:  4.799490 (4.7976)  Time: 0.590s, 1735.44/s  (2.686s,  381.22/s)  LR: 8.858e-05  Data: 0.019 (2.086)
Train: 54 [ 600/1251 ( 48%)]  Loss:  5.383574 (4.8426)  Time: 0.585s, 1751.73/s  (2.706s,  378.42/s)  LR: 8.858e-05  Data: 0.018 (2.106)
Train: 54 [ 650/1251 ( 52%)]  Loss:  5.033669 (4.8563)  Time: 0.585s, 1751.06/s  (2.699s,  379.41/s)  LR: 8.858e-05  Data: 0.020 (2.100)
Train: 54 [ 700/1251 ( 56%)]  Loss:  4.695271 (4.8455)  Time: 0.586s, 1748.90/s  (2.703s,  378.86/s)  LR: 8.858e-05  Data: 0.019 (2.105)
Train: 54 [ 750/1251 ( 60%)]  Loss:  4.993683 (4.8548)  Time: 0.585s, 1751.66/s  (2.718s,  376.72/s)  LR: 8.858e-05  Data: 0.019 (2.120)
Train: 54 [ 800/1251 ( 64%)]  Loss:  5.069947 (4.8675)  Time: 0.587s, 1743.27/s  (2.725s,  375.85/s)  LR: 8.858e-05  Data: 0.019 (2.127)
Train: 54 [ 850/1251 ( 68%)]  Loss:  5.252471 (4.8888)  Time: 0.585s, 1751.69/s  (2.719s,  376.58/s)  LR: 8.858e-05  Data: 0.020 (2.122)
Train: 54 [ 900/1251 ( 72%)]  Loss:  4.997138 (4.8945)  Time: 0.586s, 1748.38/s  (2.726s,  375.58/s)  LR: 8.858e-05  Data: 0.019 (2.129)
Train: 54 [ 950/1251 ( 76%)]  Loss:  4.410904 (4.8704)  Time: 0.583s, 1757.07/s  (2.717s,  376.85/s)  LR: 8.858e-05  Data: 0.019 (2.120)
Train: 54 [1000/1251 ( 80%)]  Loss:  4.952150 (4.8743)  Time: 0.588s, 1741.09/s  (2.716s,  377.04/s)  LR: 8.858e-05  Data: 0.019 (2.119)
Train: 54 [1050/1251 ( 84%)]  Loss:  4.732987 (4.8678)  Time: 0.589s, 1738.53/s  (2.700s,  379.23/s)  LR: 8.858e-05  Data: 0.022 (2.104)
Train: 54 [1100/1251 ( 88%)]  Loss:  4.605962 (4.8565)  Time: 0.584s, 1752.71/s  (2.720s,  376.42/s)  LR: 8.858e-05  Data: 0.020 (2.124)
Train: 54 [1150/1251 ( 92%)]  Loss:  4.637331 (4.8473)  Time: 0.585s, 1749.47/s  (2.722s,  376.19/s)  LR: 8.858e-05  Data: 0.023 (2.126)
Train: 54 [1200/1251 ( 96%)]  Loss:  4.993213 (4.8532)  Time: 0.585s, 1751.38/s  (2.724s,  375.90/s)  LR: 8.858e-05  Data: 0.022 (2.128)
Train: 54 [1250/1251 (100%)]  Loss:  4.950730 (4.8569)  Time: 0.566s, 1809.34/s  (2.718s,  376.72/s)  LR: 8.858e-05  Data: 0.000 (2.122)
Test: [   0/48]  Time: 15.210 (15.210)  Loss:  1.3839 (1.3839)  Acc@1: 72.6562 (72.6562)  Acc@5: 89.3555 (89.3555)
Test: [  48/48]  Time: 0.148 (3.625)  Loss:  1.3067 (2.2979)  Acc@1: 73.3491 (51.1220)  Acc@5: 89.2689 (75.6780)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-45.pth.tar', 47.28600007080078)

Train: 55 [   0/1251 (  0%)]  Loss:  5.037529 (5.0375)  Time: 12.097s,   84.65/s  (12.097s,   84.65/s)  LR: 7.632e-05  Data: 11.297 (11.297)
Train: 55 [  50/1251 (  4%)]  Loss:  4.893217 (4.9654)  Time: 0.584s, 1754.10/s  (2.593s,  394.90/s)  LR: 7.632e-05  Data: 0.020 (1.985)
Train: 55 [ 100/1251 (  8%)]  Loss:  4.829566 (4.9201)  Time: 0.585s, 1750.06/s  (2.802s,  365.47/s)  LR: 7.632e-05  Data: 0.019 (2.198)
Train: 55 [ 150/1251 ( 12%)]  Loss:  5.261854 (5.0055)  Time: 0.586s, 1748.52/s  (2.787s,  367.36/s)  LR: 7.632e-05  Data: 0.018 (2.178)
Train: 55 [ 200/1251 ( 16%)]  Loss:  4.504398 (4.9053)  Time: 0.585s, 1750.91/s  (2.771s,  369.58/s)  LR: 7.632e-05  Data: 0.020 (2.163)
Train: 55 [ 250/1251 ( 20%)]  Loss:  4.496113 (4.8371)  Time: 0.591s, 1732.30/s  (2.732s,  374.84/s)  LR: 7.632e-05  Data: 0.019 (2.127)
Train: 55 [ 300/1251 ( 24%)]  Loss:  4.423486 (4.7780)  Time: 0.752s, 1361.42/s  (2.707s,  378.26/s)  LR: 7.632e-05  Data: 0.190 (2.104)
Train: 55 [ 350/1251 ( 28%)]  Loss:  4.952854 (4.7999)  Time: 0.586s, 1747.05/s  (2.694s,  380.07/s)  LR: 7.632e-05  Data: 0.020 (2.090)
Train: 55 [ 400/1251 ( 32%)]  Loss:  5.007800 (4.8230)  Time: 2.851s,  359.16/s  (2.666s,  384.05/s)  LR: 7.632e-05  Data: 2.268 (2.062)
Train: 55 [ 450/1251 ( 36%)]  Loss:  4.905440 (4.8312)  Time: 0.586s, 1747.84/s  (2.718s,  376.72/s)  LR: 7.632e-05  Data: 0.019 (2.113)
Train: 55 [ 500/1251 ( 40%)]  Loss:  4.995782 (4.8462)  Time: 0.585s, 1749.67/s  (2.714s,  377.34/s)  LR: 7.632e-05  Data: 0.020 (2.110)
Train: 55 [ 550/1251 ( 44%)]  Loss:  4.778860 (4.8406)  Time: 0.584s, 1752.98/s  (2.725s,  375.83/s)  LR: 7.632e-05  Data: 0.019 (2.121)
Train: 55 [ 600/1251 ( 48%)]  Loss:  4.694686 (4.8294)  Time: 0.582s, 1758.29/s  (2.735s,  374.40/s)  LR: 7.632e-05  Data: 0.019 (2.132)
Train: 55 [ 650/1251 ( 52%)]  Loss:  4.976824 (4.8399)  Time: 0.585s, 1749.47/s  (2.732s,  374.81/s)  LR: 7.632e-05  Data: 0.021 (2.130)
Train: 55 [ 700/1251 ( 56%)]  Loss:  4.611705 (4.8247)  Time: 0.588s, 1740.71/s  (2.720s,  376.46/s)  LR: 7.632e-05  Data: 0.019 (2.118)
Train: 55 [ 750/1251 ( 60%)]  Loss:  4.589834 (4.8100)  Time: 0.587s, 1745.51/s  (2.734s,  374.49/s)  LR: 7.632e-05  Data: 0.024 (2.131)
Train: 55 [ 800/1251 ( 64%)]  Loss:  4.685958 (4.8027)  Time: 0.589s, 1738.01/s  (2.737s,  374.12/s)  LR: 7.632e-05  Data: 0.024 (2.133)
Train: 55 [ 850/1251 ( 68%)]  Loss:  4.350224 (4.7776)  Time: 0.587s, 1743.67/s  (2.736s,  374.32/s)  LR: 7.632e-05  Data: 0.024 (2.132)
Train: 55 [ 900/1251 ( 72%)]  Loss:  4.131515 (4.7436)  Time: 0.585s, 1749.07/s  (2.734s,  374.49/s)  LR: 7.632e-05  Data: 0.017 (2.131)
Train: 55 [ 950/1251 ( 76%)]  Loss:  4.947184 (4.7537)  Time: 2.560s,  399.99/s  (2.725s,  375.82/s)  LR: 7.632e-05  Data: 1.995 (2.120)
Train: 55 [1000/1251 ( 80%)]  Loss:  4.308898 (4.7326)  Time: 0.585s, 1749.79/s  (2.715s,  377.15/s)  LR: 7.632e-05  Data: 0.017 (2.112)
Train: 55 [1050/1251 ( 84%)]  Loss:  4.925654 (4.7413)  Time: 4.569s,  224.10/s  (2.705s,  378.56/s)  LR: 7.632e-05  Data: 3.891 (2.101)
Train: 55 [1100/1251 ( 88%)]  Loss:  4.988558 (4.7521)  Time: 4.764s,  214.94/s  (2.717s,  376.92/s)  LR: 7.632e-05  Data: 4.184 (2.112)
Train: 55 [1150/1251 ( 92%)]  Loss:  4.940131 (4.7599)  Time: 2.750s,  372.32/s  (2.720s,  376.51/s)  LR: 7.632e-05  Data: 2.043 (2.114)
Train: 55 [1200/1251 ( 96%)]  Loss:  4.844458 (4.7633)  Time: 6.352s,  161.22/s  (2.719s,  376.62/s)  LR: 7.632e-05  Data: 5.677 (2.112)
Train: 55 [1250/1251 (100%)]  Loss:  4.492451 (4.7529)  Time: 0.565s, 1813.88/s  (2.711s,  377.70/s)  LR: 7.632e-05  Data: 0.000 (2.104)
Test: [   0/48]  Time: 15.467 (15.467)  Loss:  1.3490 (1.3490)  Acc@1: 73.5352 (73.5352)  Acc@5: 89.6484 (89.6484)
Test: [  48/48]  Time: 0.149 (3.651)  Loss:  1.2882 (2.2655)  Acc@1: 74.0566 (51.7220)  Acc@5: 89.0330 (76.2440)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-46.pth.tar', 47.75200006835937)

Train: 56 [   0/1251 (  0%)]  Loss:  4.865112 (4.8651)  Time: 11.588s,   88.37/s  (11.588s,   88.37/s)  LR: 6.503e-05  Data: 10.882 (10.882)
Train: 56 [  50/1251 (  4%)]  Loss:  4.543605 (4.7044)  Time: 0.589s, 1739.94/s  (2.599s,  393.97/s)  LR: 6.503e-05  Data: 0.020 (2.002)
Train: 56 [ 100/1251 (  8%)]  Loss:  4.838462 (4.7491)  Time: 2.285s,  448.21/s  (2.756s,  371.55/s)  LR: 6.503e-05  Data: 1.624 (2.158)
Train: 56 [ 150/1251 ( 12%)]  Loss:  4.571909 (4.7048)  Time: 0.588s, 1740.95/s  (2.731s,  374.91/s)  LR: 6.503e-05  Data: 0.019 (2.134)
Train: 56 [ 200/1251 ( 16%)]  Loss:  5.115334 (4.7869)  Time: 6.539s,  156.60/s  (2.764s,  370.48/s)  LR: 6.503e-05  Data: 5.928 (2.169)
Train: 56 [ 250/1251 ( 20%)]  Loss:  4.833644 (4.7947)  Time: 0.586s, 1747.39/s  (2.705s,  378.61/s)  LR: 6.503e-05  Data: 0.018 (2.105)
Train: 56 [ 300/1251 ( 24%)]  Loss:  5.165315 (4.8476)  Time: 3.291s,  311.12/s  (2.689s,  380.84/s)  LR: 6.503e-05  Data: 2.729 (2.087)
Train: 56 [ 350/1251 ( 28%)]  Loss:  4.961571 (4.8619)  Time: 0.585s, 1751.58/s  (2.649s,  386.53/s)  LR: 6.503e-05  Data: 0.020 (2.046)
Train: 56 [ 400/1251 ( 32%)]  Loss:  5.092185 (4.8875)  Time: 1.390s,  736.94/s  (2.633s,  388.90/s)  LR: 6.503e-05  Data: 0.828 (2.030)
Train: 56 [ 450/1251 ( 36%)]  Loss:  4.906445 (4.8894)  Time: 0.585s, 1750.55/s  (2.653s,  385.97/s)  LR: 6.503e-05  Data: 0.020 (2.047)
Train: 56 [ 500/1251 ( 40%)]  Loss:  4.764624 (4.8780)  Time: 0.583s, 1755.48/s  (2.669s,  383.68/s)  LR: 6.503e-05  Data: 0.021 (2.066)
Train: 56 [ 550/1251 ( 44%)]  Loss:  4.450437 (4.8424)  Time: 0.588s, 1742.89/s  (2.664s,  384.37/s)  LR: 6.503e-05  Data: 0.021 (2.062)
Train: 56 [ 600/1251 ( 48%)]  Loss:  4.887234 (4.8458)  Time: 8.977s,  114.06/s  (2.686s,  381.20/s)  LR: 6.503e-05  Data: 8.386 (2.084)
Train: 56 [ 650/1251 ( 52%)]  Loss:  4.695374 (4.8351)  Time: 0.586s, 1748.02/s  (2.683s,  381.73/s)  LR: 6.503e-05  Data: 0.023 (2.080)
Train: 56 [ 700/1251 ( 56%)]  Loss:  4.695847 (4.8258)  Time: 4.760s,  215.10/s  (2.677s,  382.48/s)  LR: 6.503e-05  Data: 4.024 (2.076)
Train: 56 [ 750/1251 ( 60%)]  Loss:  5.095758 (4.8427)  Time: 0.586s, 1746.82/s  (2.678s,  382.40/s)  LR: 6.503e-05  Data: 0.018 (2.074)
Train: 56 [ 800/1251 ( 64%)]  Loss:  4.285229 (4.8099)  Time: 4.723s,  216.83/s  (2.687s,  381.03/s)  LR: 6.503e-05  Data: 4.072 (2.083)
Train: 56 [ 850/1251 ( 68%)]  Loss:  4.762402 (4.8072)  Time: 0.586s, 1746.39/s  (2.684s,  381.48/s)  LR: 6.503e-05  Data: 0.018 (2.079)
Train: 56 [ 900/1251 ( 72%)]  Loss:  4.374636 (4.7845)  Time: 3.295s,  310.79/s  (2.685s,  381.38/s)  LR: 6.503e-05  Data: 2.613 (2.079)
Train: 56 [ 950/1251 ( 76%)]  Loss:  4.794124 (4.7850)  Time: 0.588s, 1742.77/s  (2.678s,  382.42/s)  LR: 6.503e-05  Data: 0.019 (2.070)
Train: 56 [1000/1251 ( 80%)]  Loss:  4.794551 (4.7854)  Time: 8.643s,  118.48/s  (2.674s,  382.89/s)  LR: 6.503e-05  Data: 7.965 (2.067)
Train: 56 [1050/1251 ( 84%)]  Loss:  4.710480 (4.7820)  Time: 0.584s, 1752.95/s  (2.664s,  384.34/s)  LR: 6.503e-05  Data: 0.020 (2.058)
Train: 56 [1100/1251 ( 88%)]  Loss:  5.102768 (4.7960)  Time: 10.143s,  100.96/s  (2.674s,  382.95/s)  LR: 6.503e-05  Data: 9.562 (2.069)
Train: 56 [1150/1251 ( 92%)]  Loss:  4.918227 (4.8011)  Time: 0.586s, 1747.90/s  (2.674s,  382.98/s)  LR: 6.503e-05  Data: 0.022 (2.070)
Train: 56 [1200/1251 ( 96%)]  Loss:  4.574414 (4.7920)  Time: 9.201s,  111.29/s  (2.680s,  382.11/s)  LR: 6.503e-05  Data: 8.631 (2.077)
Train: 56 [1250/1251 (100%)]  Loss:  5.241838 (4.8093)  Time: 0.564s, 1814.20/s  (2.679s,  382.29/s)  LR: 6.503e-05  Data: 0.000 (2.076)
Test: [   0/48]  Time: 15.480 (15.480)  Loss:  1.3392 (1.3392)  Acc@1: 73.2422 (73.2422)  Acc@5: 89.4531 (89.4531)
Test: [  48/48]  Time: 0.149 (3.783)  Loss:  1.2756 (2.2492)  Acc@1: 73.9387 (51.7360)  Acc@5: 89.1509 (76.4560)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-47.pth.tar', 48.22199998779297)

Train: 57 [   0/1251 (  0%)]  Loss:  5.217130 (5.2171)  Time: 12.993s,   78.81/s  (12.993s,   78.81/s)  LR: 5.473e-05  Data: 12.285 (12.285)
Train: 57 [  50/1251 (  4%)]  Loss:  5.052711 (5.1349)  Time: 0.590s, 1735.23/s  (2.805s,  365.08/s)  LR: 5.473e-05  Data: 0.020 (2.205)
Train: 57 [ 100/1251 (  8%)]  Loss:  4.713860 (4.9946)  Time: 0.583s, 1755.65/s  (2.890s,  354.28/s)  LR: 5.473e-05  Data: 0.019 (2.266)
Train: 57 [ 150/1251 ( 12%)]  Loss:  4.742396 (4.9315)  Time: 0.586s, 1748.86/s  (2.889s,  354.47/s)  LR: 5.473e-05  Data: 0.020 (2.272)
Train: 57 [ 200/1251 ( 16%)]  Loss:  4.480956 (4.8414)  Time: 0.922s, 1110.85/s  (2.931s,  349.35/s)  LR: 5.473e-05  Data: 0.278 (2.320)
Train: 57 [ 250/1251 ( 20%)]  Loss:  4.307466 (4.7524)  Time: 0.584s, 1752.20/s  (2.902s,  352.83/s)  LR: 5.473e-05  Data: 0.018 (2.289)
Train: 57 [ 300/1251 ( 24%)]  Loss:  4.338526 (4.6933)  Time: 4.801s,  213.29/s  (2.881s,  355.40/s)  LR: 5.473e-05  Data: 4.136 (2.271)
Train: 57 [ 350/1251 ( 28%)]  Loss:  4.855235 (4.7135)  Time: 0.584s, 1754.20/s  (2.829s,  361.91/s)  LR: 5.473e-05  Data: 0.021 (2.220)
Train: 57 [ 400/1251 ( 32%)]  Loss:  5.185707 (4.7660)  Time: 5.311s,  192.81/s  (2.795s,  366.35/s)  LR: 5.473e-05  Data: 4.702 (2.188)
Train: 57 [ 450/1251 ( 36%)]  Loss:  5.235318 (4.8129)  Time: 0.586s, 1746.32/s  (2.811s,  364.23/s)  LR: 5.473e-05  Data: 0.018 (2.204)
Train: 57 [ 500/1251 ( 40%)]  Loss:  4.846192 (4.8160)  Time: 1.899s,  539.24/s  (2.830s,  361.80/s)  LR: 5.473e-05  Data: 1.249 (2.222)
Train: 57 [ 550/1251 ( 44%)]  Loss:  4.711864 (4.8073)  Time: 0.987s, 1037.49/s  (2.839s,  360.70/s)  LR: 5.473e-05  Data: 0.020 (2.230)
Train: 57 [ 600/1251 ( 48%)]  Loss:  4.444019 (4.7793)  Time: 1.426s,  718.25/s  (2.854s,  358.80/s)  LR: 5.473e-05  Data: 0.777 (2.243)
Train: 57 [ 650/1251 ( 52%)]  Loss:  4.803042 (4.7810)  Time: 0.585s, 1750.70/s  (2.858s,  358.28/s)  LR: 5.473e-05  Data: 0.018 (2.248)
Train: 57 [ 700/1251 ( 56%)]  Loss:  4.563504 (4.7665)  Time: 1.893s,  540.88/s  (2.859s,  358.20/s)  LR: 5.473e-05  Data: 1.232 (2.247)
Train: 57 [ 750/1251 ( 60%)]  Loss:  5.231742 (4.7956)  Time: 0.589s, 1738.71/s  (2.865s,  357.44/s)  LR: 5.473e-05  Data: 0.019 (2.252)
Train: 57 [ 800/1251 ( 64%)]  Loss:  4.932944 (4.8037)  Time: 0.587s, 1745.21/s  (2.859s,  358.21/s)  LR: 5.473e-05  Data: 0.020 (2.246)
Train: 57 [ 850/1251 ( 68%)]  Loss:  5.043089 (4.8170)  Time: 0.586s, 1747.08/s  (2.844s,  360.05/s)  LR: 5.473e-05  Data: 0.018 (2.231)
Train: 57 [ 900/1251 ( 72%)]  Loss:  4.734315 (4.8126)  Time: 8.289s,  123.54/s  (2.839s,  360.64/s)  LR: 5.473e-05  Data: 7.711 (2.226)
Train: 57 [ 950/1251 ( 76%)]  Loss:  5.389333 (4.8415)  Time: 0.584s, 1752.93/s  (2.819s,  363.29/s)  LR: 5.473e-05  Data: 0.018 (2.207)
Train: 57 [1000/1251 ( 80%)]  Loss:  4.924008 (4.8454)  Time: 7.674s,  133.44/s  (2.803s,  365.27/s)  LR: 5.473e-05  Data: 6.998 (2.191)
Train: 57 [1050/1251 ( 84%)]  Loss:  4.804249 (4.8435)  Time: 0.588s, 1740.29/s  (2.784s,  367.88/s)  LR: 5.473e-05  Data: 0.023 (2.172)
Train: 57 [1100/1251 ( 88%)]  Loss:  5.251448 (4.8613)  Time: 8.127s,  126.00/s  (2.791s,  366.87/s)  LR: 5.473e-05  Data: 7.548 (2.180)
Train: 57 [1150/1251 ( 92%)]  Loss:  4.868798 (4.8616)  Time: 0.585s, 1749.41/s  (2.783s,  367.94/s)  LR: 5.473e-05  Data: 0.020 (2.172)
Train: 57 [1200/1251 ( 96%)]  Loss:  5.193908 (4.8749)  Time: 7.323s,  139.83/s  (2.781s,  368.20/s)  LR: 5.473e-05  Data: 6.762 (2.170)
Train: 57 [1250/1251 (100%)]  Loss:  4.972651 (4.8786)  Time: 0.566s, 1809.12/s  (2.771s,  369.54/s)  LR: 5.473e-05  Data: 0.000 (2.160)
Test: [   0/48]  Time: 15.694 (15.694)  Loss:  1.2795 (1.2795)  Acc@1: 74.5117 (74.5117)  Acc@5: 90.0391 (90.0391)
Test: [  48/48]  Time: 0.149 (3.557)  Loss:  1.2452 (2.2308)  Acc@1: 73.5849 (52.0780)  Acc@5: 89.5047 (76.5040)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-48.pth.tar', 48.3840000390625)

Train: 58 [   0/1251 (  0%)]  Loss:  5.100570 (5.1006)  Time: 11.473s,   89.26/s  (11.473s,   89.26/s)  LR: 4.546e-05  Data: 10.890 (10.890)
Train: 58 [  50/1251 (  4%)]  Loss:  4.567100 (4.8338)  Time: 0.586s, 1746.25/s  (2.633s,  388.96/s)  LR: 4.546e-05  Data: 0.021 (2.047)
Train: 58 [ 100/1251 (  8%)]  Loss:  4.894032 (4.8539)  Time: 0.589s, 1739.84/s  (2.715s,  377.16/s)  LR: 4.546e-05  Data: 0.020 (2.121)
Train: 58 [ 150/1251 ( 12%)]  Loss:  4.753896 (4.8289)  Time: 0.584s, 1752.44/s  (2.677s,  382.52/s)  LR: 4.546e-05  Data: 0.020 (2.082)
Train: 58 [ 200/1251 ( 16%)]  Loss:  4.693141 (4.8017)  Time: 0.582s, 1760.31/s  (2.696s,  379.82/s)  LR: 4.546e-05  Data: 0.019 (2.106)
Train: 58 [ 250/1251 ( 20%)]  Loss:  4.819595 (4.8047)  Time: 0.614s, 1668.45/s  (2.676s,  382.68/s)  LR: 4.546e-05  Data: 0.020 (2.090)
Train: 58 [ 300/1251 ( 24%)]  Loss:  5.013224 (4.8345)  Time: 0.584s, 1753.34/s  (2.667s,  383.97/s)  LR: 4.546e-05  Data: 0.019 (2.079)
Train: 58 [ 350/1251 ( 28%)]  Loss:  4.665208 (4.8133)  Time: 0.585s, 1750.71/s  (2.639s,  388.05/s)  LR: 4.546e-05  Data: 0.020 (2.048)
Train: 58 [ 400/1251 ( 32%)]  Loss:  5.212834 (4.8577)  Time: 0.585s, 1751.55/s  (2.627s,  389.75/s)  LR: 4.546e-05  Data: 0.022 (2.037)
Train: 58 [ 450/1251 ( 36%)]  Loss:  5.295218 (4.9015)  Time: 0.584s, 1754.73/s  (2.641s,  387.74/s)  LR: 4.546e-05  Data: 0.020 (2.049)
Train: 58 [ 500/1251 ( 40%)]  Loss:  5.201128 (4.9287)  Time: 0.593s, 1726.13/s  (2.654s,  385.79/s)  LR: 4.546e-05  Data: 0.018 (2.062)
Train: 58 [ 550/1251 ( 44%)]  Loss:  5.240852 (4.9547)  Time: 0.585s, 1749.96/s  (2.656s,  385.54/s)  LR: 4.546e-05  Data: 0.023 (2.064)
Train: 58 [ 600/1251 ( 48%)]  Loss:  4.666880 (4.9326)  Time: 0.588s, 1741.68/s  (2.670s,  383.46/s)  LR: 4.546e-05  Data: 0.019 (2.079)
Train: 58 [ 650/1251 ( 52%)]  Loss:  4.919913 (4.9317)  Time: 0.586s, 1747.57/s  (2.669s,  383.72/s)  LR: 4.546e-05  Data: 0.021 (2.078)
Train: 58 [ 700/1251 ( 56%)]  Loss:  4.920528 (4.9309)  Time: 0.584s, 1753.08/s  (2.666s,  384.15/s)  LR: 4.546e-05  Data: 0.018 (2.075)
Train: 58 [ 750/1251 ( 60%)]  Loss:  4.671381 (4.9147)  Time: 0.588s, 1740.56/s  (2.652s,  386.11/s)  LR: 4.546e-05  Data: 0.023 (2.061)
Train: 58 [ 800/1251 ( 64%)]  Loss:  4.878503 (4.9126)  Time: 5.626s,  182.03/s  (2.671s,  383.40/s)  LR: 4.546e-05  Data: 5.045 (2.078)
Train: 58 [ 850/1251 ( 68%)]  Loss:  4.408964 (4.8846)  Time: 0.588s, 1741.70/s  (2.676s,  382.72/s)  LR: 4.546e-05  Data: 0.022 (2.081)
Train: 58 [ 900/1251 ( 72%)]  Loss:  4.380811 (4.8581)  Time: 5.177s,  197.78/s  (2.678s,  382.34/s)  LR: 4.546e-05  Data: 4.615 (2.083)
Train: 58 [ 950/1251 ( 76%)]  Loss:  5.249507 (4.8777)  Time: 0.587s, 1744.57/s  (2.671s,  383.38/s)  LR: 4.546e-05  Data: 0.023 (2.076)
Train: 58 [1000/1251 ( 80%)]  Loss:  4.754787 (4.8718)  Time: 6.265s,  163.46/s  (2.665s,  384.18/s)  LR: 4.546e-05  Data: 5.666 (2.070)
Train: 58 [1050/1251 ( 84%)]  Loss:  4.911530 (4.8736)  Time: 0.587s, 1745.20/s  (2.655s,  385.75/s)  LR: 4.546e-05  Data: 0.024 (2.059)
Train: 58 [1100/1251 ( 88%)]  Loss:  5.106371 (4.8837)  Time: 5.187s,  197.40/s  (2.652s,  386.08/s)  LR: 4.546e-05  Data: 4.544 (2.057)
Train: 58 [1150/1251 ( 92%)]  Loss:  5.219865 (4.8977)  Time: 0.585s, 1750.68/s  (2.658s,  385.31/s)  LR: 4.546e-05  Data: 0.021 (2.063)
Train: 58 [1200/1251 ( 96%)]  Loss:  4.995443 (4.9017)  Time: 2.590s,  395.30/s  (2.656s,  385.59/s)  LR: 4.546e-05  Data: 2.028 (2.060)
Train: 58 [1250/1251 (100%)]  Loss:  4.994508 (4.9052)  Time: 0.566s, 1809.09/s  (2.647s,  386.83/s)  LR: 4.546e-05  Data: 0.000 (2.050)
Test: [   0/48]  Time: 14.889 (14.889)  Loss:  1.2838 (1.2838)  Acc@1: 73.6328 (73.6328)  Acc@5: 90.5273 (90.5273)
Test: [  48/48]  Time: 0.148 (3.420)  Loss:  1.2543 (2.2109)  Acc@1: 74.7642 (52.4860)  Acc@5: 89.2689 (76.9660)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-49.pth.tar', 49.06200003173828)

Train: 59 [   0/1251 (  0%)]  Loss:  4.848430 (4.8484)  Time: 11.488s,   89.14/s  (11.488s,   89.14/s)  LR: 3.722e-05  Data: 10.689 (10.689)
Train: 59 [  50/1251 (  4%)]  Loss:  5.011450 (4.9299)  Time: 0.585s, 1750.79/s  (2.440s,  419.70/s)  LR: 3.722e-05  Data: 0.020 (1.839)
Train: 59 [ 100/1251 (  8%)]  Loss:  4.801119 (4.8870)  Time: 0.585s, 1749.43/s  (2.373s,  431.52/s)  LR: 3.722e-05  Data: 0.020 (1.776)
Train: 59 [ 150/1251 ( 12%)]  Loss:  5.268373 (4.9823)  Time: 0.583s, 1756.79/s  (2.377s,  430.80/s)  LR: 3.722e-05  Data: 0.020 (1.783)
Train: 59 [ 200/1251 ( 16%)]  Loss:  5.184463 (5.0228)  Time: 0.590s, 1736.88/s  (2.441s,  419.51/s)  LR: 3.722e-05  Data: 0.020 (1.849)
Train: 59 [ 250/1251 ( 20%)]  Loss:  4.630241 (4.9573)  Time: 0.960s, 1066.66/s  (2.442s,  419.33/s)  LR: 3.722e-05  Data: 0.359 (1.847)
Train: 59 [ 300/1251 ( 24%)]  Loss:  4.935901 (4.9543)  Time: 1.562s,  655.43/s  (2.432s,  421.13/s)  LR: 3.722e-05  Data: 0.854 (1.830)
Train: 59 [ 350/1251 ( 28%)]  Loss:  4.404218 (4.8855)  Time: 0.583s, 1756.52/s  (2.420s,  423.17/s)  LR: 3.722e-05  Data: 0.020 (1.821)
Train: 59 [ 400/1251 ( 32%)]  Loss:  5.081081 (4.9073)  Time: 4.946s,  207.04/s  (2.396s,  427.39/s)  LR: 3.722e-05  Data: 4.262 (1.794)
Train: 59 [ 450/1251 ( 36%)]  Loss:  4.225162 (4.8390)  Time: 0.586s, 1747.84/s  (2.377s,  430.81/s)  LR: 3.722e-05  Data: 0.020 (1.774)
Train: 59 [ 500/1251 ( 40%)]  Loss:  4.267479 (4.7871)  Time: 2.882s,  355.31/s  (2.363s,  433.38/s)  LR: 3.722e-05  Data: 2.320 (1.760)
Train: 59 [ 550/1251 ( 44%)]  Loss:  4.610987 (4.7724)  Time: 1.560s,  656.43/s  (2.395s,  427.64/s)  LR: 3.722e-05  Data: 0.870 (1.790)
Train: 59 [ 600/1251 ( 48%)]  Loss:  5.112689 (4.7986)  Time: 1.834s,  558.36/s  (2.406s,  425.57/s)  LR: 3.722e-05  Data: 1.182 (1.798)
Train: 59 [ 650/1251 ( 52%)]  Loss:  4.886938 (4.8049)  Time: 2.772s,  369.39/s  (2.425s,  422.26/s)  LR: 3.722e-05  Data: 2.114 (1.816)
Train: 59 [ 700/1251 ( 56%)]  Loss:  4.743049 (4.8008)  Time: 1.358s,  754.02/s  (2.426s,  422.18/s)  LR: 3.722e-05  Data: 0.795 (1.816)
Train: 59 [ 750/1251 ( 60%)]  Loss:  4.075705 (4.7555)  Time: 5.621s,  182.19/s  (2.428s,  421.76/s)  LR: 3.722e-05  Data: 4.976 (1.817)
Train: 59 [ 800/1251 ( 64%)]  Loss:  4.665057 (4.7501)  Time: 0.586s, 1747.45/s  (2.418s,  423.49/s)  LR: 3.722e-05  Data: 0.018 (1.807)
Train: 59 [ 850/1251 ( 68%)]  Loss:  5.014896 (4.7648)  Time: 6.895s,  148.52/s  (2.430s,  421.42/s)  LR: 3.722e-05  Data: 6.194 (1.819)
Train: 59 [ 900/1251 ( 72%)]  Loss:  4.670038 (4.7599)  Time: 0.585s, 1750.60/s  (2.456s,  416.97/s)  LR: 3.722e-05  Data: 0.020 (1.845)
Train: 59 [ 950/1251 ( 76%)]  Loss:  5.030609 (4.7734)  Time: 7.657s,  133.73/s  (2.474s,  413.94/s)  LR: 3.722e-05  Data: 7.072 (1.865)
Train: 59 [1000/1251 ( 80%)]  Loss:  5.015378 (4.7849)  Time: 0.585s, 1751.26/s  (2.476s,  413.55/s)  LR: 3.722e-05  Data: 0.019 (1.868)
Train: 59 [1050/1251 ( 84%)]  Loss:  4.507910 (4.7723)  Time: 6.501s,  157.52/s  (2.490s,  411.17/s)  LR: 3.722e-05  Data: 5.939 (1.882)
Train: 59 [1100/1251 ( 88%)]  Loss:  4.636024 (4.7664)  Time: 0.585s, 1749.84/s  (2.489s,  411.35/s)  LR: 3.722e-05  Data: 0.019 (1.881)
Train: 59 [1150/1251 ( 92%)]  Loss:  4.776478 (4.7668)  Time: 5.651s,  181.22/s  (2.492s,  410.86/s)  LR: 3.722e-05  Data: 5.088 (1.884)
Train: 59 [1200/1251 ( 96%)]  Loss:  4.656737 (4.7624)  Time: 0.584s, 1753.78/s  (2.489s,  411.41/s)  LR: 3.722e-05  Data: 0.018 (1.882)
Train: 59 [1250/1251 (100%)]  Loss:  4.591109 (4.7558)  Time: 0.566s, 1810.66/s  (2.523s,  405.85/s)  LR: 3.722e-05  Data: 0.000 (1.914)
Test: [   0/48]  Time: 21.711 (21.711)  Loss:  1.2956 (1.2956)  Acc@1: 73.6328 (73.6328)  Acc@5: 90.1367 (90.1367)
Test: [  48/48]  Time: 0.149 (5.218)  Loss:  1.2438 (2.2096)  Acc@1: 73.8208 (52.4560)  Acc@5: 89.0330 (77.0960)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-59.pth.tar', 52.45600000488281)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-50.pth.tar', 49.46600003173828)

Train: 60 [   0/1251 (  0%)]  Loss:  4.039206 (4.0392)  Time: 18.861s,   54.29/s  (18.861s,   54.29/s)  LR: 3.005e-05  Data: 15.832 (15.832)
Train: 60 [  50/1251 (  4%)]  Loss:  4.241013 (4.1401)  Time: 0.585s, 1749.80/s  (3.371s,  303.74/s)  LR: 3.005e-05  Data: 0.019 (2.730)
Train: 60 [ 100/1251 (  8%)]  Loss:  4.782849 (4.3544)  Time: 0.587s, 1745.32/s  (3.029s,  338.07/s)  LR: 3.005e-05  Data: 0.018 (2.411)
Train: 60 [ 150/1251 ( 12%)]  Loss:  4.950617 (4.5034)  Time: 0.585s, 1751.78/s  (2.851s,  359.18/s)  LR: 3.005e-05  Data: 0.020 (2.242)
Train: 60 [ 200/1251 ( 16%)]  Loss:  4.342380 (4.4712)  Time: 3.802s,  269.31/s  (2.860s,  357.99/s)  LR: 3.005e-05  Data: 3.190 (2.252)
Train: 60 [ 250/1251 ( 20%)]  Loss:  4.599648 (4.4926)  Time: 0.584s, 1753.52/s  (2.799s,  365.88/s)  LR: 3.005e-05  Data: 0.018 (2.192)
Train: 60 [ 300/1251 ( 24%)]  Loss:  5.033321 (4.5699)  Time: 7.879s,  129.96/s  (2.802s,  365.51/s)  LR: 3.005e-05  Data: 7.237 (2.196)
Train: 60 [ 350/1251 ( 28%)]  Loss:  5.051135 (4.6300)  Time: 0.584s, 1754.82/s  (2.768s,  369.91/s)  LR: 3.005e-05  Data: 0.019 (2.163)
Train: 60 [ 400/1251 ( 32%)]  Loss:  4.521799 (4.6180)  Time: 8.153s,  125.60/s  (2.755s,  371.71/s)  LR: 3.005e-05  Data: 7.579 (2.153)
Train: 60 [ 450/1251 ( 36%)]  Loss:  4.511722 (4.6074)  Time: 0.586s, 1746.65/s  (2.726s,  375.64/s)  LR: 3.005e-05  Data: 0.019 (2.125)
Train: 60 [ 500/1251 ( 40%)]  Loss:  4.541668 (4.6014)  Time: 7.753s,  132.08/s  (2.708s,  378.09/s)  LR: 3.005e-05  Data: 7.139 (2.108)
Train: 60 [ 550/1251 ( 44%)]  Loss:  4.941584 (4.6297)  Time: 0.587s, 1743.48/s  (2.713s,  377.49/s)  LR: 3.005e-05  Data: 0.021 (2.112)
Train: 60 [ 600/1251 ( 48%)]  Loss:  4.782522 (4.6415)  Time: 5.090s,  201.20/s  (2.737s,  374.14/s)  LR: 3.005e-05  Data: 4.306 (2.136)
Train: 60 [ 650/1251 ( 52%)]  Loss:  4.620357 (4.6400)  Time: 0.582s, 1760.94/s  (2.743s,  373.29/s)  LR: 3.005e-05  Data: 0.019 (2.142)
Train: 60 [ 700/1251 ( 56%)]  Loss:  4.748770 (4.6472)  Time: 6.212s,  164.83/s  (2.744s,  373.12/s)  LR: 3.005e-05  Data: 5.377 (2.142)
Train: 60 [ 750/1251 ( 60%)]  Loss:  4.689646 (4.6499)  Time: 0.584s, 1752.57/s  (2.733s,  374.68/s)  LR: 3.005e-05  Data: 0.020 (2.130)
Train: 60 [ 800/1251 ( 64%)]  Loss:  4.601324 (4.6470)  Time: 5.244s,  195.29/s  (2.722s,  376.18/s)  LR: 3.005e-05  Data: 4.660 (2.119)
Train: 60 [ 850/1251 ( 68%)]  Loss:  4.825638 (4.6570)  Time: 0.587s, 1744.69/s  (2.709s,  378.04/s)  LR: 3.005e-05  Data: 0.020 (2.106)
Train: 60 [ 900/1251 ( 72%)]  Loss:  4.744494 (4.6616)  Time: 4.026s,  254.35/s  (2.709s,  378.00/s)  LR: 3.005e-05  Data: 3.464 (2.106)
Train: 60 [ 950/1251 ( 76%)]  Loss:  4.667863 (4.6619)  Time: 0.587s, 1744.75/s  (2.705s,  378.60/s)  LR: 3.005e-05  Data: 0.018 (2.102)
Train: 60 [1000/1251 ( 80%)]  Loss:  4.414052 (4.6501)  Time: 5.204s,  196.76/s  (2.695s,  379.90/s)  LR: 3.005e-05  Data: 4.567 (2.093)
Train: 60 [1050/1251 ( 84%)]  Loss:  4.925168 (4.6626)  Time: 0.586s, 1747.81/s  (2.677s,  382.59/s)  LR: 3.005e-05  Data: 0.018 (2.074)
Train: 60 [1100/1251 ( 88%)]  Loss:  4.937397 (4.6745)  Time: 4.315s,  237.29/s  (2.658s,  385.20/s)  LR: 3.005e-05  Data: 3.753 (2.056)
Train: 60 [1150/1251 ( 92%)]  Loss:  4.446305 (4.6650)  Time: 0.586s, 1747.15/s  (2.637s,  388.34/s)  LR: 3.005e-05  Data: 0.021 (2.035)
Train: 60 [1200/1251 ( 96%)]  Loss:  4.661809 (4.6649)  Time: 4.330s,  236.49/s  (2.617s,  391.23/s)  LR: 3.005e-05  Data: 3.630 (2.016)
Train: 60 [1250/1251 (100%)]  Loss:  4.814399 (4.6706)  Time: 0.566s, 1810.58/s  (2.609s,  392.50/s)  LR: 3.005e-05  Data: 0.000 (2.007)
Test: [   0/48]  Time: 14.895 (14.895)  Loss:  1.2634 (1.2634)  Acc@1: 74.3164 (74.3164)  Acc@5: 90.2344 (90.2344)
Test: [  48/48]  Time: 0.149 (3.392)  Loss:  1.2156 (2.1894)  Acc@1: 74.5283 (52.7320)  Acc@5: 89.5047 (77.2360)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-60.pth.tar', 52.73200005371094)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-59.pth.tar', 52.45600000488281)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-51.pth.tar', 49.86600008056641)

Train: 61 [   0/1251 (  0%)]  Loss:  4.874294 (4.8743)  Time: 11.415s,   89.71/s  (11.415s,   89.71/s)  LR: 2.395e-05  Data: 10.607 (10.607)
Train: 61 [  50/1251 (  4%)]  Loss:  4.677613 (4.7760)  Time: 0.590s, 1736.02/s  (2.576s,  397.51/s)  LR: 2.395e-05  Data: 0.020 (1.959)
Train: 61 [ 100/1251 (  8%)]  Loss:  4.997953 (4.8500)  Time: 0.588s, 1740.85/s  (2.513s,  407.44/s)  LR: 2.395e-05  Data: 0.022 (1.906)
Train: 61 [ 150/1251 ( 12%)]  Loss:  4.699159 (4.8123)  Time: 0.585s, 1749.65/s  (2.416s,  423.76/s)  LR: 2.395e-05  Data: 0.019 (1.813)
Train: 61 [ 200/1251 ( 16%)]  Loss:  5.263494 (4.9025)  Time: 0.584s, 1752.72/s  (2.371s,  431.91/s)  LR: 2.395e-05  Data: 0.019 (1.771)
Train: 61 [ 250/1251 ( 20%)]  Loss:  4.365718 (4.8130)  Time: 0.588s, 1740.70/s  (2.325s,  440.37/s)  LR: 2.395e-05  Data: 0.023 (1.729)
Train: 61 [ 300/1251 ( 24%)]  Loss:  4.861792 (4.8200)  Time: 0.583s, 1755.05/s  (2.308s,  443.61/s)  LR: 2.395e-05  Data: 0.019 (1.714)
Train: 61 [ 350/1251 ( 28%)]  Loss:  4.645911 (4.7982)  Time: 0.586s, 1745.99/s  (2.319s,  441.53/s)  LR: 2.395e-05  Data: 0.020 (1.724)
Train: 61 [ 400/1251 ( 32%)]  Loss:  5.093428 (4.8310)  Time: 0.584s, 1752.13/s  (2.340s,  437.70/s)  LR: 2.395e-05  Data: 0.020 (1.744)
Train: 61 [ 450/1251 ( 36%)]  Loss:  4.282861 (4.7762)  Time: 0.585s, 1751.37/s  (2.325s,  440.46/s)  LR: 2.395e-05  Data: 0.021 (1.729)
Train: 61 [ 500/1251 ( 40%)]  Loss:  4.468977 (4.7483)  Time: 5.420s,  188.93/s  (2.323s,  440.85/s)  LR: 2.395e-05  Data: 4.780 (1.725)
Train: 61 [ 550/1251 ( 44%)]  Loss:  4.897326 (4.7607)  Time: 0.582s, 1759.54/s  (2.309s,  443.48/s)  LR: 2.395e-05  Data: 0.019 (1.710)
Train: 61 [ 600/1251 ( 48%)]  Loss:  4.970550 (4.7769)  Time: 6.314s,  162.19/s  (2.306s,  444.01/s)  LR: 2.395e-05  Data: 5.739 (1.708)
Train: 61 [ 650/1251 ( 52%)]  Loss:  4.521237 (4.7586)  Time: 0.584s, 1753.56/s  (2.294s,  446.44/s)  LR: 2.395e-05  Data: 0.018 (1.696)
Train: 61 [ 700/1251 ( 56%)]  Loss:  4.348059 (4.7312)  Time: 10.285s,   99.57/s  (2.309s,  443.41/s)  LR: 2.395e-05  Data: 9.722 (1.711)
Train: 61 [ 750/1251 ( 60%)]  Loss:  4.836307 (4.7378)  Time: 0.586s, 1747.83/s  (2.305s,  444.29/s)  LR: 2.395e-05  Data: 0.019 (1.707)
Train: 61 [ 800/1251 ( 64%)]  Loss:  5.067918 (4.7572)  Time: 6.926s,  147.86/s  (2.314s,  442.59/s)  LR: 2.395e-05  Data: 6.363 (1.717)
Train: 61 [ 850/1251 ( 68%)]  Loss:  4.628609 (4.7501)  Time: 0.592s, 1730.76/s  (2.312s,  442.93/s)  LR: 2.395e-05  Data: 0.018 (1.714)
Train: 61 [ 900/1251 ( 72%)]  Loss:  5.343081 (4.7813)  Time: 8.161s,  125.48/s  (2.313s,  442.77/s)  LR: 2.395e-05  Data: 7.499 (1.715)
Train: 61 [ 950/1251 ( 76%)]  Loss:  4.821522 (4.7833)  Time: 0.587s, 1743.03/s  (2.304s,  444.39/s)  LR: 2.395e-05  Data: 0.019 (1.707)
Train: 61 [1000/1251 ( 80%)]  Loss:  5.321163 (4.8089)  Time: 7.683s,  133.28/s  (2.302s,  444.76/s)  LR: 2.395e-05  Data: 7.018 (1.706)
Train: 61 [1050/1251 ( 84%)]  Loss:  4.460517 (4.7931)  Time: 0.587s, 1744.44/s  (2.296s,  446.06/s)  LR: 2.395e-05  Data: 0.020 (1.699)
Train: 61 [1100/1251 ( 88%)]  Loss:  4.292460 (4.7713)  Time: 8.783s,  116.59/s  (2.306s,  444.09/s)  LR: 2.395e-05  Data: 8.151 (1.709)
Train: 61 [1150/1251 ( 92%)]  Loss:  4.713539 (4.7689)  Time: 0.584s, 1752.49/s  (2.301s,  445.09/s)  LR: 2.395e-05  Data: 0.020 (1.705)
Train: 61 [1200/1251 ( 96%)]  Loss:  4.546933 (4.7600)  Time: 6.994s,  146.42/s  (2.308s,  443.66/s)  LR: 2.395e-05  Data: 6.401 (1.712)
Train: 61 [1250/1251 (100%)]  Loss:  5.292069 (4.7805)  Time: 0.564s, 1814.14/s  (2.307s,  443.91/s)  LR: 2.395e-05  Data: 0.000 (1.711)
Test: [   0/48]  Time: 14.618 (14.618)  Loss:  1.2574 (1.2574)  Acc@1: 74.5117 (74.5117)  Acc@5: 90.0391 (90.0391)
Test: [  48/48]  Time: 0.148 (3.353)  Loss:  1.2475 (2.1868)  Acc@1: 74.5283 (52.9420)  Acc@5: 89.1509 (77.2400)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-61.pth.tar', 52.942000053710935)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-60.pth.tar', 52.73200005371094)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-59.pth.tar', 52.45600000488281)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-52.pth.tar', 50.65999995605469)

Train: 62 [   0/1251 (  0%)]  Loss:  5.282338 (5.2823)  Time: 10.005s,  102.35/s  (10.005s,  102.35/s)  LR: 1.895e-05  Data: 9.421 (9.421)
Train: 62 [  50/1251 (  4%)]  Loss:  4.907982 (5.0952)  Time: 0.587s, 1745.30/s  (2.360s,  433.87/s)  LR: 1.895e-05  Data: 0.024 (1.783)
Train: 62 [ 100/1251 (  8%)]  Loss:  5.233510 (5.1413)  Time: 0.586s, 1747.08/s  (2.345s,  436.69/s)  LR: 1.895e-05  Data: 0.024 (1.762)
Train: 62 [ 150/1251 ( 12%)]  Loss:  5.195060 (5.1547)  Time: 1.657s,  618.15/s  (2.280s,  449.14/s)  LR: 1.895e-05  Data: 1.093 (1.697)
Train: 62 [ 200/1251 ( 16%)]  Loss:  5.104995 (5.1448)  Time: 0.587s, 1745.22/s  (2.335s,  438.46/s)  LR: 1.895e-05  Data: 0.021 (1.747)
Train: 62 [ 250/1251 ( 20%)]  Loss:  4.559449 (5.0472)  Time: 0.584s, 1753.11/s  (2.341s,  437.50/s)  LR: 1.895e-05  Data: 0.020 (1.753)
Train: 62 [ 300/1251 ( 24%)]  Loss:  5.101053 (5.0549)  Time: 0.586s, 1748.27/s  (2.358s,  434.34/s)  LR: 1.895e-05  Data: 0.020 (1.768)
Train: 62 [ 350/1251 ( 28%)]  Loss:  5.004283 (5.0486)  Time: 0.588s, 1742.30/s  (2.334s,  438.76/s)  LR: 1.895e-05  Data: 0.020 (1.745)
Train: 62 [ 400/1251 ( 32%)]  Loss:  4.757046 (5.0162)  Time: 0.588s, 1742.10/s  (2.332s,  439.04/s)  LR: 1.895e-05  Data: 0.021 (1.744)
Train: 62 [ 450/1251 ( 36%)]  Loss:  5.061954 (5.0208)  Time: 0.584s, 1752.13/s  (2.313s,  442.69/s)  LR: 1.895e-05  Data: 0.022 (1.726)
Train: 62 [ 500/1251 ( 40%)]  Loss:  5.003282 (5.0192)  Time: 0.587s, 1744.45/s  (2.310s,  443.32/s)  LR: 1.895e-05  Data: 0.020 (1.723)
Train: 62 [ 550/1251 ( 44%)]  Loss:  4.610485 (4.9851)  Time: 0.585s, 1750.86/s  (2.310s,  443.30/s)  LR: 1.895e-05  Data: 0.021 (1.724)
Train: 62 [ 600/1251 ( 48%)]  Loss:  4.727198 (4.9653)  Time: 0.594s, 1725.22/s  (2.331s,  439.21/s)  LR: 1.895e-05  Data: 0.020 (1.746)
Train: 62 [ 650/1251 ( 52%)]  Loss:  4.205057 (4.9110)  Time: 0.584s, 1754.54/s  (2.345s,  436.71/s)  LR: 1.895e-05  Data: 0.020 (1.759)
Train: 62 [ 700/1251 ( 56%)]  Loss:  5.035628 (4.9193)  Time: 0.780s, 1312.37/s  (2.361s,  433.66/s)  LR: 1.895e-05  Data: 0.024 (1.775)
Train: 62 [ 750/1251 ( 60%)]  Loss:  4.604735 (4.8996)  Time: 0.587s, 1745.19/s  (2.356s,  434.57/s)  LR: 1.895e-05  Data: 0.021 (1.769)
Train: 62 [ 800/1251 ( 64%)]  Loss:  4.920696 (4.9009)  Time: 0.588s, 1740.68/s  (2.359s,  434.02/s)  LR: 1.895e-05  Data: 0.024 (1.771)
Train: 62 [ 850/1251 ( 68%)]  Loss:  5.193249 (4.9171)  Time: 0.589s, 1738.68/s  (2.351s,  435.55/s)  LR: 1.895e-05  Data: 0.020 (1.763)
Train: 62 [ 900/1251 ( 72%)]  Loss:  4.975009 (4.9202)  Time: 0.583s, 1755.57/s  (2.349s,  435.89/s)  LR: 1.895e-05  Data: 0.021 (1.761)
Train: 62 [ 950/1251 ( 76%)]  Loss:  4.612316 (4.9048)  Time: 0.586s, 1747.82/s  (2.356s,  434.70/s)  LR: 1.895e-05  Data: 0.020 (1.767)
Train: 62 [1000/1251 ( 80%)]  Loss:  4.366898 (4.8792)  Time: 0.584s, 1752.32/s  (2.362s,  433.54/s)  LR: 1.895e-05  Data: 0.021 (1.774)
Train: 62 [1050/1251 ( 84%)]  Loss:  4.739985 (4.8728)  Time: 0.589s, 1739.34/s  (2.357s,  434.41/s)  LR: 1.895e-05  Data: 0.021 (1.769)
Train: 62 [1100/1251 ( 88%)]  Loss:  5.225502 (4.8882)  Time: 0.587s, 1745.58/s  (2.363s,  433.42/s)  LR: 1.895e-05  Data: 0.020 (1.775)
Train: 62 [1150/1251 ( 92%)]  Loss:  5.224949 (4.9022)  Time: 0.587s, 1743.80/s  (2.355s,  434.78/s)  LR: 1.895e-05  Data: 0.021 (1.768)
Train: 62 [1200/1251 ( 96%)]  Loss:  4.805039 (4.8983)  Time: 0.584s, 1752.37/s  (2.353s,  435.20/s)  LR: 1.895e-05  Data: 0.019 (1.765)
Train: 62 [1250/1251 (100%)]  Loss:  5.175193 (4.9090)  Time: 0.565s, 1813.97/s  (2.342s,  437.31/s)  LR: 1.895e-05  Data: 0.000 (1.753)
Test: [   0/48]  Time: 13.110 (13.110)  Loss:  1.2463 (1.2463)  Acc@1: 75.1953 (75.1953)  Acc@5: 90.8203 (90.8203)
Test: [  48/48]  Time: 0.149 (3.331)  Loss:  1.2104 (2.1798)  Acc@1: 75.1179 (53.1380)  Acc@5: 89.7406 (77.4120)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-62.pth.tar', 53.13800005126953)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-61.pth.tar', 52.942000053710935)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-60.pth.tar', 52.73200005371094)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-59.pth.tar', 52.45600000488281)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-53.pth.tar', 50.75400005615234)

Train: 63 [   0/1251 (  0%)]  Loss:  5.129431 (5.1294)  Time: 12.146s,   84.31/s  (12.146s,   84.31/s)  LR: 1.504e-05  Data: 11.260 (11.260)
Train: 63 [  50/1251 (  4%)]  Loss:  5.079151 (5.1043)  Time: 0.585s, 1750.45/s  (2.562s,  399.73/s)  LR: 1.504e-05  Data: 0.022 (1.937)
Train: 63 [ 100/1251 (  8%)]  Loss:  4.865011 (5.0245)  Time: 2.590s,  395.33/s  (2.523s,  405.81/s)  LR: 1.504e-05  Data: 1.888 (1.913)
Train: 63 [ 150/1251 ( 12%)]  Loss:  4.774728 (4.9621)  Time: 0.585s, 1749.85/s  (2.429s,  421.54/s)  LR: 1.504e-05  Data: 0.023 (1.823)
Train: 63 [ 200/1251 ( 16%)]  Loss:  4.408717 (4.8514)  Time: 5.719s,  179.04/s  (2.405s,  425.77/s)  LR: 1.504e-05  Data: 5.157 (1.801)
Train: 63 [ 250/1251 ( 20%)]  Loss:  4.855815 (4.8521)  Time: 0.586s, 1748.50/s  (2.350s,  435.76/s)  LR: 1.504e-05  Data: 0.023 (1.745)
Train: 63 [ 300/1251 ( 24%)]  Loss:  4.177174 (4.7557)  Time: 0.593s, 1725.53/s  (2.330s,  439.50/s)  LR: 1.504e-05  Data: 0.021 (1.726)
Train: 63 [ 350/1251 ( 28%)]  Loss:  5.020247 (4.7888)  Time: 0.584s, 1752.09/s  (2.312s,  443.00/s)  LR: 1.504e-05  Data: 0.023 (1.711)
Train: 63 [ 400/1251 ( 32%)]  Loss:  5.259050 (4.8410)  Time: 0.587s, 1745.02/s  (2.331s,  439.32/s)  LR: 1.504e-05  Data: 0.022 (1.730)
Train: 63 [ 450/1251 ( 36%)]  Loss:  4.452911 (4.8022)  Time: 0.587s, 1743.48/s  (2.340s,  437.68/s)  LR: 1.504e-05  Data: 0.022 (1.736)
Train: 63 [ 500/1251 ( 40%)]  Loss:  4.437242 (4.7690)  Time: 0.586s, 1747.24/s  (2.330s,  439.54/s)  LR: 1.504e-05  Data: 0.021 (1.726)
Train: 63 [ 550/1251 ( 44%)]  Loss:  4.882462 (4.7785)  Time: 0.584s, 1753.38/s  (2.333s,  438.86/s)  LR: 1.504e-05  Data: 0.020 (1.731)
Train: 63 [ 600/1251 ( 48%)]  Loss:  5.158259 (4.8077)  Time: 0.583s, 1755.51/s  (2.326s,  440.28/s)  LR: 1.504e-05  Data: 0.019 (1.724)
Train: 63 [ 650/1251 ( 52%)]  Loss:  4.921940 (4.8159)  Time: 0.585s, 1749.11/s  (2.322s,  441.02/s)  LR: 1.504e-05  Data: 0.022 (1.721)
Train: 63 [ 700/1251 ( 56%)]  Loss:  5.274558 (4.8464)  Time: 0.589s, 1739.77/s  (2.319s,  441.57/s)  LR: 1.504e-05  Data: 0.023 (1.718)
Train: 63 [ 750/1251 ( 60%)]  Loss:  4.619557 (4.8323)  Time: 0.589s, 1738.33/s  (2.314s,  442.43/s)  LR: 1.504e-05  Data: 0.022 (1.715)
Train: 63 [ 800/1251 ( 64%)]  Loss:  4.905196 (4.8366)  Time: 0.586s, 1747.91/s  (2.327s,  440.08/s)  LR: 1.504e-05  Data: 0.023 (1.728)
Train: 63 [ 850/1251 ( 68%)]  Loss:  4.831270 (4.8363)  Time: 0.588s, 1740.83/s  (2.340s,  437.61/s)  LR: 1.504e-05  Data: 0.021 (1.742)
Train: 63 [ 900/1251 ( 72%)]  Loss:  4.508271 (4.8190)  Time: 0.588s, 1740.11/s  (2.337s,  438.17/s)  LR: 1.504e-05  Data: 0.025 (1.740)
Train: 63 [ 950/1251 ( 76%)]  Loss:  4.835920 (4.8198)  Time: 0.586s, 1747.64/s  (2.339s,  437.78/s)  LR: 1.504e-05  Data: 0.018 (1.742)
Train: 63 [1000/1251 ( 80%)]  Loss:  5.131655 (4.8347)  Time: 0.590s, 1736.53/s  (2.337s,  438.17/s)  LR: 1.504e-05  Data: 0.021 (1.738)
Train: 63 [1050/1251 ( 84%)]  Loss:  4.337163 (4.8121)  Time: 0.585s, 1749.51/s  (2.332s,  439.17/s)  LR: 1.504e-05  Data: 0.023 (1.732)
Train: 63 [1100/1251 ( 88%)]  Loss:  4.828797 (4.8128)  Time: 0.591s, 1732.87/s  (2.324s,  440.61/s)  LR: 1.504e-05  Data: 0.022 (1.725)
Train: 63 [1150/1251 ( 92%)]  Loss:  4.073448 (4.7820)  Time: 0.588s, 1741.91/s  (2.330s,  439.52/s)  LR: 1.504e-05  Data: 0.021 (1.730)
Train: 63 [1200/1251 ( 96%)]  Loss:  4.501976 (4.7708)  Time: 0.587s, 1743.27/s  (2.330s,  439.58/s)  LR: 1.504e-05  Data: 0.024 (1.731)
Train: 63 [1250/1251 (100%)]  Loss:  5.092362 (4.7832)  Time: 0.565s, 1812.24/s  (2.341s,  437.41/s)  LR: 1.504e-05  Data: 0.000 (1.743)
Test: [   0/48]  Time: 15.472 (15.472)  Loss:  1.2481 (1.2481)  Acc@1: 75.1953 (75.1953)  Acc@5: 91.0156 (91.0156)
Test: [  48/48]  Time: 0.149 (3.482)  Loss:  1.2301 (2.1776)  Acc@1: 74.6462 (53.1000)  Acc@5: 89.9764 (77.4700)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-62.pth.tar', 53.13800005126953)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-63.pth.tar', 53.10000010498047)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-61.pth.tar', 52.942000053710935)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-60.pth.tar', 52.73200005371094)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-59.pth.tar', 52.45600000488281)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-54.pth.tar', 51.12200005859375)

Train: 64 [   0/1251 (  0%)]  Loss:  4.500179 (4.5002)  Time: 12.258s,   83.54/s  (12.258s,   83.54/s)  LR: 1.224e-05  Data: 10.996 (10.996)
Train: 64 [  50/1251 (  4%)]  Loss:  4.847847 (4.6740)  Time: 0.591s, 1733.39/s  (2.446s,  418.59/s)  LR: 1.224e-05  Data: 0.019 (1.846)
Train: 64 [ 100/1251 (  8%)]  Loss:  4.641222 (4.6631)  Time: 4.269s,  239.89/s  (2.378s,  430.53/s)  LR: 1.224e-05  Data: 3.703 (1.774)
Train: 64 [ 150/1251 ( 12%)]  Loss:  5.247450 (4.8092)  Time: 0.590s, 1736.91/s  (2.289s,  447.35/s)  LR: 1.224e-05  Data: 0.018 (1.686)
Train: 64 [ 200/1251 ( 16%)]  Loss:  5.228550 (4.8930)  Time: 5.049s,  202.81/s  (2.335s,  438.55/s)  LR: 1.224e-05  Data: 4.486 (1.732)
Train: 64 [ 250/1251 ( 20%)]  Loss:  4.742028 (4.8679)  Time: 0.590s, 1735.18/s  (2.327s,  439.96/s)  LR: 1.224e-05  Data: 0.019 (1.724)
Train: 64 [ 300/1251 ( 24%)]  Loss:  4.503001 (4.8158)  Time: 3.293s,  310.97/s  (2.348s,  436.18/s)  LR: 1.224e-05  Data: 2.618 (1.743)
Train: 64 [ 350/1251 ( 28%)]  Loss:  5.135753 (4.8558)  Time: 0.587s, 1744.64/s  (2.344s,  436.82/s)  LR: 1.224e-05  Data: 0.021 (1.741)
Train: 64 [ 400/1251 ( 32%)]  Loss:  4.676169 (4.8358)  Time: 5.132s,  199.54/s  (2.353s,  435.13/s)  LR: 1.224e-05  Data: 4.469 (1.749)
Train: 64 [ 450/1251 ( 36%)]  Loss:  4.234871 (4.7757)  Time: 0.589s, 1738.00/s  (2.338s,  438.03/s)  LR: 1.224e-05  Data: 0.019 (1.733)
Train: 64 [ 500/1251 ( 40%)]  Loss:  4.699150 (4.7687)  Time: 4.821s,  212.39/s  (2.333s,  438.86/s)  LR: 1.224e-05  Data: 4.243 (1.728)
Train: 64 [ 550/1251 ( 44%)]  Loss:  4.877654 (4.7778)  Time: 0.587s, 1743.49/s  (2.307s,  443.90/s)  LR: 1.224e-05  Data: 0.024 (1.701)
Train: 64 [ 600/1251 ( 48%)]  Loss:  4.972769 (4.7928)  Time: 0.588s, 1741.39/s  (2.322s,  440.96/s)  LR: 1.224e-05  Data: 0.022 (1.717)
Train: 64 [ 650/1251 ( 52%)]  Loss:  4.648642 (4.7825)  Time: 0.589s, 1738.80/s  (2.324s,  440.59/s)  LR: 1.224e-05  Data: 0.024 (1.720)
Train: 64 [ 700/1251 ( 56%)]  Loss:  4.833650 (4.7859)  Time: 0.584s, 1753.42/s  (2.341s,  437.42/s)  LR: 1.224e-05  Data: 0.020 (1.737)
Train: 64 [ 750/1251 ( 60%)]  Loss:  4.785301 (4.7859)  Time: 1.511s,  677.90/s  (2.344s,  436.85/s)  LR: 1.224e-05  Data: 0.948 (1.741)
Train: 64 [ 800/1251 ( 64%)]  Loss:  5.193274 (4.8099)  Time: 0.587s, 1744.56/s  (2.344s,  436.84/s)  LR: 1.224e-05  Data: 0.020 (1.741)
Train: 64 [ 850/1251 ( 68%)]  Loss:  4.790947 (4.8088)  Time: 1.421s,  720.76/s  (2.337s,  438.15/s)  LR: 1.224e-05  Data: 0.730 (1.734)
Train: 64 [ 900/1251 ( 72%)]  Loss:  4.256716 (4.7797)  Time: 0.587s, 1744.20/s  (2.335s,  438.48/s)  LR: 1.224e-05  Data: 0.020 (1.729)
Train: 64 [ 950/1251 ( 76%)]  Loss:  4.595746 (4.7705)  Time: 2.975s,  344.19/s  (2.326s,  440.21/s)  LR: 1.224e-05  Data: 2.403 (1.720)
Train: 64 [1000/1251 ( 80%)]  Loss:  5.000333 (4.7815)  Time: 1.565s,  654.42/s  (2.336s,  438.30/s)  LR: 1.224e-05  Data: 1.003 (1.729)
Train: 64 [1050/1251 ( 84%)]  Loss:  4.313738 (4.7602)  Time: 0.593s, 1727.42/s  (2.336s,  438.39/s)  LR: 1.224e-05  Data: 0.024 (1.728)
Train: 64 [1100/1251 ( 88%)]  Loss:  4.702464 (4.7577)  Time: 0.589s, 1739.31/s  (2.335s,  438.64/s)  LR: 1.224e-05  Data: 0.022 (1.727)
Train: 64 [1150/1251 ( 92%)]  Loss:  4.661844 (4.7537)  Time: 0.588s, 1742.44/s  (2.334s,  438.79/s)  LR: 1.224e-05  Data: 0.022 (1.727)
Train: 64 [1200/1251 ( 96%)]  Loss:  5.052198 (4.7657)  Time: 0.586s, 1746.30/s  (2.332s,  439.10/s)  LR: 1.224e-05  Data: 0.019 (1.726)
Train: 64 [1250/1251 (100%)]  Loss:  5.223108 (4.7833)  Time: 0.565s, 1810.95/s  (2.327s,  439.96/s)  LR: 1.224e-05  Data: 0.000 (1.721)
Test: [   0/48]  Time: 14.228 (14.228)  Loss:  1.2368 (1.2368)  Acc@1: 75.3906 (75.3906)  Acc@5: 91.1133 (91.1133)
Test: [  48/48]  Time: 0.148 (3.204)  Loss:  1.2268 (2.1747)  Acc@1: 74.7642 (53.1580)  Acc@5: 89.9764 (77.5800)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-64.pth.tar', 53.15800002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-62.pth.tar', 53.13800005126953)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-63.pth.tar', 53.10000010498047)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-61.pth.tar', 52.942000053710935)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-60.pth.tar', 52.73200005371094)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-59.pth.tar', 52.45600000488281)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-55.pth.tar', 51.72200010742188)

Train: 65 [   0/1251 (  0%)]  Loss:  5.216846 (5.2168)  Time: 9.704s,  105.53/s  (9.704s,  105.53/s)  LR: 1.056e-05  Data: 9.122 (9.122)
Train: 65 [  50/1251 (  4%)]  Loss:  4.875539 (5.0462)  Time: 0.584s, 1754.22/s  (2.536s,  403.84/s)  LR: 1.056e-05  Data: 0.019 (1.939)
Train: 65 [ 100/1251 (  8%)]  Loss:  4.862194 (4.9849)  Time: 4.565s,  224.32/s  (2.468s,  414.97/s)  LR: 1.056e-05  Data: 3.857 (1.868)
Train: 65 [ 150/1251 ( 12%)]  Loss:  4.835772 (4.9476)  Time: 0.587s, 1745.26/s  (2.397s,  427.20/s)  LR: 1.056e-05  Data: 0.022 (1.796)
Train: 65 [ 200/1251 ( 16%)]  Loss:  4.465994 (4.8513)  Time: 7.158s,  143.05/s  (2.393s,  427.88/s)  LR: 1.056e-05  Data: 6.463 (1.795)
Train: 65 [ 250/1251 ( 20%)]  Loss:  4.836965 (4.8489)  Time: 0.585s, 1751.25/s  (2.360s,  433.92/s)  LR: 1.056e-05  Data: 0.021 (1.764)
Train: 65 [ 300/1251 ( 24%)]  Loss:  4.762888 (4.8366)  Time: 6.949s,  147.36/s  (2.343s,  437.00/s)  LR: 1.056e-05  Data: 6.274 (1.748)
Train: 65 [ 350/1251 ( 28%)]  Loss:  4.761958 (4.8273)  Time: 0.585s, 1749.10/s  (2.317s,  441.87/s)  LR: 1.056e-05  Data: 0.020 (1.723)
Train: 65 [ 400/1251 ( 32%)]  Loss:  4.964254 (4.8425)  Time: 6.846s,  149.57/s  (2.308s,  443.68/s)  LR: 1.056e-05  Data: 6.191 (1.715)
Train: 65 [ 450/1251 ( 36%)]  Loss:  5.017373 (4.8600)  Time: 0.584s, 1753.31/s  (2.352s,  435.44/s)  LR: 1.056e-05  Data: 0.019 (1.760)
Train: 65 [ 500/1251 ( 40%)]  Loss:  4.525370 (4.8296)  Time: 8.871s,  115.44/s  (2.381s,  430.06/s)  LR: 1.056e-05  Data: 8.202 (1.791)
Train: 65 [ 550/1251 ( 44%)]  Loss:  4.821789 (4.8289)  Time: 0.585s, 1750.26/s  (2.396s,  427.35/s)  LR: 1.056e-05  Data: 0.023 (1.806)
Train: 65 [ 600/1251 ( 48%)]  Loss:  5.236170 (4.8602)  Time: 8.094s,  126.51/s  (2.416s,  423.87/s)  LR: 1.056e-05  Data: 7.400 (1.824)
Train: 65 [ 650/1251 ( 52%)]  Loss:  4.360141 (4.8245)  Time: 1.747s,  586.24/s  (2.426s,  422.01/s)  LR: 1.056e-05  Data: 1.074 (1.833)
Train: 65 [ 700/1251 ( 56%)]  Loss:  4.559805 (4.8069)  Time: 6.300s,  162.54/s  (2.438s,  420.05/s)  LR: 1.056e-05  Data: 5.714 (1.844)
Train: 65 [ 750/1251 ( 60%)]  Loss:  4.780319 (4.8052)  Time: 0.587s, 1745.45/s  (2.435s,  420.48/s)  LR: 1.056e-05  Data: 0.022 (1.841)
Train: 65 [ 800/1251 ( 64%)]  Loss:  5.118174 (4.8236)  Time: 3.779s,  271.00/s  (2.460s,  416.26/s)  LR: 1.056e-05  Data: 3.157 (1.866)
Train: 65 [ 850/1251 ( 68%)]  Loss:  4.135642 (4.7854)  Time: 0.587s, 1744.66/s  (2.470s,  414.66/s)  LR: 1.056e-05  Data: 0.020 (1.874)
Train: 65 [ 900/1251 ( 72%)]  Loss:  4.174580 (4.7533)  Time: 2.200s,  465.42/s  (2.476s,  413.55/s)  LR: 1.056e-05  Data: 1.638 (1.880)
Train: 65 [ 950/1251 ( 76%)]  Loss:  4.716355 (4.7514)  Time: 0.587s, 1744.46/s  (2.480s,  412.85/s)  LR: 1.056e-05  Data: 0.023 (1.884)
Train: 65 [1000/1251 ( 80%)]  Loss:  5.086025 (4.7673)  Time: 2.634s,  388.80/s  (2.478s,  413.26/s)  LR: 1.056e-05  Data: 2.058 (1.880)
Train: 65 [1050/1251 ( 84%)]  Loss:  4.952738 (4.7758)  Time: 0.591s, 1732.84/s  (2.476s,  413.56/s)  LR: 1.056e-05  Data: 0.025 (1.878)
Train: 65 [1100/1251 ( 88%)]  Loss:  4.785163 (4.7762)  Time: 1.751s,  584.93/s  (2.467s,  415.10/s)  LR: 1.056e-05  Data: 1.105 (1.869)
Train: 65 [1150/1251 ( 92%)]  Loss:  4.921815 (4.7822)  Time: 0.585s, 1749.39/s  (2.480s,  412.88/s)  LR: 1.056e-05  Data: 0.018 (1.882)
Train: 65 [1200/1251 ( 96%)]  Loss:  5.013994 (4.7915)  Time: 1.032s,  992.41/s  (2.485s,  412.11/s)  LR: 1.056e-05  Data: 0.338 (1.887)
Train: 65 [1250/1251 (100%)]  Loss:  4.895820 (4.7955)  Time: 0.565s, 1812.44/s  (2.490s,  411.17/s)  LR: 1.056e-05  Data: 0.000 (1.892)
Test: [   0/48]  Time: 15.932 (15.932)  Loss:  1.2556 (1.2556)  Acc@1: 75.0000 (75.0000)  Acc@5: 90.6250 (90.6250)
Test: [  48/48]  Time: 0.149 (3.527)  Loss:  1.2195 (2.1704)  Acc@1: 75.2358 (53.2620)  Acc@5: 90.2123 (77.6060)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-65.pth.tar', 53.26199997314453)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-64.pth.tar', 53.15800002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-62.pth.tar', 53.13800005126953)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-63.pth.tar', 53.10000010498047)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-61.pth.tar', 52.942000053710935)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-60.pth.tar', 52.73200005371094)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-58.pth.tar', 52.48600002685547)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-59.pth.tar', 52.45600000488281)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-57.pth.tar', 52.078000031738284)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-56.pth.tar', 51.73600005615234)

*** Best metric: 53.26199997314453 (epoch 65)

wandb: Waiting for W&B process to finish, PID 52593
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210525_140351-PreTraining_vit_deit_tiny_patch16_224_1k/logs/debug.log
wandb: Find internal logs for this run at: /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210525_140351-PreTraining_vit_deit_tiny_patch16_224_1k/logs/debug-internal.log
wandb: Run summary:
wandb:    eval_top1 53.262
wandb:    eval_top5 77.606
wandb:   _timestamp 1621994919
wandb:   train_loss 4.79553
wandb:        _step 65
wandb:        epoch 65
wandb:     _runtime 224134
wandb:    eval_loss 2.17042
wandb: Run history:
wandb:        epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   train_loss ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ
wandb:    eval_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    eval_top1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    eval_top5 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     _runtime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   _timestamp ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:        _step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced PreTraining_vit_deit_tiny_patch16_224_1k: https://wandb.ai/gyama_x/pytorch-image-models/runs/PreTraining_vit_deit_tiny_patch16_224_1k
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
--End--
Wed May 26 11:08:50 JST 2021
