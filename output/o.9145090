--Start--
Sun May 23 17:34:19 JST 2021
Added key: store_based_barrier_key:1 to store for rank: 0
Added key: store_based_barrier_key:1 to store for rank: 2
Added key: store_based_barrier_key:1 to store for rank: 1
Added key: store_based_barrier_key:1 to store for rank: 3
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
wandb: Currently logged in as: gyama_x (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.10.30 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.27
wandb: Syncing run PreTraining_vit_deit_tiny_patch16_224_1k
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gyama_x/pytorch-image-models
wandb: üöÄ View run at https://wandb.ai/gyama_x/pytorch-image-models/runs/PreTraining_vit_deit_tiny_patch16_224_1k
wandb: Run data is saved locally in /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210523_173510-PreTraining_vit_deit_tiny_patch16_224_1k
wandb: Run `wandb offline` to turn off syncing.

Model vit_deit_tiny_patch16_224 created, param count:5717416
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.9
AMP not enabled. Training in float32.
Using native Torch DistributedDataParallel.
Scheduled epochs: 22
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/gs/hs0/tga-i/sugiyama.y.al/TIMM/TIMM_386/lib/python3.8/site-packages/torchvision/transforms/functional.py:364: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Train: 0 [   0/1251 (  0%)]  Loss:  6.944414 (6.9444)  Time: 14.937s,   68.56/s  (14.937s,   68.56/s)  LR: 1.000e-04  Data: 12.947 (12.947)
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Reducer buckets have been rebuilt in this iteration.
Train: 0 [  50/1251 (  4%)]  Loss:  6.920884 (6.9326)  Time: 0.587s, 1743.48/s  (2.308s,  443.69/s)  LR: 1.000e-04  Data: 0.023 (1.683)
Train: 0 [ 100/1251 (  8%)]  Loss:  6.913058 (6.9261)  Time: 6.058s,  169.03/s  (2.237s,  457.69/s)  LR: 1.000e-04  Data: 5.475 (1.629)
Train: 0 [ 150/1251 ( 12%)]  Loss:  6.879448 (6.9145)  Time: 0.585s, 1751.84/s  (2.278s,  449.54/s)  LR: 1.000e-04  Data: 0.020 (1.676)
Train: 0 [ 200/1251 ( 16%)]  Loss:  6.868503 (6.9053)  Time: 5.199s,  196.95/s  (2.293s,  446.51/s)  LR: 1.000e-04  Data: 4.637 (1.689)
Train: 0 [ 250/1251 ( 20%)]  Loss:  6.852562 (6.8965)  Time: 0.585s, 1750.65/s  (2.343s,  436.99/s)  LR: 1.000e-04  Data: 0.019 (1.738)
Train: 0 [ 300/1251 ( 24%)]  Loss:  6.884165 (6.8947)  Time: 7.725s,  132.55/s  (2.355s,  434.87/s)  LR: 1.000e-04  Data: 7.139 (1.751)
Train: 0 [ 350/1251 ( 28%)]  Loss:  6.822980 (6.8858)  Time: 0.585s, 1750.59/s  (2.351s,  435.64/s)  LR: 1.000e-04  Data: 0.021 (1.747)
Train: 0 [ 400/1251 ( 32%)]  Loss:  6.863301 (6.8833)  Time: 6.878s,  148.89/s  (2.356s,  434.72/s)  LR: 1.000e-04  Data: 6.315 (1.754)
Train: 0 [ 450/1251 ( 36%)]  Loss:  6.828917 (6.8778)  Time: 1.712s,  598.01/s  (2.323s,  440.72/s)  LR: 1.000e-04  Data: 1.138 (1.721)
Train: 0 [ 500/1251 ( 40%)]  Loss:  6.840716 (6.8744)  Time: 7.061s,  145.03/s  (2.314s,  442.59/s)  LR: 1.000e-04  Data: 5.960 (1.712)
Train: 0 [ 550/1251 ( 44%)]  Loss:  6.834620 (6.8711)  Time: 0.585s, 1750.71/s  (2.277s,  449.67/s)  LR: 1.000e-04  Data: 0.022 (1.677)
Train: 0 [ 600/1251 ( 48%)]  Loss:  6.827368 (6.8678)  Time: 2.658s,  385.20/s  (2.244s,  456.43/s)  LR: 1.000e-04  Data: 2.004 (1.642)
Train: 0 [ 650/1251 ( 52%)]  Loss:  6.802267 (6.8631)  Time: 10.702s,   95.68/s  (2.259s,  453.38/s)  LR: 1.000e-04  Data: 10.062 (1.657)
Train: 0 [ 700/1251 ( 56%)]  Loss:  6.816810 (6.8600)  Time: 0.585s, 1749.86/s  (2.244s,  456.35/s)  LR: 1.000e-04  Data: 0.021 (1.644)
Train: 0 [ 750/1251 ( 60%)]  Loss:  6.840503 (6.8588)  Time: 4.933s,  207.58/s  (2.233s,  458.51/s)  LR: 1.000e-04  Data: 4.342 (1.633)
Train: 0 [ 800/1251 ( 64%)]  Loss:  6.776931 (6.8540)  Time: 1.591s,  643.56/s  (2.219s,  461.54/s)  LR: 1.000e-04  Data: 0.977 (1.620)
Train: 0 [ 850/1251 ( 68%)]  Loss:  6.794033 (6.8506)  Time: 6.030s,  169.83/s  (2.227s,  459.86/s)  LR: 1.000e-04  Data: 5.458 (1.628)
Train: 0 [ 900/1251 ( 72%)]  Loss:  6.770448 (6.8464)  Time: 1.898s,  539.52/s  (2.219s,  461.51/s)  LR: 1.000e-04  Data: 1.333 (1.621)
Train: 0 [ 950/1251 ( 76%)]  Loss:  6.778907 (6.8430)  Time: 5.087s,  201.28/s  (2.210s,  463.31/s)  LR: 1.000e-04  Data: 4.524 (1.612)
Train: 0 [1000/1251 ( 80%)]  Loss:  6.714164 (6.8369)  Time: 0.633s, 1617.32/s  (2.202s,  465.03/s)  LR: 1.000e-04  Data: 0.021 (1.603)
Train: 0 [1050/1251 ( 84%)]  Loss:  6.749368 (6.8329)  Time: 6.743s,  151.87/s  (2.198s,  465.90/s)  LR: 1.000e-04  Data: 6.154 (1.599)
Train: 0 [1100/1251 ( 88%)]  Loss:  6.759338 (6.8297)  Time: 1.933s,  529.68/s  (2.215s,  462.30/s)  LR: 1.000e-04  Data: 1.371 (1.616)
Train: 0 [1150/1251 ( 92%)]  Loss:  6.704941 (6.8245)  Time: 3.062s,  334.45/s  (2.209s,  463.47/s)  LR: 1.000e-04  Data: 2.400 (1.610)
Train: 0 [1200/1251 ( 96%)]  Loss:  6.705028 (6.8197)  Time: 6.168s,  166.01/s  (2.212s,  462.90/s)  LR: 1.000e-04  Data: 5.590 (1.613)
Train: 0 [1250/1251 (100%)]  Loss:  6.727532 (6.8162)  Time: 0.565s, 1811.54/s  (2.208s,  463.75/s)  LR: 1.000e-04  Data: 0.000 (1.609)
Test: [   0/48]  Time: 15.362 (15.362)  Loss:  6.2181 (6.2181)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 13.0859 (13.0859)
Test: [  48/48]  Time: 0.710 (3.095)  Loss:  5.9217 (6.4621)  Acc@1: 10.7311 ( 1.5380)  Acc@5: 21.6981 ( 5.4960)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 1 [   0/1251 (  0%)]  Loss:  6.721529 (6.7215)  Time: 10.458s,   97.91/s  (10.458s,   97.91/s)  LR: 2.800e-04  Data: 9.204 (9.204)
Train: 1 [  50/1251 (  4%)]  Loss:  6.726264 (6.7239)  Time: 0.586s, 1747.23/s  (2.199s,  465.69/s)  LR: 2.800e-04  Data: 0.021 (1.610)
Train: 1 [ 100/1251 (  8%)]  Loss:  6.765039 (6.7376)  Time: 0.589s, 1737.17/s  (2.125s,  481.78/s)  LR: 2.800e-04  Data: 0.022 (1.533)
Train: 1 [ 150/1251 ( 12%)]  Loss:  6.621287 (6.7085)  Time: 0.584s, 1754.11/s  (2.113s,  484.68/s)  LR: 2.800e-04  Data: 0.021 (1.522)
Train: 1 [ 200/1251 ( 16%)]  Loss:  6.694843 (6.7058)  Time: 0.585s, 1749.92/s  (2.198s,  465.78/s)  LR: 2.800e-04  Data: 0.021 (1.610)
Train: 1 [ 250/1251 ( 20%)]  Loss:  6.642270 (6.6952)  Time: 0.590s, 1736.93/s  (2.161s,  473.83/s)  LR: 2.800e-04  Data: 0.021 (1.573)
Train: 1 [ 300/1251 ( 24%)]  Loss:  6.757695 (6.7041)  Time: 1.554s,  658.91/s  (2.166s,  472.67/s)  LR: 2.800e-04  Data: 0.971 (1.577)
Train: 1 [ 350/1251 ( 28%)]  Loss:  6.695505 (6.7031)  Time: 0.591s, 1733.57/s  (2.166s,  472.68/s)  LR: 2.800e-04  Data: 0.020 (1.576)
Train: 1 [ 400/1251 ( 32%)]  Loss:  6.686914 (6.7013)  Time: 3.665s,  279.40/s  (2.165s,  472.90/s)  LR: 2.800e-04  Data: 2.982 (1.574)
Train: 1 [ 450/1251 ( 36%)]  Loss:  6.683226 (6.6995)  Time: 0.997s, 1027.39/s  (2.153s,  475.66/s)  LR: 2.800e-04  Data: 0.360 (1.561)
Train: 1 [ 500/1251 ( 40%)]  Loss:  6.634186 (6.6935)  Time: 3.003s,  341.04/s  (2.150s,  476.37/s)  LR: 2.800e-04  Data: 2.440 (1.555)
Train: 1 [ 550/1251 ( 44%)]  Loss:  6.649599 (6.6899)  Time: 3.063s,  334.30/s  (2.145s,  477.39/s)  LR: 2.800e-04  Data: 2.468 (1.550)
Train: 1 [ 600/1251 ( 48%)]  Loss:  6.610190 (6.6837)  Time: 6.626s,  154.54/s  (2.186s,  468.45/s)  LR: 2.800e-04  Data: 6.041 (1.590)
Train: 1 [ 650/1251 ( 52%)]  Loss:  6.690987 (6.6843)  Time: 0.584s, 1753.14/s  (2.178s,  470.15/s)  LR: 2.800e-04  Data: 0.021 (1.583)
Train: 1 [ 700/1251 ( 56%)]  Loss:  6.572745 (6.6768)  Time: 0.587s, 1744.88/s  (2.172s,  471.43/s)  LR: 2.800e-04  Data: 0.024 (1.576)
Train: 1 [ 750/1251 ( 60%)]  Loss:  6.678872 (6.6769)  Time: 0.587s, 1744.22/s  (2.163s,  473.48/s)  LR: 2.800e-04  Data: 0.021 (1.567)
Train: 1 [ 800/1251 ( 64%)]  Loss:  6.706188 (6.6787)  Time: 0.593s, 1728.04/s  (2.159s,  474.20/s)  LR: 2.800e-04  Data: 0.024 (1.564)
Train: 1 [ 850/1251 ( 68%)]  Loss:  6.616570 (6.6752)  Time: 0.589s, 1738.00/s  (2.154s,  475.39/s)  LR: 2.800e-04  Data: 0.019 (1.557)
Train: 1 [ 900/1251 ( 72%)]  Loss:  6.665788 (6.6747)  Time: 1.551s,  660.38/s  (2.146s,  477.21/s)  LR: 2.800e-04  Data: 0.886 (1.548)
Train: 1 [ 950/1251 ( 76%)]  Loss:  6.530112 (6.6675)  Time: 0.587s, 1744.71/s  (2.139s,  478.66/s)  LR: 2.800e-04  Data: 0.022 (1.541)
Train: 1 [1000/1251 ( 80%)]  Loss:  6.585029 (6.6636)  Time: 0.809s, 1265.52/s  (2.155s,  475.23/s)  LR: 2.800e-04  Data: 0.027 (1.557)
Train: 1 [1050/1251 ( 84%)]  Loss:  6.685616 (6.6646)  Time: 0.583s, 1756.29/s  (2.157s,  474.71/s)  LR: 2.800e-04  Data: 0.021 (1.559)
Train: 1 [1100/1251 ( 88%)]  Loss:  6.619479 (6.6626)  Time: 0.585s, 1749.80/s  (2.159s,  474.22/s)  LR: 2.800e-04  Data: 0.021 (1.561)
Train: 1 [1150/1251 ( 92%)]  Loss:  6.635402 (6.6615)  Time: 0.584s, 1752.22/s  (2.151s,  476.06/s)  LR: 2.800e-04  Data: 0.021 (1.554)
Train: 1 [1200/1251 ( 96%)]  Loss:  6.579769 (6.6582)  Time: 0.586s, 1746.42/s  (2.154s,  475.35/s)  LR: 2.800e-04  Data: 0.022 (1.558)
Train: 1 [1250/1251 (100%)]  Loss:  6.610530 (6.6564)  Time: 0.564s, 1815.97/s  (2.152s,  475.79/s)  LR: 2.800e-04  Data: 0.000 (1.557)
Test: [   0/48]  Time: 12.488 (12.488)  Loss:  5.6718 (5.6718)  Acc@1:  2.7344 ( 2.7344)  Acc@5: 18.9453 (18.9453)
Test: [  48/48]  Time: 0.148 (2.941)  Loss:  5.0793 (5.9655)  Acc@1: 24.8821 ( 3.9840)  Acc@5: 40.0943 (12.4000)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 2 [   0/1251 (  0%)]  Loss:  6.658639 (6.6586)  Time: 10.133s,  101.05/s  (10.133s,  101.05/s)  LR: 4.600e-04  Data: 9.220 (9.220)
Train: 2 [  50/1251 (  4%)]  Loss:  6.535439 (6.5970)  Time: 0.594s, 1723.80/s  (2.166s,  472.83/s)  LR: 4.600e-04  Data: 0.028 (1.577)
Train: 2 [ 100/1251 (  8%)]  Loss:  6.421467 (6.5385)  Time: 0.588s, 1742.35/s  (2.345s,  436.72/s)  LR: 4.600e-04  Data: 0.021 (1.752)
Train: 2 [ 150/1251 ( 12%)]  Loss:  6.658110 (6.5684)  Time: 0.588s, 1740.77/s  (2.218s,  461.61/s)  LR: 4.600e-04  Data: 0.025 (1.623)
Train: 2 [ 200/1251 ( 16%)]  Loss:  6.643252 (6.5834)  Time: 0.585s, 1751.29/s  (2.166s,  472.72/s)  LR: 4.600e-04  Data: 0.021 (1.570)
Train: 2 [ 250/1251 ( 20%)]  Loss:  6.644582 (6.5936)  Time: 1.945s,  526.49/s  (2.130s,  480.79/s)  LR: 4.600e-04  Data: 1.357 (1.536)
Train: 2 [ 300/1251 ( 24%)]  Loss:  6.620748 (6.5975)  Time: 0.588s, 1741.39/s  (2.157s,  474.77/s)  LR: 4.600e-04  Data: 0.020 (1.562)
Train: 2 [ 350/1251 ( 28%)]  Loss:  6.594239 (6.5971)  Time: 0.589s, 1739.70/s  (2.131s,  480.62/s)  LR: 4.600e-04  Data: 0.023 (1.537)
Train: 2 [ 400/1251 ( 32%)]  Loss:  6.587997 (6.5961)  Time: 0.587s, 1743.25/s  (2.131s,  480.44/s)  LR: 4.600e-04  Data: 0.022 (1.540)
Train: 2 [ 450/1251 ( 36%)]  Loss:  6.508197 (6.5873)  Time: 0.587s, 1745.35/s  (2.130s,  480.70/s)  LR: 4.600e-04  Data: 0.021 (1.537)
Train: 2 [ 500/1251 ( 40%)]  Loss:  6.479364 (6.5775)  Time: 1.365s,  750.23/s  (2.165s,  473.02/s)  LR: 4.600e-04  Data: 0.546 (1.570)
Train: 2 [ 550/1251 ( 44%)]  Loss:  6.429858 (6.5652)  Time: 0.587s, 1745.33/s  (2.191s,  467.33/s)  LR: 4.600e-04  Data: 0.020 (1.592)
Train: 2 [ 600/1251 ( 48%)]  Loss:  6.343335 (6.5481)  Time: 3.357s,  305.03/s  (2.206s,  464.27/s)  LR: 4.600e-04  Data: 2.630 (1.606)
Train: 2 [ 650/1251 ( 52%)]  Loss:  6.358453 (6.5345)  Time: 0.588s, 1740.96/s  (2.230s,  459.23/s)  LR: 4.600e-04  Data: 0.023 (1.630)
Train: 2 [ 700/1251 ( 56%)]  Loss:  6.389452 (6.5249)  Time: 0.600s, 1705.33/s  (2.249s,  455.24/s)  LR: 4.600e-04  Data: 0.018 (1.647)
Train: 2 [ 750/1251 ( 60%)]  Loss:  6.637330 (6.5319)  Time: 6.114s,  167.47/s  (2.259s,  453.39/s)  LR: 4.600e-04  Data: 5.533 (1.655)
Train: 2 [ 800/1251 ( 64%)]  Loss:  6.390835 (6.5236)  Time: 0.584s, 1753.23/s  (2.258s,  453.58/s)  LR: 4.600e-04  Data: 0.021 (1.654)
Train: 2 [ 850/1251 ( 68%)]  Loss:  6.239202 (6.5078)  Time: 2.795s,  366.40/s  (2.252s,  454.74/s)  LR: 4.600e-04  Data: 2.232 (1.647)
Train: 2 [ 900/1251 ( 72%)]  Loss:  6.430012 (6.5037)  Time: 2.076s,  493.16/s  (2.265s,  452.04/s)  LR: 4.600e-04  Data: 1.427 (1.659)
Train: 2 [ 950/1251 ( 76%)]  Loss:  6.520489 (6.5046)  Time: 4.209s,  243.31/s  (2.257s,  453.63/s)  LR: 4.600e-04  Data: 3.610 (1.651)
Train: 2 [1000/1251 ( 80%)]  Loss:  6.433666 (6.5012)  Time: 5.989s,  170.97/s  (2.254s,  454.21/s)  LR: 4.600e-04  Data: 5.271 (1.649)
Train: 2 [1050/1251 ( 84%)]  Loss:  6.379760 (6.4957)  Time: 0.588s, 1741.17/s  (2.255s,  454.08/s)  LR: 4.600e-04  Data: 0.021 (1.650)
Train: 2 [1100/1251 ( 88%)]  Loss:  6.523836 (6.4969)  Time: 7.543s,  135.76/s  (2.254s,  454.21/s)  LR: 4.600e-04  Data: 6.882 (1.650)
Train: 2 [1150/1251 ( 92%)]  Loss:  6.380785 (6.4920)  Time: 1.085s,  943.86/s  (2.249s,  455.24/s)  LR: 4.600e-04  Data: 0.072 (1.645)
Train: 2 [1200/1251 ( 96%)]  Loss:  6.472351 (6.4913)  Time: 6.987s,  146.55/s  (2.249s,  455.30/s)  LR: 4.600e-04  Data: 6.324 (1.646)
Train: 2 [1250/1251 (100%)]  Loss:  6.390038 (6.4874)  Time: 0.565s, 1812.07/s  (2.243s,  456.63/s)  LR: 4.600e-04  Data: 0.000 (1.640)
Test: [   0/48]  Time: 14.255 (14.255)  Loss:  5.0723 (5.0723)  Acc@1: 11.0352 (11.0352)  Acc@5: 29.5898 (29.5898)
Test: [  48/48]  Time: 0.149 (3.476)  Loss:  4.7110 (5.5633)  Acc@1: 23.2311 ( 6.5980)  Acc@5: 38.9151 (18.1700)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 3 [   0/1251 (  0%)]  Loss:  6.425049 (6.4250)  Time: 11.272s,   90.85/s  (11.272s,   90.85/s)  LR: 6.400e-04  Data: 10.109 (10.109)
Train: 3 [  50/1251 (  4%)]  Loss:  6.410273 (6.4177)  Time: 0.586s, 1748.80/s  (2.260s,  453.10/s)  LR: 6.400e-04  Data: 0.022 (1.665)
Train: 3 [ 100/1251 (  8%)]  Loss:  6.549079 (6.4615)  Time: 0.584s, 1753.56/s  (2.334s,  438.64/s)  LR: 6.400e-04  Data: 0.019 (1.740)
Train: 3 [ 150/1251 ( 12%)]  Loss:  6.464914 (6.4623)  Time: 0.587s, 1743.31/s  (2.302s,  444.90/s)  LR: 6.400e-04  Data: 0.023 (1.703)
Train: 3 [ 200/1251 ( 16%)]  Loss:  6.417548 (6.4534)  Time: 2.324s,  440.53/s  (2.256s,  453.99/s)  LR: 6.400e-04  Data: 1.660 (1.653)
Train: 3 [ 250/1251 ( 20%)]  Loss:  6.561864 (6.4715)  Time: 0.583s, 1755.19/s  (2.217s,  461.97/s)  LR: 6.400e-04  Data: 0.020 (1.611)
Train: 3 [ 300/1251 ( 24%)]  Loss:  6.491884 (6.4744)  Time: 2.872s,  356.54/s  (2.193s,  467.01/s)  LR: 6.400e-04  Data: 2.210 (1.584)
Train: 3 [ 350/1251 ( 28%)]  Loss:  6.515495 (6.4795)  Time: 0.587s, 1744.49/s  (2.166s,  472.74/s)  LR: 6.400e-04  Data: 0.021 (1.557)
Train: 3 [ 400/1251 ( 32%)]  Loss:  6.421125 (6.4730)  Time: 1.923s,  532.49/s  (2.214s,  462.53/s)  LR: 6.400e-04  Data: 1.356 (1.605)
Train: 3 [ 450/1251 ( 36%)]  Loss:  6.179056 (6.4436)  Time: 0.584s, 1752.90/s  (2.201s,  465.30/s)  LR: 6.400e-04  Data: 0.021 (1.593)
Train: 3 [ 500/1251 ( 40%)]  Loss:  6.633258 (6.4609)  Time: 0.586s, 1747.62/s  (2.201s,  465.28/s)  LR: 6.400e-04  Data: 0.022 (1.595)
Train: 3 [ 550/1251 ( 44%)]  Loss:  6.443357 (6.4594)  Time: 3.672s,  278.90/s  (2.241s,  456.86/s)  LR: 6.400e-04  Data: 3.092 (1.633)
Train: 3 [ 600/1251 ( 48%)]  Loss:  6.478547 (6.4609)  Time: 2.289s,  447.43/s  (2.273s,  450.42/s)  LR: 6.400e-04  Data: 1.709 (1.664)
Train: 3 [ 650/1251 ( 52%)]  Loss:  6.474569 (6.4619)  Time: 3.394s,  301.68/s  (2.292s,  446.86/s)  LR: 6.400e-04  Data: 2.720 (1.682)
Train: 3 [ 700/1251 ( 56%)]  Loss:  6.478423 (6.4630)  Time: 1.888s,  542.33/s  (2.297s,  445.78/s)  LR: 6.400e-04  Data: 1.173 (1.687)
Train: 3 [ 750/1251 ( 60%)]  Loss:  6.493895 (6.4649)  Time: 7.040s,  145.45/s  (2.327s,  440.05/s)  LR: 6.400e-04  Data: 6.475 (1.714)
Train: 3 [ 800/1251 ( 64%)]  Loss:  6.401796 (6.4612)  Time: 2.732s,  374.87/s  (2.342s,  437.15/s)  LR: 6.400e-04  Data: 2.072 (1.728)
Train: 3 [ 850/1251 ( 68%)]  Loss:  6.245122 (6.4492)  Time: 1.141s,  897.50/s  (2.351s,  435.60/s)  LR: 6.400e-04  Data: 0.559 (1.735)
Train: 3 [ 900/1251 ( 72%)]  Loss:  6.252798 (6.4388)  Time: 8.334s,  122.87/s  (2.368s,  432.49/s)  LR: 6.400e-04  Data: 7.672 (1.751)
Train: 3 [ 950/1251 ( 76%)]  Loss:  6.274023 (6.4306)  Time: 0.592s, 1728.71/s  (2.368s,  432.49/s)  LR: 6.400e-04  Data: 0.025 (1.752)
Train: 3 [1000/1251 ( 80%)]  Loss:  6.253428 (6.4222)  Time: 4.731s,  216.45/s  (2.372s,  431.64/s)  LR: 6.400e-04  Data: 4.169 (1.757)
Train: 3 [1050/1251 ( 84%)]  Loss:  6.571208 (6.4289)  Time: 2.544s,  402.58/s  (2.375s,  431.13/s)  LR: 6.400e-04  Data: 1.955 (1.759)
Train: 3 [1100/1251 ( 88%)]  Loss:  6.333101 (6.4248)  Time: 0.862s, 1188.09/s  (2.393s,  427.93/s)  LR: 6.400e-04  Data: 0.205 (1.776)
Train: 3 [1150/1251 ( 92%)]  Loss:  6.466718 (6.4265)  Time: 0.585s, 1749.43/s  (2.398s,  426.96/s)  LR: 6.400e-04  Data: 0.020 (1.782)
Train: 3 [1200/1251 ( 96%)]  Loss:  6.187881 (6.4170)  Time: 1.513s,  676.73/s  (2.408s,  425.33/s)  LR: 6.400e-04  Data: 0.950 (1.791)
Train: 3 [1250/1251 (100%)]  Loss:  6.287511 (6.4120)  Time: 0.564s, 1814.56/s  (2.411s,  424.64/s)  LR: 6.400e-04  Data: 0.000 (1.794)
Test: [   0/48]  Time: 13.929 (13.929)  Loss:  4.7896 (4.7896)  Acc@1: 13.1836 (13.1836)  Acc@5: 35.1562 (35.1562)
Test: [  48/48]  Time: 0.148 (3.304)  Loss:  4.1615 (5.3080)  Acc@1: 30.3066 ( 8.5280)  Acc@5: 46.3443 (22.2380)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 4 [   0/1251 (  0%)]  Loss:  6.226305 (6.2263)  Time: 11.318s,   90.47/s  (11.318s,   90.47/s)  LR: 8.200e-04  Data: 10.099 (10.099)
Train: 4 [  50/1251 (  4%)]  Loss:  6.255417 (6.2409)  Time: 0.588s, 1740.18/s  (2.368s,  432.39/s)  LR: 8.200e-04  Data: 0.020 (1.769)
Train: 4 [ 100/1251 (  8%)]  Loss:  6.491252 (6.3243)  Time: 0.588s, 1741.65/s  (2.352s,  435.32/s)  LR: 8.200e-04  Data: 0.025 (1.758)
Train: 4 [ 150/1251 ( 12%)]  Loss:  6.119916 (6.2732)  Time: 0.587s, 1743.29/s  (2.411s,  424.70/s)  LR: 8.200e-04  Data: 0.020 (1.819)
Train: 4 [ 200/1251 ( 16%)]  Loss:  6.438868 (6.3064)  Time: 0.588s, 1741.40/s  (2.472s,  414.23/s)  LR: 8.200e-04  Data: 0.025 (1.877)
Train: 4 [ 250/1251 ( 20%)]  Loss:  6.440341 (6.3287)  Time: 0.591s, 1731.66/s  (2.452s,  417.60/s)  LR: 8.200e-04  Data: 0.020 (1.859)
Train: 4 [ 300/1251 ( 24%)]  Loss:  6.421582 (6.3420)  Time: 0.588s, 1741.00/s  (2.453s,  417.51/s)  LR: 8.200e-04  Data: 0.021 (1.859)
Train: 4 [ 350/1251 ( 28%)]  Loss:  6.233500 (6.3284)  Time: 0.589s, 1738.72/s  (2.419s,  423.26/s)  LR: 8.200e-04  Data: 0.020 (1.827)
Train: 4 [ 400/1251 ( 32%)]  Loss:  6.586637 (6.3571)  Time: 0.585s, 1749.66/s  (2.412s,  424.62/s)  LR: 8.200e-04  Data: 0.021 (1.821)
Train: 4 [ 450/1251 ( 36%)]  Loss:  6.159875 (6.3374)  Time: 0.590s, 1736.24/s  (2.383s,  429.71/s)  LR: 8.200e-04  Data: 0.021 (1.793)
Train: 4 [ 500/1251 ( 40%)]  Loss:  6.187172 (6.3237)  Time: 0.584s, 1752.59/s  (2.369s,  432.16/s)  LR: 8.200e-04  Data: 0.019 (1.779)
Train: 4 [ 550/1251 ( 44%)]  Loss:  6.194564 (6.3130)  Time: 0.587s, 1745.42/s  (2.398s,  426.97/s)  LR: 8.200e-04  Data: 0.020 (1.807)
Train: 4 [ 600/1251 ( 48%)]  Loss:  6.480186 (6.3258)  Time: 0.585s, 1749.23/s  (2.442s,  419.40/s)  LR: 8.200e-04  Data: 0.022 (1.850)
Train: 4 [ 650/1251 ( 52%)]  Loss:  6.270139 (6.3218)  Time: 0.587s, 1744.58/s  (2.452s,  417.69/s)  LR: 8.200e-04  Data: 0.020 (1.860)
Train: 4 [ 700/1251 ( 56%)]  Loss:  6.097958 (6.3069)  Time: 0.588s, 1742.24/s  (2.461s,  416.09/s)  LR: 8.200e-04  Data: 0.024 (1.869)
Train: 4 [ 750/1251 ( 60%)]  Loss:  6.378460 (6.3114)  Time: 0.586s, 1748.91/s  (2.461s,  416.10/s)  LR: 8.200e-04  Data: 0.021 (1.868)
Train: 4 [ 800/1251 ( 64%)]  Loss:  6.263356 (6.3086)  Time: 0.589s, 1738.73/s  (2.462s,  415.93/s)  LR: 8.200e-04  Data: 0.021 (1.869)
Train: 4 [ 850/1251 ( 68%)]  Loss:  6.236266 (6.3045)  Time: 0.587s, 1743.62/s  (2.447s,  418.40/s)  LR: 8.200e-04  Data: 0.020 (1.855)
Train: 4 [ 900/1251 ( 72%)]  Loss:  6.240629 (6.3012)  Time: 0.943s, 1085.42/s  (2.467s,  415.12/s)  LR: 8.200e-04  Data: 0.279 (1.875)
Train: 4 [ 950/1251 ( 76%)]  Loss:  6.414787 (6.3069)  Time: 0.587s, 1743.12/s  (2.470s,  414.57/s)  LR: 8.200e-04  Data: 0.019 (1.878)
Train: 4 [1000/1251 ( 80%)]  Loss:  6.336146 (6.3083)  Time: 0.591s, 1733.78/s  (2.472s,  414.16/s)  LR: 8.200e-04  Data: 0.022 (1.880)
Train: 4 [1050/1251 ( 84%)]  Loss:  6.131584 (6.3002)  Time: 0.585s, 1749.63/s  (2.469s,  414.70/s)  LR: 8.200e-04  Data: 0.020 (1.876)
Train: 4 [1100/1251 ( 88%)]  Loss:  6.235354 (6.2974)  Time: 2.534s,  404.09/s  (2.473s,  414.14/s)  LR: 8.200e-04  Data: 1.689 (1.879)
Train: 4 [1150/1251 ( 92%)]  Loss:  6.544725 (6.3077)  Time: 0.587s, 1743.34/s  (2.469s,  414.69/s)  LR: 8.200e-04  Data: 0.022 (1.873)
Train: 4 [1200/1251 ( 96%)]  Loss:  6.490814 (6.3150)  Time: 7.560s,  135.44/s  (2.468s,  414.89/s)  LR: 8.200e-04  Data: 6.892 (1.872)
Train: 4 [1250/1251 (100%)]  Loss:  6.295485 (6.3143)  Time: 0.565s, 1812.16/s  (2.476s,  413.59/s)  LR: 8.200e-04  Data: 0.000 (1.880)
Test: [   0/48]  Time: 15.414 (15.414)  Loss:  4.5293 (4.5293)  Acc@1: 14.7461 (14.7461)  Acc@5: 37.7930 (37.7930)
Test: [  48/48]  Time: 0.149 (3.792)  Loss:  3.7460 (5.0919)  Acc@1: 33.6085 (10.2800)  Acc@5: 53.5377 (25.3500)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 5 [   0/1251 (  0%)]  Loss:  6.306825 (6.3068)  Time: 12.263s,   83.50/s  (12.263s,   83.50/s)  LR: 8.791e-04  Data: 11.474 (11.474)
Train: 5 [  50/1251 (  4%)]  Loss:  6.492541 (6.3997)  Time: 0.588s, 1742.71/s  (2.724s,  375.95/s)  LR: 8.791e-04  Data: 0.021 (2.110)
Train: 5 [ 100/1251 (  8%)]  Loss:  6.263232 (6.3542)  Time: 2.801s,  365.57/s  (2.620s,  390.80/s)  LR: 8.791e-04  Data: 2.123 (2.017)
Train: 5 [ 150/1251 ( 12%)]  Loss:  6.235345 (6.3245)  Time: 0.586s, 1747.56/s  (2.535s,  403.99/s)  LR: 8.791e-04  Data: 0.018 (1.928)
Train: 5 [ 200/1251 ( 16%)]  Loss:  6.231170 (6.3058)  Time: 2.505s,  408.73/s  (2.503s,  409.11/s)  LR: 8.791e-04  Data: 1.856 (1.896)
Train: 5 [ 250/1251 ( 20%)]  Loss:  6.341717 (6.3118)  Time: 0.589s, 1737.79/s  (2.460s,  416.33/s)  LR: 8.791e-04  Data: 0.022 (1.854)
Train: 5 [ 300/1251 ( 24%)]  Loss:  6.079890 (6.2787)  Time: 4.513s,  226.92/s  (2.537s,  403.67/s)  LR: 8.791e-04  Data: 3.950 (1.929)
Train: 5 [ 350/1251 ( 28%)]  Loss:  6.233325 (6.2730)  Time: 0.591s, 1732.35/s  (2.523s,  405.88/s)  LR: 8.791e-04  Data: 0.027 (1.916)
Train: 5 [ 400/1251 ( 32%)]  Loss:  6.425976 (6.2900)  Time: 0.587s, 1745.81/s  (2.534s,  404.03/s)  LR: 8.791e-04  Data: 0.021 (1.926)
Train: 5 [ 450/1251 ( 36%)]  Loss:  6.363284 (6.2973)  Time: 0.592s, 1729.21/s  (2.512s,  407.68/s)  LR: 8.791e-04  Data: 0.025 (1.905)
Train: 5 [ 500/1251 ( 40%)]  Loss:  6.043898 (6.2743)  Time: 0.586s, 1746.55/s  (2.501s,  409.46/s)  LR: 8.791e-04  Data: 0.021 (1.897)
Train: 5 [ 550/1251 ( 44%)]  Loss:  6.307130 (6.2770)  Time: 0.588s, 1742.62/s  (2.479s,  413.07/s)  LR: 8.791e-04  Data: 0.021 (1.877)
Train: 5 [ 600/1251 ( 48%)]  Loss:  6.420829 (6.2881)  Time: 0.587s, 1745.74/s  (2.485s,  412.14/s)  LR: 8.791e-04  Data: 0.020 (1.883)
Train: 5 [ 650/1251 ( 52%)]  Loss:  6.373588 (6.2942)  Time: 0.587s, 1743.22/s  (2.523s,  405.84/s)  LR: 8.791e-04  Data: 0.019 (1.922)
Train: 5 [ 700/1251 ( 56%)]  Loss:  6.422623 (6.3028)  Time: 0.587s, 1743.60/s  (2.541s,  402.92/s)  LR: 8.791e-04  Data: 0.023 (1.939)
Train: 5 [ 750/1251 ( 60%)]  Loss:  6.282880 (6.3015)  Time: 0.586s, 1747.66/s  (2.539s,  403.31/s)  LR: 8.791e-04  Data: 0.021 (1.938)
Train: 5 [ 800/1251 ( 64%)]  Loss:  6.196924 (6.2954)  Time: 0.585s, 1749.86/s  (2.540s,  403.21/s)  LR: 8.791e-04  Data: 0.021 (1.939)
Train: 5 [ 850/1251 ( 68%)]  Loss:  6.231963 (6.2918)  Time: 4.278s,  239.35/s  (2.528s,  405.10/s)  LR: 8.791e-04  Data: 3.597 (1.928)
Train: 5 [ 900/1251 ( 72%)]  Loss:  6.194349 (6.2867)  Time: 0.587s, 1745.07/s  (2.516s,  407.02/s)  LR: 8.791e-04  Data: 0.020 (1.916)
Train: 5 [ 950/1251 ( 76%)]  Loss:  6.278410 (6.2863)  Time: 2.452s,  417.60/s  (2.503s,  409.05/s)  LR: 8.791e-04  Data: 1.770 (1.903)
Train: 5 [1000/1251 ( 80%)]  Loss:  5.950390 (6.2703)  Time: 1.820s,  562.60/s  (2.514s,  407.33/s)  LR: 8.791e-04  Data: 1.157 (1.913)
Train: 5 [1050/1251 ( 84%)]  Loss:  6.007436 (6.2584)  Time: 4.515s,  226.82/s  (2.520s,  406.33/s)  LR: 8.791e-04  Data: 3.864 (1.919)
Train: 5 [1100/1251 ( 88%)]  Loss:  6.326876 (6.2613)  Time: 0.587s, 1744.22/s  (2.519s,  406.51/s)  LR: 8.791e-04  Data: 0.021 (1.918)
Train: 5 [1150/1251 ( 92%)]  Loss:  6.198756 (6.2587)  Time: 5.520s,  185.51/s  (2.515s,  407.09/s)  LR: 8.791e-04  Data: 4.238 (1.913)
Train: 5 [1200/1251 ( 96%)]  Loss:  6.087253 (6.2519)  Time: 0.587s, 1743.94/s  (2.509s,  408.19/s)  LR: 8.791e-04  Data: 0.019 (1.906)
Train: 5 [1250/1251 (100%)]  Loss:  6.047934 (6.2440)  Time: 0.564s, 1816.34/s  (2.500s,  409.56/s)  LR: 8.791e-04  Data: 0.000 (1.897)
Test: [   0/48]  Time: 14.169 (14.169)  Loss:  4.1518 (4.1518)  Acc@1: 21.0938 (21.0938)  Acc@5: 47.2656 (47.2656)
Test: [  48/48]  Time: 0.149 (3.274)  Loss:  3.3344 (4.8551)  Acc@1: 41.9811 (13.0500)  Acc@5: 62.5000 (30.4920)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 6 [   0/1251 (  0%)]  Loss:  6.142528 (6.1425)  Time: 10.618s,   96.44/s  (10.618s,   96.44/s)  LR: 8.292e-04  Data: 9.483 (9.483)
Train: 6 [  50/1251 (  4%)]  Loss:  6.110530 (6.1265)  Time: 0.587s, 1743.29/s  (2.824s,  362.60/s)  LR: 8.292e-04  Data: 0.020 (2.216)
Train: 6 [ 100/1251 (  8%)]  Loss:  6.168158 (6.1404)  Time: 3.961s,  258.55/s  (2.790s,  366.96/s)  LR: 8.292e-04  Data: 3.269 (2.178)
Train: 6 [ 150/1251 ( 12%)]  Loss:  6.167330 (6.1471)  Time: 0.586s, 1748.01/s  (2.638s,  388.10/s)  LR: 8.292e-04  Data: 0.021 (2.032)
Train: 6 [ 200/1251 ( 16%)]  Loss:  6.252193 (6.1681)  Time: 5.898s,  173.61/s  (2.559s,  400.15/s)  LR: 8.292e-04  Data: 5.234 (1.954)
Train: 6 [ 250/1251 ( 20%)]  Loss:  6.274254 (6.1858)  Time: 0.587s, 1744.24/s  (2.498s,  409.89/s)  LR: 8.292e-04  Data: 0.022 (1.894)
Train: 6 [ 300/1251 ( 24%)]  Loss:  6.232017 (6.1924)  Time: 6.577s,  155.69/s  (2.469s,  414.69/s)  LR: 8.292e-04  Data: 5.887 (1.866)
Train: 6 [ 350/1251 ( 28%)]  Loss:  6.061551 (6.1761)  Time: 0.586s, 1746.15/s  (2.430s,  421.48/s)  LR: 8.292e-04  Data: 0.018 (1.829)
Train: 6 [ 400/1251 ( 32%)]  Loss:  6.127802 (6.1707)  Time: 9.498s,  107.81/s  (2.460s,  416.28/s)  LR: 8.292e-04  Data: 8.878 (1.859)
Train: 6 [ 450/1251 ( 36%)]  Loss:  6.275400 (6.1812)  Time: 0.585s, 1751.52/s  (2.448s,  418.38/s)  LR: 8.292e-04  Data: 0.022 (1.848)
Train: 6 [ 500/1251 ( 40%)]  Loss:  6.081457 (6.1721)  Time: 9.160s,  111.79/s  (2.460s,  416.26/s)  LR: 8.292e-04  Data: 8.064 (1.860)
Train: 6 [ 550/1251 ( 44%)]  Loss:  5.933963 (6.1523)  Time: 0.615s, 1665.00/s  (2.452s,  417.65/s)  LR: 8.292e-04  Data: 0.046 (1.853)
Train: 6 [ 600/1251 ( 48%)]  Loss:  6.300124 (6.1636)  Time: 6.698s,  152.89/s  (2.466s,  415.19/s)  LR: 8.292e-04  Data: 6.035 (1.866)
Train: 6 [ 650/1251 ( 52%)]  Loss:  6.091149 (6.1585)  Time: 2.863s,  357.63/s  (2.466s,  415.32/s)  LR: 8.292e-04  Data: 2.196 (1.862)
Train: 6 [ 700/1251 ( 56%)]  Loss:  6.224921 (6.1629)  Time: 4.496s,  227.75/s  (2.460s,  416.34/s)  LR: 8.292e-04  Data: 3.848 (1.856)
Train: 6 [ 750/1251 ( 60%)]  Loss:  5.753619 (6.1373)  Time: 7.413s,  138.14/s  (2.459s,  416.37/s)  LR: 8.292e-04  Data: 5.872 (1.854)
Train: 6 [ 800/1251 ( 64%)]  Loss:  5.928284 (6.1250)  Time: 4.377s,  233.93/s  (2.473s,  414.03/s)  LR: 8.292e-04  Data: 3.708 (1.866)
Train: 6 [ 850/1251 ( 68%)]  Loss:  5.983930 (6.1172)  Time: 2.254s,  454.24/s  (2.471s,  414.41/s)  LR: 8.292e-04  Data: 1.692 (1.864)
Train: 6 [ 900/1251 ( 72%)]  Loss:  6.330975 (6.1284)  Time: 3.593s,  285.02/s  (2.474s,  413.93/s)  LR: 8.292e-04  Data: 2.915 (1.865)
Train: 6 [ 950/1251 ( 76%)]  Loss:  6.151195 (6.1296)  Time: 7.131s,  143.59/s  (2.474s,  413.87/s)  LR: 8.292e-04  Data: 6.449 (1.865)
Train: 6 [1000/1251 ( 80%)]  Loss:  6.126586 (6.1294)  Time: 0.591s, 1733.84/s  (2.466s,  415.23/s)  LR: 8.292e-04  Data: 0.022 (1.858)
Train: 6 [1050/1251 ( 84%)]  Loss:  5.828614 (6.1158)  Time: 7.349s,  139.33/s  (2.459s,  416.49/s)  LR: 8.292e-04  Data: 6.751 (1.850)
Train: 6 [1100/1251 ( 88%)]  Loss:  5.924739 (6.1074)  Time: 0.588s, 1742.06/s  (2.444s,  418.92/s)  LR: 8.292e-04  Data: 0.020 (1.837)
Train: 6 [1150/1251 ( 92%)]  Loss:  5.676449 (6.0895)  Time: 7.549s,  135.65/s  (2.459s,  416.50/s)  LR: 8.292e-04  Data: 6.940 (1.852)
Train: 6 [1200/1251 ( 96%)]  Loss:  6.294816 (6.0977)  Time: 0.591s, 1733.07/s  (2.460s,  416.20/s)  LR: 8.292e-04  Data: 0.021 (1.854)
Train: 6 [1250/1251 (100%)]  Loss:  6.169617 (6.1005)  Time: 0.565s, 1813.96/s  (2.461s,  416.03/s)  LR: 8.292e-04  Data: 0.000 (1.856)
Test: [   0/48]  Time: 15.039 (15.039)  Loss:  3.9438 (3.9438)  Acc@1: 23.1445 (23.1445)  Acc@5: 54.8828 (54.8828)
Test: [  48/48]  Time: 0.149 (3.572)  Loss:  3.2547 (4.6016)  Acc@1: 43.0425 (16.1760)  Acc@5: 62.1462 (35.4940)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 7 [   0/1251 (  0%)]  Loss:  6.151405 (6.1514)  Time: 11.925s,   85.87/s  (11.925s,   85.87/s)  LR: 7.726e-04  Data: 11.220 (11.220)
Train: 7 [  50/1251 (  4%)]  Loss:  6.083211 (6.1173)  Time: 0.590s, 1735.36/s  (2.554s,  400.88/s)  LR: 7.726e-04  Data: 0.022 (1.955)
Train: 7 [ 100/1251 (  8%)]  Loss:  6.268205 (6.1676)  Time: 0.729s, 1404.68/s  (2.515s,  407.18/s)  LR: 7.726e-04  Data: 0.064 (1.909)
Train: 7 [ 150/1251 ( 12%)]  Loss:  5.942250 (6.1113)  Time: 0.587s, 1743.40/s  (2.476s,  413.56/s)  LR: 7.726e-04  Data: 0.019 (1.861)
Train: 7 [ 200/1251 ( 16%)]  Loss:  6.136293 (6.1163)  Time: 1.336s,  766.22/s  (2.566s,  399.02/s)  LR: 7.726e-04  Data: 0.679 (1.948)
Train: 7 [ 250/1251 ( 20%)]  Loss:  5.950808 (6.0887)  Time: 0.586s, 1747.42/s  (2.599s,  393.94/s)  LR: 7.726e-04  Data: 0.020 (1.986)
Train: 7 [ 300/1251 ( 24%)]  Loss:  6.107422 (6.0914)  Time: 0.586s, 1746.44/s  (2.581s,  396.68/s)  LR: 7.726e-04  Data: 0.021 (1.973)
Train: 7 [ 350/1251 ( 28%)]  Loss:  6.055056 (6.0868)  Time: 0.589s, 1738.67/s  (2.578s,  397.28/s)  LR: 7.726e-04  Data: 0.020 (1.971)
Train: 7 [ 400/1251 ( 32%)]  Loss:  6.195802 (6.0989)  Time: 0.586s, 1746.34/s  (2.539s,  403.27/s)  LR: 7.726e-04  Data: 0.021 (1.936)
Train: 7 [ 450/1251 ( 36%)]  Loss:  6.251691 (6.1142)  Time: 0.584s, 1754.92/s  (2.522s,  406.03/s)  LR: 7.726e-04  Data: 0.021 (1.921)
Train: 7 [ 500/1251 ( 40%)]  Loss:  5.758104 (6.0818)  Time: 0.587s, 1744.97/s  (2.496s,  410.20/s)  LR: 7.726e-04  Data: 0.020 (1.896)
Train: 7 [ 550/1251 ( 44%)]  Loss:  5.758983 (6.0549)  Time: 0.589s, 1739.83/s  (2.519s,  406.52/s)  LR: 7.726e-04  Data: 0.025 (1.916)
Train: 7 [ 600/1251 ( 48%)]  Loss:  5.811276 (6.0362)  Time: 0.587s, 1745.67/s  (2.533s,  404.33/s)  LR: 7.726e-04  Data: 0.020 (1.930)
Train: 7 [ 650/1251 ( 52%)]  Loss:  5.954333 (6.0303)  Time: 3.100s,  330.28/s  (2.549s,  401.72/s)  LR: 7.726e-04  Data: 2.493 (1.946)
Train: 7 [ 700/1251 ( 56%)]  Loss:  6.126288 (6.0367)  Time: 0.587s, 1744.80/s  (2.544s,  402.51/s)  LR: 7.726e-04  Data: 0.021 (1.942)
Train: 7 [ 750/1251 ( 60%)]  Loss:  6.111939 (6.0414)  Time: 5.356s,  191.18/s  (2.535s,  403.97/s)  LR: 7.726e-04  Data: 4.687 (1.933)
Train: 7 [ 800/1251 ( 64%)]  Loss:  6.035177 (6.0411)  Time: 0.588s, 1740.33/s  (2.523s,  405.93/s)  LR: 7.726e-04  Data: 0.022 (1.919)
Train: 7 [ 850/1251 ( 68%)]  Loss:  6.164966 (6.0480)  Time: 3.426s,  298.92/s  (2.508s,  408.36/s)  LR: 7.726e-04  Data: 2.805 (1.904)
Train: 7 [ 900/1251 ( 72%)]  Loss:  6.013083 (6.0461)  Time: 0.585s, 1750.66/s  (2.518s,  406.67/s)  LR: 7.726e-04  Data: 0.019 (1.913)
Train: 7 [ 950/1251 ( 76%)]  Loss:  5.767835 (6.0322)  Time: 4.986s,  205.37/s  (2.518s,  406.69/s)  LR: 7.726e-04  Data: 4.347 (1.913)
Train: 7 [1000/1251 ( 80%)]  Loss:  5.912262 (6.0265)  Time: 0.585s, 1750.67/s  (2.511s,  407.77/s)  LR: 7.726e-04  Data: 0.019 (1.906)
Train: 7 [1050/1251 ( 84%)]  Loss:  6.131493 (6.0313)  Time: 7.342s,  139.47/s  (2.509s,  408.17/s)  LR: 7.726e-04  Data: 6.565 (1.903)
Train: 7 [1100/1251 ( 88%)]  Loss:  6.017042 (6.0306)  Time: 0.587s, 1745.19/s  (2.500s,  409.68/s)  LR: 7.726e-04  Data: 0.018 (1.895)
Train: 7 [1150/1251 ( 92%)]  Loss:  6.112179 (6.0340)  Time: 7.218s,  141.87/s  (2.494s,  410.65/s)  LR: 7.726e-04  Data: 6.638 (1.890)
Train: 7 [1200/1251 ( 96%)]  Loss:  6.024226 (6.0337)  Time: 1.110s,  922.78/s  (2.485s,  412.10/s)  LR: 7.726e-04  Data: 0.526 (1.882)
Train: 7 [1250/1251 (100%)]  Loss:  6.334621 (6.0452)  Time: 0.564s, 1816.16/s  (2.498s,  409.91/s)  LR: 7.726e-04  Data: 0.000 (1.896)
Test: [   0/48]  Time: 18.111 (18.111)  Loss:  3.6071 (3.6071)  Acc@1: 32.3242 (32.3242)  Acc@5: 58.7891 (58.7891)
Test: [  48/48]  Time: 0.150 (4.028)  Loss:  3.2134 (4.4112)  Acc@1: 44.3396 (18.9360)  Acc@5: 62.3821 (39.4440)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 8 [   0/1251 (  0%)]  Loss:  6.032836 (6.0328)  Time: 15.745s,   65.04/s  (15.745s,   65.04/s)  LR: 7.106e-04  Data: 15.104 (15.104)
Train: 8 [  50/1251 (  4%)]  Loss:  6.132219 (6.0825)  Time: 0.585s, 1749.70/s  (3.015s,  339.61/s)  LR: 7.106e-04  Data: 0.020 (2.413)
Train: 8 [ 100/1251 (  8%)]  Loss:  6.204756 (6.1233)  Time: 0.817s, 1253.40/s  (2.948s,  347.36/s)  LR: 7.106e-04  Data: 0.147 (2.347)
Train: 8 [ 150/1251 ( 12%)]  Loss:  5.845290 (6.0538)  Time: 0.588s, 1740.16/s  (2.836s,  361.13/s)  LR: 7.106e-04  Data: 0.021 (2.233)
Train: 8 [ 200/1251 ( 16%)]  Loss:  5.509514 (5.9449)  Time: 0.587s, 1744.76/s  (2.750s,  372.32/s)  LR: 7.106e-04  Data: 0.020 (2.150)
Train: 8 [ 250/1251 ( 20%)]  Loss:  6.230260 (5.9925)  Time: 0.586s, 1747.96/s  (2.733s,  374.69/s)  LR: 7.106e-04  Data: 0.022 (2.133)
Train: 8 [ 300/1251 ( 24%)]  Loss:  6.177822 (6.0190)  Time: 0.587s, 1745.88/s  (2.727s,  375.46/s)  LR: 7.106e-04  Data: 0.023 (2.129)
Train: 8 [ 350/1251 ( 28%)]  Loss:  6.021553 (6.0193)  Time: 0.586s, 1748.90/s  (2.701s,  379.18/s)  LR: 7.106e-04  Data: 0.020 (2.100)
Train: 8 [ 400/1251 ( 32%)]  Loss:  5.704463 (5.9843)  Time: 1.813s,  564.94/s  (2.696s,  379.85/s)  LR: 7.106e-04  Data: 1.193 (2.093)
Train: 8 [ 450/1251 ( 36%)]  Loss:  5.914005 (5.9773)  Time: 0.585s, 1749.20/s  (2.663s,  384.56/s)  LR: 7.106e-04  Data: 0.021 (2.062)
Train: 8 [ 500/1251 ( 40%)]  Loss:  6.275803 (6.0044)  Time: 0.901s, 1136.61/s  (2.647s,  386.90/s)  LR: 7.106e-04  Data: 0.339 (2.043)
Train: 8 [ 550/1251 ( 44%)]  Loss:  6.083564 (6.0110)  Time: 1.453s,  704.93/s  (2.614s,  391.70/s)  LR: 7.106e-04  Data: 0.808 (2.012)
Train: 8 [ 600/1251 ( 48%)]  Loss:  5.593041 (5.9789)  Time: 0.591s, 1733.19/s  (2.628s,  389.72/s)  LR: 7.106e-04  Data: 0.023 (2.023)
Train: 8 [ 650/1251 ( 52%)]  Loss:  5.882664 (5.9720)  Time: 6.041s,  169.52/s  (2.656s,  385.54/s)  LR: 7.106e-04  Data: 5.357 (2.050)
Train: 8 [ 700/1251 ( 56%)]  Loss:  5.786485 (5.9596)  Time: 0.588s, 1742.80/s  (2.648s,  386.72/s)  LR: 7.106e-04  Data: 0.019 (2.040)
Train: 8 [ 750/1251 ( 60%)]  Loss:  5.710903 (5.9441)  Time: 6.076s,  168.54/s  (2.649s,  386.54/s)  LR: 7.106e-04  Data: 5.383 (2.041)
Train: 8 [ 800/1251 ( 64%)]  Loss:  6.187923 (5.9584)  Time: 0.588s, 1742.37/s  (2.640s,  387.81/s)  LR: 7.106e-04  Data: 0.021 (2.033)
Train: 8 [ 850/1251 ( 68%)]  Loss:  6.023537 (5.9620)  Time: 6.079s,  168.45/s  (2.649s,  386.59/s)  LR: 7.106e-04  Data: 5.514 (2.041)
Train: 8 [ 900/1251 ( 72%)]  Loss:  6.011919 (5.9647)  Time: 0.586s, 1748.49/s  (2.653s,  385.98/s)  LR: 7.106e-04  Data: 0.023 (2.036)
Train: 8 [ 950/1251 ( 76%)]  Loss:  5.552489 (5.9441)  Time: 2.065s,  495.80/s  (2.698s,  379.59/s)  LR: 7.106e-04  Data: 1.500 (2.072)
Train: 8 [1000/1251 ( 80%)]  Loss:  5.780902 (5.9363)  Time: 0.590s, 1735.45/s  (2.711s,  377.74/s)  LR: 7.106e-04  Data: 0.023 (2.087)
Train: 8 [1050/1251 ( 84%)]  Loss:  5.861871 (5.9329)  Time: 0.586s, 1747.15/s  (2.730s,  375.08/s)  LR: 7.106e-04  Data: 0.020 (2.108)
Train: 8 [1100/1251 ( 88%)]  Loss:  6.261571 (5.9472)  Time: 0.587s, 1745.34/s  (2.738s,  374.02/s)  LR: 7.106e-04  Data: 0.020 (2.110)
Train: 8 [1150/1251 ( 92%)]  Loss:  5.814847 (5.9417)  Time: 0.588s, 1741.54/s  (2.729s,  375.23/s)  LR: 7.106e-04  Data: 0.019 (2.102)
Train: 8 [1200/1251 ( 96%)]  Loss:  6.167079 (5.9507)  Time: 0.587s, 1743.07/s  (2.716s,  376.96/s)  LR: 7.106e-04  Data: 0.021 (2.092)
Train: 8 [1250/1251 (100%)]  Loss:  5.906297 (5.9490)  Time: 0.567s, 1807.47/s  (2.726s,  375.63/s)  LR: 7.106e-04  Data: 0.000 (2.102)
Test: [   0/48]  Time: 17.650 (17.650)  Loss:  3.2669 (3.2669)  Acc@1: 34.4727 (34.4727)  Acc@5: 64.9414 (64.9414)
Test: [  48/48]  Time: 0.150 (3.755)  Loss:  2.6840 (4.1016)  Acc@1: 49.4104 (22.0120)  Acc@5: 68.3962 (44.1120)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 9 [   0/1251 (  0%)]  Loss:  5.864152 (5.8642)  Time: 12.006s,   85.29/s  (12.006s,   85.29/s)  LR: 6.445e-04  Data: 11.165 (11.165)
Train: 9 [  50/1251 (  4%)]  Loss:  5.755609 (5.8099)  Time: 1.094s,  935.88/s  (2.729s,  375.29/s)  LR: 6.445e-04  Data: 0.520 (2.113)
Train: 9 [ 100/1251 (  8%)]  Loss:  5.496492 (5.7054)  Time: 2.162s,  473.71/s  (2.669s,  383.61/s)  LR: 6.445e-04  Data: 1.365 (2.059)
Train: 9 [ 150/1251 ( 12%)]  Loss:  5.837499 (5.7384)  Time: 0.587s, 1745.58/s  (2.603s,  393.38/s)  LR: 6.445e-04  Data: 0.024 (1.993)
Train: 9 [ 200/1251 ( 16%)]  Loss:  5.712993 (5.7333)  Time: 0.586s, 1746.57/s  (2.572s,  398.13/s)  LR: 6.445e-04  Data: 0.018 (1.966)
Train: 9 [ 250/1251 ( 20%)]  Loss:  5.921593 (5.7647)  Time: 0.728s, 1406.13/s  (2.540s,  403.20/s)  LR: 6.445e-04  Data: 0.165 (1.934)
Train: 9 [ 300/1251 ( 24%)]  Loss:  5.652694 (5.7487)  Time: 0.590s, 1734.88/s  (2.572s,  398.10/s)  LR: 6.445e-04  Data: 0.019 (1.968)
Train: 9 [ 350/1251 ( 28%)]  Loss:  6.125470 (5.7958)  Time: 3.159s,  324.15/s  (2.596s,  394.44/s)  LR: 6.445e-04  Data: 2.496 (1.991)
Train: 9 [ 400/1251 ( 32%)]  Loss:  6.138185 (5.8339)  Time: 0.588s, 1742.01/s  (2.590s,  395.39/s)  LR: 6.445e-04  Data: 0.021 (1.983)
Train: 9 [ 450/1251 ( 36%)]  Loss:  5.731397 (5.8236)  Time: 2.322s,  440.96/s  (2.580s,  396.85/s)  LR: 6.445e-04  Data: 1.740 (1.974)
Train: 9 [ 500/1251 ( 40%)]  Loss:  5.985396 (5.8383)  Time: 0.585s, 1751.55/s  (2.553s,  401.03/s)  LR: 6.445e-04  Data: 0.022 (1.949)
Train: 9 [ 550/1251 ( 44%)]  Loss:  5.478244 (5.8083)  Time: 0.733s, 1396.94/s  (2.539s,  403.36/s)  LR: 6.445e-04  Data: 0.168 (1.934)
Train: 9 [ 600/1251 ( 48%)]  Loss:  6.122418 (5.8325)  Time: 0.590s, 1735.24/s  (2.523s,  405.88/s)  LR: 6.445e-04  Data: 0.026 (1.919)
Train: 9 [ 650/1251 ( 52%)]  Loss:  5.947670 (5.8407)  Time: 0.593s, 1727.08/s  (2.557s,  400.53/s)  LR: 6.445e-04  Data: 0.027 (1.955)
Train: 9 [ 700/1251 ( 56%)]  Loss:  6.067829 (5.8558)  Time: 0.583s, 1755.07/s  (2.556s,  400.56/s)  LR: 6.445e-04  Data: 0.020 (1.956)
Train: 9 [ 750/1251 ( 60%)]  Loss:  5.742511 (5.8488)  Time: 1.781s,  575.08/s  (2.555s,  400.79/s)  LR: 6.445e-04  Data: 1.219 (1.954)
Train: 9 [ 800/1251 ( 64%)]  Loss:  5.882387 (5.8507)  Time: 0.583s, 1756.82/s  (2.548s,  401.95/s)  LR: 6.445e-04  Data: 0.020 (1.946)
Train: 9 [ 850/1251 ( 68%)]  Loss:  5.855631 (5.8510)  Time: 4.535s,  225.78/s  (2.547s,  402.10/s)  LR: 6.445e-04  Data: 3.721 (1.944)
Train: 9 [ 900/1251 ( 72%)]  Loss:  5.365657 (5.8255)  Time: 0.588s, 1742.06/s  (2.538s,  403.41/s)  LR: 6.445e-04  Data: 0.020 (1.936)
Train: 9 [ 950/1251 ( 76%)]  Loss:  5.804565 (5.8244)  Time: 0.588s, 1741.61/s  (2.530s,  404.74/s)  LR: 6.445e-04  Data: 0.021 (1.927)
Train: 9 [1000/1251 ( 80%)]  Loss:  5.627222 (5.8150)  Time: 0.584s, 1752.04/s  (2.542s,  402.85/s)  LR: 6.445e-04  Data: 0.019 (1.938)
Train: 9 [1050/1251 ( 84%)]  Loss:  5.997104 (5.8233)  Time: 0.590s, 1735.26/s  (2.546s,  402.16/s)  LR: 6.445e-04  Data: 0.024 (1.943)
Train: 9 [1100/1251 ( 88%)]  Loss:  5.849001 (5.8244)  Time: 0.625s, 1638.97/s  (2.544s,  402.55/s)  LR: 6.445e-04  Data: 0.020 (1.940)
Train: 9 [1150/1251 ( 92%)]  Loss:  5.901049 (5.8276)  Time: 0.587s, 1744.86/s  (2.536s,  403.83/s)  LR: 6.445e-04  Data: 0.021 (1.932)
Train: 9 [1200/1251 ( 96%)]  Loss:  5.518300 (5.8152)  Time: 0.583s, 1755.94/s  (2.528s,  405.07/s)  LR: 6.445e-04  Data: 0.019 (1.924)
Train: 9 [1250/1251 (100%)]  Loss:  5.813061 (5.8152)  Time: 0.565s, 1813.43/s  (2.515s,  407.16/s)  LR: 6.445e-04  Data: 0.000 (1.911)
Test: [   0/48]  Time: 13.314 (13.314)  Loss:  3.1138 (3.1138)  Acc@1: 35.5469 (35.5469)  Acc@5: 66.6992 (66.6992)
Test: [  48/48]  Time: 0.149 (3.182)  Loss:  2.4765 (3.8762)  Acc@1: 53.7736 (24.5280)  Acc@5: 71.3443 (47.3700)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-0.pth.tar', 1.5380000073242188)

Train: 10 [   0/1251 (  0%)]  Loss:  5.801006 (5.8010)  Time: 11.248s,   91.04/s  (11.248s,   91.04/s)  LR: 5.754e-04  Data: 10.074 (10.074)
Train: 10 [  50/1251 (  4%)]  Loss:  5.737635 (5.7693)  Time: 0.587s, 1744.92/s  (2.825s,  362.44/s)  LR: 5.754e-04  Data: 0.024 (2.213)
Train: 10 [ 100/1251 (  8%)]  Loss:  5.900972 (5.8132)  Time: 0.585s, 1749.87/s  (2.779s,  368.47/s)  LR: 5.754e-04  Data: 0.019 (2.178)
Train: 10 [ 150/1251 ( 12%)]  Loss:  5.322480 (5.6905)  Time: 0.585s, 1749.26/s  (2.697s,  379.73/s)  LR: 5.754e-04  Data: 0.023 (2.097)
Train: 10 [ 200/1251 ( 16%)]  Loss:  5.956909 (5.7438)  Time: 0.585s, 1751.51/s  (2.672s,  383.27/s)  LR: 5.754e-04  Data: 0.020 (2.070)
Train: 10 [ 250/1251 ( 20%)]  Loss:  5.668930 (5.7313)  Time: 0.587s, 1745.93/s  (2.595s,  394.59/s)  LR: 5.754e-04  Data: 0.023 (1.994)
Train: 10 [ 300/1251 ( 24%)]  Loss:  6.034894 (5.7747)  Time: 0.585s, 1750.11/s  (2.545s,  402.40/s)  LR: 5.754e-04  Data: 0.022 (1.944)
Train: 10 [ 350/1251 ( 28%)]  Loss:  5.387083 (5.7262)  Time: 0.589s, 1738.94/s  (2.493s,  410.78/s)  LR: 5.754e-04  Data: 0.026 (1.894)
Train: 10 [ 400/1251 ( 32%)]  Loss:  5.744662 (5.7283)  Time: 0.585s, 1750.04/s  (2.521s,  406.20/s)  LR: 5.754e-04  Data: 0.021 (1.923)
Train: 10 [ 450/1251 ( 36%)]  Loss:  5.393378 (5.6948)  Time: 0.585s, 1750.65/s  (2.519s,  406.51/s)  LR: 5.754e-04  Data: 0.021 (1.922)
Train: 10 [ 500/1251 ( 40%)]  Loss:  5.906113 (5.7140)  Time: 0.586s, 1746.49/s  (2.528s,  405.05/s)  LR: 5.754e-04  Data: 0.021 (1.930)
Train: 10 [ 550/1251 ( 44%)]  Loss:  5.815433 (5.7225)  Time: 0.584s, 1754.47/s  (2.525s,  405.59/s)  LR: 5.754e-04  Data: 0.020 (1.929)
Train: 10 [ 600/1251 ( 48%)]  Loss:  6.009527 (5.7445)  Time: 0.588s, 1740.08/s  (2.539s,  403.30/s)  LR: 5.754e-04  Data: 0.020 (1.942)
Train: 10 [ 650/1251 ( 52%)]  Loss:  5.836390 (5.7511)  Time: 0.586s, 1746.42/s  (2.530s,  404.71/s)  LR: 5.754e-04  Data: 0.021 (1.934)
Train: 10 [ 700/1251 ( 56%)]  Loss:  5.621462 (5.7425)  Time: 0.588s, 1741.67/s  (2.527s,  405.28/s)  LR: 5.754e-04  Data: 0.025 (1.931)
Train: 10 [ 750/1251 ( 60%)]  Loss:  5.750390 (5.7430)  Time: 0.585s, 1748.97/s  (2.539s,  403.28/s)  LR: 5.754e-04  Data: 0.019 (1.944)
Train: 10 [ 800/1251 ( 64%)]  Loss:  5.817912 (5.7474)  Time: 0.585s, 1750.38/s  (2.542s,  402.79/s)  LR: 5.754e-04  Data: 0.021 (1.948)
Train: 10 [ 850/1251 ( 68%)]  Loss:  6.031603 (5.7632)  Time: 0.805s, 1272.71/s  (2.540s,  403.08/s)  LR: 5.754e-04  Data: 0.098 (1.946)
Train: 10 [ 900/1251 ( 72%)]  Loss:  5.822698 (5.7663)  Time: 0.588s, 1741.36/s  (2.544s,  402.55/s)  LR: 5.754e-04  Data: 0.020 (1.950)
Train: 10 [ 950/1251 ( 76%)]  Loss:  5.496804 (5.7528)  Time: 0.585s, 1750.20/s  (2.536s,  403.86/s)  LR: 5.754e-04  Data: 0.022 (1.941)
Train: 10 [1000/1251 ( 80%)]  Loss:  5.739538 (5.7522)  Time: 0.588s, 1740.55/s  (2.532s,  404.39/s)  LR: 5.754e-04  Data: 0.022 (1.937)
Train: 10 [1050/1251 ( 84%)]  Loss:  5.595146 (5.7450)  Time: 0.586s, 1748.70/s  (2.522s,  406.07/s)  LR: 5.754e-04  Data: 0.023 (1.926)
Train: 10 [1100/1251 ( 88%)]  Loss:  5.581117 (5.7379)  Time: 0.587s, 1743.87/s  (2.530s,  404.72/s)  LR: 5.754e-04  Data: 0.022 (1.935)
Train: 10 [1150/1251 ( 92%)]  Loss:  5.577032 (5.7312)  Time: 0.590s, 1735.56/s  (2.526s,  405.36/s)  LR: 5.754e-04  Data: 0.023 (1.931)
Train: 10 [1200/1251 ( 96%)]  Loss:  5.696908 (5.7298)  Time: 8.147s,  125.69/s  (2.536s,  403.79/s)  LR: 5.754e-04  Data: 7.451 (1.939)
Train: 10 [1250/1251 (100%)]  Loss:  5.837511 (5.7340)  Time: 0.563s, 1819.64/s  (2.534s,  404.11/s)  LR: 5.754e-04  Data: 0.000 (1.937)
Test: [   0/48]  Time: 15.917 (15.917)  Loss:  2.8740 (2.8740)  Acc@1: 42.5781 (42.5781)  Acc@5: 69.9219 (69.9219)
Test: [  48/48]  Time: 0.149 (3.536)  Loss:  2.4487 (3.7478)  Acc@1: 54.1274 (27.0380)  Acc@5: 71.9340 (50.8960)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-1.pth.tar', 3.9840000134277345)

Train: 11 [   0/1251 (  0%)]  Loss:  5.822050 (5.8221)  Time: 11.866s,   86.30/s  (11.866s,   86.30/s)  LR: 5.050e-04  Data: 11.203 (11.203)
Train: 11 [  50/1251 (  4%)]  Loss:  5.615343 (5.7187)  Time: 0.591s, 1733.09/s  (2.587s,  395.89/s)  LR: 5.050e-04  Data: 0.027 (1.983)
Train: 11 [ 100/1251 (  8%)]  Loss:  5.775194 (5.7375)  Time: 0.587s, 1743.57/s  (2.522s,  406.06/s)  LR: 5.050e-04  Data: 0.023 (1.932)
Train: 11 [ 150/1251 ( 12%)]  Loss:  5.912268 (5.7812)  Time: 0.587s, 1743.04/s  (2.554s,  400.94/s)  LR: 5.050e-04  Data: 0.024 (1.965)
Train: 11 [ 200/1251 ( 16%)]  Loss:  5.456150 (5.7162)  Time: 0.589s, 1739.27/s  (2.563s,  399.50/s)  LR: 5.050e-04  Data: 0.019 (1.970)
Train: 11 [ 250/1251 ( 20%)]  Loss:  5.540624 (5.6869)  Time: 0.584s, 1752.34/s  (2.506s,  408.57/s)  LR: 5.050e-04  Data: 0.022 (1.916)
Train: 11 [ 300/1251 ( 24%)]  Loss:  5.048561 (5.5957)  Time: 0.865s, 1183.37/s  (2.483s,  412.41/s)  LR: 5.050e-04  Data: 0.284 (1.891)
Train: 11 [ 350/1251 ( 28%)]  Loss:  5.843173 (5.6267)  Time: 0.587s, 1745.82/s  (2.452s,  417.67/s)  LR: 5.050e-04  Data: 0.021 (1.862)
Train: 11 [ 400/1251 ( 32%)]  Loss:  5.839695 (5.6503)  Time: 0.585s, 1750.34/s  (2.439s,  419.86/s)  LR: 5.050e-04  Data: 0.020 (1.850)
Train: 11 [ 450/1251 ( 36%)]  Loss:  5.746739 (5.6600)  Time: 0.587s, 1743.77/s  (2.407s,  425.34/s)  LR: 5.050e-04  Data: 0.023 (1.820)
Train: 11 [ 500/1251 ( 40%)]  Loss:  5.709750 (5.6645)  Time: 0.585s, 1750.12/s  (2.397s,  427.25/s)  LR: 5.050e-04  Data: 0.021 (1.809)
Train: 11 [ 550/1251 ( 44%)]  Loss:  5.677614 (5.6656)  Time: 4.691s,  218.28/s  (2.440s,  419.69/s)  LR: 5.050e-04  Data: 3.696 (1.851)
Train: 11 [ 600/1251 ( 48%)]  Loss:  5.527103 (5.6549)  Time: 0.585s, 1750.62/s  (2.475s,  413.78/s)  LR: 5.050e-04  Data: 0.021 (1.886)
Train: 11 [ 650/1251 ( 52%)]  Loss:  5.845193 (5.6685)  Time: 0.586s, 1746.38/s  (2.480s,  412.82/s)  LR: 5.050e-04  Data: 0.019 (1.892)
Train: 11 [ 700/1251 ( 56%)]  Loss:  5.598083 (5.6638)  Time: 0.589s, 1738.40/s  (2.492s,  410.98/s)  LR: 5.050e-04  Data: 0.024 (1.903)
Train: 11 [ 750/1251 ( 60%)]  Loss:  5.667718 (5.6641)  Time: 1.622s,  631.30/s  (2.485s,  412.00/s)  LR: 5.050e-04  Data: 1.015 (1.895)
Train: 11 [ 800/1251 ( 64%)]  Loss:  5.479266 (5.6532)  Time: 0.585s, 1751.40/s  (2.487s,  411.73/s)  LR: 5.050e-04  Data: 0.020 (1.897)
Train: 11 [ 850/1251 ( 68%)]  Loss:  5.395065 (5.6389)  Time: 6.601s,  155.13/s  (2.486s,  411.89/s)  LR: 5.050e-04  Data: 5.947 (1.895)
Train: 11 [ 900/1251 ( 72%)]  Loss:  5.122257 (5.6117)  Time: 0.586s, 1748.48/s  (2.499s,  409.72/s)  LR: 5.050e-04  Data: 0.018 (1.908)
Train: 11 [ 950/1251 ( 76%)]  Loss:  5.731013 (5.6176)  Time: 0.591s, 1733.79/s  (2.503s,  409.06/s)  LR: 5.050e-04  Data: 0.026 (1.912)
Train: 11 [1000/1251 ( 80%)]  Loss:  5.351142 (5.6050)  Time: 0.586s, 1748.24/s  (2.508s,  408.31/s)  LR: 5.050e-04  Data: 0.021 (1.917)
Train: 11 [1050/1251 ( 84%)]  Loss:  5.693400 (5.6090)  Time: 0.588s, 1741.36/s  (2.505s,  408.70/s)  LR: 5.050e-04  Data: 0.024 (1.914)
Train: 11 [1100/1251 ( 88%)]  Loss:  5.628795 (5.6098)  Time: 0.589s, 1737.59/s  (2.507s,  408.41/s)  LR: 5.050e-04  Data: 0.023 (1.916)
Train: 11 [1150/1251 ( 92%)]  Loss:  5.711359 (5.6141)  Time: 0.589s, 1738.26/s  (2.498s,  409.94/s)  LR: 5.050e-04  Data: 0.022 (1.906)
Train: 11 [1200/1251 ( 96%)]  Loss:  5.641453 (5.6152)  Time: 0.588s, 1740.72/s  (2.498s,  409.95/s)  LR: 5.050e-04  Data: 0.021 (1.906)
Train: 11 [1250/1251 (100%)]  Loss:  5.254654 (5.6013)  Time: 0.567s, 1807.04/s  (2.506s,  408.63/s)  LR: 5.050e-04  Data: 0.000 (1.915)
Test: [   0/48]  Time: 15.560 (15.560)  Loss:  2.4325 (2.4325)  Acc@1: 52.2461 (52.2461)  Acc@5: 77.4414 (77.4414)
Test: [  48/48]  Time: 0.151 (3.658)  Loss:  2.2597 (3.5626)  Acc@1: 58.9623 (29.6160)  Acc@5: 74.6462 (54.0000)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-2.pth.tar', 6.5980000396728515)

Train: 12 [   0/1251 (  0%)]  Loss:  5.629426 (5.6294)  Time: 12.152s,   84.26/s  (12.152s,   84.26/s)  LR: 4.346e-04  Data: 11.179 (11.179)
Train: 12 [  50/1251 (  4%)]  Loss:  5.326301 (5.4779)  Time: 0.588s, 1742.44/s  (2.694s,  380.07/s)  LR: 4.346e-04  Data: 0.022 (2.101)
Train: 12 [ 100/1251 (  8%)]  Loss:  5.670997 (5.5422)  Time: 0.589s, 1738.10/s  (2.598s,  394.08/s)  LR: 4.346e-04  Data: 0.020 (1.999)
Train: 12 [ 150/1251 ( 12%)]  Loss:  5.472911 (5.5249)  Time: 0.591s, 1732.95/s  (2.533s,  404.22/s)  LR: 4.346e-04  Data: 0.025 (1.930)
Train: 12 [ 200/1251 ( 16%)]  Loss:  5.882271 (5.5964)  Time: 0.587s, 1744.02/s  (2.487s,  411.80/s)  LR: 4.346e-04  Data: 0.020 (1.880)
Train: 12 [ 250/1251 ( 20%)]  Loss:  5.789135 (5.6285)  Time: 0.592s, 1730.69/s  (2.506s,  408.66/s)  LR: 4.346e-04  Data: 0.023 (1.900)
Train: 12 [ 300/1251 ( 24%)]  Loss:  5.928666 (5.6714)  Time: 1.294s,  791.32/s  (2.492s,  410.84/s)  LR: 4.346e-04  Data: 0.731 (1.881)
Train: 12 [ 350/1251 ( 28%)]  Loss:  5.719266 (5.6774)  Time: 0.590s, 1736.44/s  (2.477s,  413.42/s)  LR: 4.346e-04  Data: 0.025 (1.866)
Train: 12 [ 400/1251 ( 32%)]  Loss:  5.838143 (5.6952)  Time: 0.586s, 1747.84/s  (2.456s,  416.91/s)  LR: 4.346e-04  Data: 0.022 (1.845)
Train: 12 [ 450/1251 ( 36%)]  Loss:  5.661482 (5.6919)  Time: 0.585s, 1750.82/s  (2.449s,  418.19/s)  LR: 4.346e-04  Data: 0.021 (1.839)
Train: 12 [ 500/1251 ( 40%)]  Loss:  5.421553 (5.6673)  Time: 0.588s, 1741.95/s  (2.424s,  422.37/s)  LR: 4.346e-04  Data: 0.023 (1.819)
Train: 12 [ 550/1251 ( 44%)]  Loss:  5.436563 (5.6481)  Time: 0.587s, 1743.44/s  (2.418s,  423.52/s)  LR: 4.346e-04  Data: 0.021 (1.813)
Train: 12 [ 600/1251 ( 48%)]  Loss:  5.608822 (5.6450)  Time: 0.588s, 1740.09/s  (2.413s,  424.37/s)  LR: 4.346e-04  Data: 0.022 (1.807)
Train: 12 [ 650/1251 ( 52%)]  Loss:  5.467494 (5.6324)  Time: 0.590s, 1736.71/s  (2.454s,  417.27/s)  LR: 4.346e-04  Data: 0.023 (1.850)
Train: 12 [ 700/1251 ( 56%)]  Loss:  5.411889 (5.6177)  Time: 0.589s, 1739.62/s  (2.459s,  416.46/s)  LR: 4.346e-04  Data: 0.021 (1.856)
Train: 12 [ 750/1251 ( 60%)]  Loss:  5.651998 (5.6198)  Time: 0.589s, 1739.68/s  (2.457s,  416.78/s)  LR: 4.346e-04  Data: 0.021 (1.856)
Train: 12 [ 800/1251 ( 64%)]  Loss:  5.364926 (5.6048)  Time: 0.585s, 1750.84/s  (2.446s,  418.72/s)  LR: 4.346e-04  Data: 0.019 (1.846)
Train: 12 [ 850/1251 ( 68%)]  Loss:  5.574232 (5.6031)  Time: 0.586s, 1747.91/s  (2.439s,  419.82/s)  LR: 4.346e-04  Data: 0.019 (1.841)
Train: 12 [ 900/1251 ( 72%)]  Loss:  5.184501 (5.5811)  Time: 0.587s, 1745.29/s  (2.426s,  422.01/s)  LR: 4.346e-04  Data: 0.019 (1.829)
Train: 12 [ 950/1251 ( 76%)]  Loss:  5.425735 (5.5733)  Time: 0.587s, 1745.94/s  (2.423s,  422.67/s)  LR: 4.346e-04  Data: 0.022 (1.826)
Train: 12 [1000/1251 ( 80%)]  Loss:  5.581429 (5.5737)  Time: 0.586s, 1746.21/s  (2.426s,  422.07/s)  LR: 4.346e-04  Data: 0.021 (1.830)
Train: 12 [1050/1251 ( 84%)]  Loss:  5.538290 (5.5721)  Time: 0.589s, 1739.39/s  (2.436s,  420.40/s)  LR: 4.346e-04  Data: 0.021 (1.839)
Train: 12 [1100/1251 ( 88%)]  Loss:  5.743170 (5.5795)  Time: 0.586s, 1747.32/s  (2.440s,  419.71/s)  LR: 4.346e-04  Data: 0.022 (1.843)
Train: 12 [1150/1251 ( 92%)]  Loss:  5.637457 (5.5819)  Time: 0.591s, 1732.72/s  (2.448s,  418.28/s)  LR: 4.346e-04  Data: 0.019 (1.850)
Train: 12 [1200/1251 ( 96%)]  Loss:  5.439775 (5.5763)  Time: 0.591s, 1731.57/s  (2.447s,  418.55/s)  LR: 4.346e-04  Data: 0.026 (1.850)
Train: 12 [1250/1251 (100%)]  Loss:  5.835909 (5.5862)  Time: 0.566s, 1808.72/s  (2.444s,  418.94/s)  LR: 4.346e-04  Data: 0.000 (1.847)
Test: [   0/48]  Time: 14.554 (14.554)  Loss:  2.4677 (2.4677)  Acc@1: 50.1953 (50.1953)  Acc@5: 77.5391 (77.5391)
Test: [  48/48]  Time: 0.148 (3.372)  Loss:  2.0792 (3.4901)  Acc@1: 60.4953 (30.8860)  Acc@5: 77.3585 (55.4940)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-3.pth.tar', 8.528000010375976)

Train: 13 [   0/1251 (  0%)]  Loss:  5.890792 (5.8908)  Time: 10.902s,   93.93/s  (10.902s,   93.93/s)  LR: 3.655e-04  Data: 9.904 (9.904)
Train: 13 [  50/1251 (  4%)]  Loss:  5.831662 (5.8612)  Time: 0.592s, 1728.67/s  (2.805s,  365.01/s)  LR: 3.655e-04  Data: 0.023 (2.194)
Train: 13 [ 100/1251 (  8%)]  Loss:  5.418219 (5.7136)  Time: 0.585s, 1751.53/s  (2.737s,  374.18/s)  LR: 3.655e-04  Data: 0.020 (2.133)
Train: 13 [ 150/1251 ( 12%)]  Loss:  5.395184 (5.6340)  Time: 0.587s, 1743.90/s  (2.621s,  390.74/s)  LR: 3.655e-04  Data: 0.024 (2.026)
Train: 13 [ 200/1251 ( 16%)]  Loss:  5.287670 (5.5647)  Time: 0.586s, 1748.26/s  (2.598s,  394.10/s)  LR: 3.655e-04  Data: 0.019 (2.005)
Train: 13 [ 250/1251 ( 20%)]  Loss:  5.189081 (5.5021)  Time: 0.588s, 1741.72/s  (2.550s,  401.50/s)  LR: 3.655e-04  Data: 0.022 (1.960)
Train: 13 [ 300/1251 ( 24%)]  Loss:  5.225926 (5.4626)  Time: 0.586s, 1747.26/s  (2.518s,  406.74/s)  LR: 3.655e-04  Data: 0.023 (1.929)
Train: 13 [ 350/1251 ( 28%)]  Loss:  5.532499 (5.4714)  Time: 0.586s, 1747.48/s  (2.476s,  413.60/s)  LR: 3.655e-04  Data: 0.024 (1.886)
Train: 13 [ 400/1251 ( 32%)]  Loss:  5.797277 (5.5076)  Time: 0.591s, 1733.54/s  (2.494s,  410.56/s)  LR: 3.655e-04  Data: 0.023 (1.904)
Train: 13 [ 450/1251 ( 36%)]  Loss:  5.806395 (5.5375)  Time: 0.586s, 1747.27/s  (2.492s,  410.92/s)  LR: 3.655e-04  Data: 0.023 (1.902)
Train: 13 [ 500/1251 ( 40%)]  Loss:  5.506247 (5.5346)  Time: 0.589s, 1738.26/s  (2.512s,  407.70/s)  LR: 3.655e-04  Data: 0.023 (1.921)
Train: 13 [ 550/1251 ( 44%)]  Loss:  5.311038 (5.5160)  Time: 0.589s, 1737.35/s  (2.510s,  408.05/s)  LR: 3.655e-04  Data: 0.026 (1.920)
Train: 13 [ 600/1251 ( 48%)]  Loss:  5.154348 (5.4882)  Time: 0.590s, 1735.01/s  (2.527s,  405.30/s)  LR: 3.655e-04  Data: 0.023 (1.937)
Train: 13 [ 650/1251 ( 52%)]  Loss:  5.493684 (5.4886)  Time: 0.588s, 1742.16/s  (2.524s,  405.69/s)  LR: 3.655e-04  Data: 0.019 (1.934)
Train: 13 [ 700/1251 ( 56%)]  Loss:  5.170194 (5.4673)  Time: 0.594s, 1724.49/s  (2.521s,  406.18/s)  LR: 3.655e-04  Data: 0.024 (1.932)
Train: 13 [ 750/1251 ( 60%)]  Loss:  5.859975 (5.4919)  Time: 0.588s, 1741.46/s  (2.527s,  405.30/s)  LR: 3.655e-04  Data: 0.019 (1.937)
Train: 13 [ 800/1251 ( 64%)]  Loss:  5.413156 (5.4873)  Time: 0.591s, 1732.84/s  (2.537s,  403.56/s)  LR: 3.655e-04  Data: 0.026 (1.947)
Train: 13 [ 850/1251 ( 68%)]  Loss:  5.646502 (5.4961)  Time: 0.590s, 1735.42/s  (2.531s,  404.51/s)  LR: 3.655e-04  Data: 0.019 (1.942)
Train: 13 [ 900/1251 ( 72%)]  Loss:  5.473474 (5.4949)  Time: 0.591s, 1733.24/s  (2.533s,  404.29/s)  LR: 3.655e-04  Data: 0.020 (1.942)
Train: 13 [ 950/1251 ( 76%)]  Loss:  5.904207 (5.5154)  Time: 0.587s, 1743.12/s  (2.525s,  405.51/s)  LR: 3.655e-04  Data: 0.018 (1.935)
Train: 13 [1000/1251 ( 80%)]  Loss:  5.607963 (5.5198)  Time: 0.587s, 1743.56/s  (2.526s,  405.46/s)  LR: 3.655e-04  Data: 0.021 (1.935)
Train: 13 [1050/1251 ( 84%)]  Loss:  5.551753 (5.5212)  Time: 0.585s, 1750.48/s  (2.516s,  407.03/s)  LR: 3.655e-04  Data: 0.021 (1.925)
Train: 13 [1100/1251 ( 88%)]  Loss:  5.933971 (5.5392)  Time: 0.587s, 1745.74/s  (2.516s,  406.92/s)  LR: 3.655e-04  Data: 0.018 (1.925)
Train: 13 [1150/1251 ( 92%)]  Loss:  5.556262 (5.5399)  Time: 0.587s, 1743.74/s  (2.520s,  406.42/s)  LR: 3.655e-04  Data: 0.022 (1.928)
Train: 13 [1200/1251 ( 96%)]  Loss:  5.821869 (5.5512)  Time: 0.589s, 1738.01/s  (2.524s,  405.68/s)  LR: 3.655e-04  Data: 0.021 (1.933)
Train: 13 [1250/1251 (100%)]  Loss:  5.700781 (5.5569)  Time: 0.565s, 1813.16/s  (2.523s,  405.90/s)  LR: 3.655e-04  Data: 0.000 (1.931)
Test: [   0/48]  Time: 14.531 (14.531)  Loss:  2.3341 (2.3341)  Acc@1: 53.6133 (53.6133)  Acc@5: 76.9531 (76.9531)
Test: [  48/48]  Time: 0.149 (3.496)  Loss:  1.9527 (3.3453)  Acc@1: 63.0896 (32.5600)  Acc@5: 79.5991 (57.6160)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-4.pth.tar', 10.28000005493164)

Train: 14 [   0/1251 (  0%)]  Loss:  5.632899 (5.6329)  Time: 11.758s,   87.09/s  (11.758s,   87.09/s)  LR: 2.994e-04  Data: 10.916 (10.916)
Train: 14 [  50/1251 (  4%)]  Loss:  5.240947 (5.4369)  Time: 0.588s, 1742.53/s  (2.515s,  407.18/s)  LR: 2.994e-04  Data: 0.024 (1.917)
Train: 14 [ 100/1251 (  8%)]  Loss:  5.694476 (5.5228)  Time: 2.698s,  379.47/s  (2.469s,  414.78/s)  LR: 2.994e-04  Data: 2.136 (1.872)
Train: 14 [ 150/1251 ( 12%)]  Loss:  5.597688 (5.5415)  Time: 0.586s, 1746.04/s  (2.508s,  408.23/s)  LR: 2.994e-04  Data: 0.024 (1.906)
Train: 14 [ 200/1251 ( 16%)]  Loss:  5.390593 (5.5113)  Time: 2.144s,  477.68/s  (2.512s,  407.70/s)  LR: 2.994e-04  Data: 1.581 (1.900)
Train: 14 [ 250/1251 ( 20%)]  Loss:  5.550044 (5.5178)  Time: 0.587s, 1744.62/s  (2.514s,  407.30/s)  LR: 2.994e-04  Data: 0.021 (1.906)
Train: 14 [ 300/1251 ( 24%)]  Loss:  5.642898 (5.5356)  Time: 1.884s,  543.45/s  (2.524s,  405.64/s)  LR: 2.994e-04  Data: 1.200 (1.913)
Train: 14 [ 350/1251 ( 28%)]  Loss:  5.348015 (5.5122)  Time: 0.584s, 1752.03/s  (2.501s,  409.48/s)  LR: 2.994e-04  Data: 0.020 (1.887)
Train: 14 [ 400/1251 ( 32%)]  Loss:  5.699175 (5.5330)  Time: 0.589s, 1737.46/s  (2.492s,  410.99/s)  LR: 2.994e-04  Data: 0.019 (1.877)
Train: 14 [ 450/1251 ( 36%)]  Loss:  5.852002 (5.5649)  Time: 2.559s,  400.22/s  (2.486s,  411.96/s)  LR: 2.994e-04  Data: 1.986 (1.872)
Train: 14 [ 500/1251 ( 40%)]  Loss:  5.736129 (5.5804)  Time: 4.196s,  244.02/s  (2.473s,  414.03/s)  LR: 2.994e-04  Data: 3.526 (1.858)
Train: 14 [ 550/1251 ( 44%)]  Loss:  5.907853 (5.6077)  Time: 0.585s, 1749.82/s  (2.499s,  409.75/s)  LR: 2.994e-04  Data: 0.022 (1.884)
Train: 14 [ 600/1251 ( 48%)]  Loss:  5.462389 (5.5965)  Time: 5.906s,  173.38/s  (2.524s,  405.64/s)  LR: 2.994e-04  Data: 5.335 (1.908)
Train: 14 [ 650/1251 ( 52%)]  Loss:  5.601583 (5.5969)  Time: 0.586s, 1747.11/s  (2.534s,  404.12/s)  LR: 2.994e-04  Data: 0.023 (1.917)
Train: 14 [ 700/1251 ( 56%)]  Loss:  5.704261 (5.6041)  Time: 1.141s,  897.75/s  (2.534s,  404.13/s)  LR: 2.994e-04  Data: 0.578 (1.917)
Train: 14 [ 750/1251 ( 60%)]  Loss:  5.321264 (5.5864)  Time: 0.590s, 1734.36/s  (2.536s,  403.86/s)  LR: 2.994e-04  Data: 0.019 (1.920)
Train: 14 [ 800/1251 ( 64%)]  Loss:  5.519426 (5.5824)  Time: 0.586s, 1747.19/s  (2.526s,  405.44/s)  LR: 2.994e-04  Data: 0.023 (1.913)
Train: 14 [ 850/1251 ( 68%)]  Loss:  5.020575 (5.5512)  Time: 0.587s, 1744.23/s  (2.534s,  404.11/s)  LR: 2.994e-04  Data: 0.021 (1.923)
Train: 14 [ 900/1251 ( 72%)]  Loss:  5.322188 (5.5392)  Time: 0.584s, 1752.39/s  (2.532s,  404.35/s)  LR: 2.994e-04  Data: 0.018 (1.922)
Train: 14 [ 950/1251 ( 76%)]  Loss:  5.900371 (5.5572)  Time: 0.585s, 1751.39/s  (2.538s,  403.43/s)  LR: 2.994e-04  Data: 0.020 (1.930)
Train: 14 [1000/1251 ( 80%)]  Loss:  5.285087 (5.5443)  Time: 0.586s, 1747.65/s  (2.535s,  403.98/s)  LR: 2.994e-04  Data: 0.020 (1.926)
Train: 14 [1050/1251 ( 84%)]  Loss:  5.469179 (5.5409)  Time: 0.587s, 1743.72/s  (2.534s,  404.07/s)  LR: 2.994e-04  Data: 0.020 (1.925)
Train: 14 [1100/1251 ( 88%)]  Loss:  5.668921 (5.5464)  Time: 0.586s, 1747.86/s  (2.528s,  405.11/s)  LR: 2.994e-04  Data: 0.022 (1.920)
Train: 14 [1150/1251 ( 92%)]  Loss:  5.924947 (5.5622)  Time: 0.590s, 1736.01/s  (2.529s,  404.93/s)  LR: 2.994e-04  Data: 0.020 (1.922)
Train: 14 [1200/1251 ( 96%)]  Loss:  5.401454 (5.5558)  Time: 0.590s, 1735.75/s  (2.516s,  406.94/s)  LR: 2.994e-04  Data: 0.021 (1.910)
Train: 14 [1250/1251 (100%)]  Loss:  5.660465 (5.5598)  Time: 0.567s, 1806.88/s  (2.531s,  404.56/s)  LR: 2.994e-04  Data: 0.000 (1.925)
Test: [   0/48]  Time: 16.287 (16.287)  Loss:  2.0829 (2.0829)  Acc@1: 57.8125 (57.8125)  Acc@5: 80.8594 (80.8594)
Test: [  48/48]  Time: 0.149 (3.736)  Loss:  1.9927 (3.1984)  Acc@1: 61.9104 (35.1140)  Acc@5: 77.3585 (60.2420)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-5.pth.tar', 13.050000007324218)

Train: 15 [   0/1251 (  0%)]  Loss:  5.618787 (5.6188)  Time: 13.204s,   77.55/s  (13.204s,   77.55/s)  LR: 2.374e-04  Data: 12.133 (12.133)
Train: 15 [  50/1251 (  4%)]  Loss:  5.652845 (5.6358)  Time: 0.586s, 1746.24/s  (2.586s,  395.91/s)  LR: 2.374e-04  Data: 0.020 (1.974)
Train: 15 [ 100/1251 (  8%)]  Loss:  5.405499 (5.5590)  Time: 1.638s,  625.21/s  (2.543s,  402.62/s)  LR: 2.374e-04  Data: 1.075 (1.930)
Train: 15 [ 150/1251 ( 12%)]  Loss:  5.779142 (5.6141)  Time: 2.705s,  378.60/s  (2.496s,  410.31/s)  LR: 2.374e-04  Data: 2.010 (1.875)
Train: 15 [ 200/1251 ( 16%)]  Loss:  5.829931 (5.6572)  Time: 0.586s, 1746.56/s  (2.468s,  414.84/s)  LR: 2.374e-04  Data: 0.018 (1.855)
Train: 15 [ 250/1251 ( 20%)]  Loss:  5.143964 (5.5717)  Time: 7.199s,  142.24/s  (2.512s,  407.72/s)  LR: 2.374e-04  Data: 6.589 (1.897)
Train: 15 [ 300/1251 ( 24%)]  Loss:  5.638989 (5.5813)  Time: 0.587s, 1744.69/s  (2.505s,  408.85/s)  LR: 2.374e-04  Data: 0.017 (1.889)
Train: 15 [ 350/1251 ( 28%)]  Loss:  5.108572 (5.5222)  Time: 5.062s,  202.30/s  (2.514s,  407.37/s)  LR: 2.374e-04  Data: 4.481 (1.903)
Train: 15 [ 400/1251 ( 32%)]  Loss:  5.806164 (5.5538)  Time: 2.216s,  462.15/s  (2.505s,  408.72/s)  LR: 2.374e-04  Data: 1.534 (1.893)
Train: 15 [ 450/1251 ( 36%)]  Loss:  5.005221 (5.4989)  Time: 1.206s,  849.10/s  (2.501s,  409.47/s)  LR: 2.374e-04  Data: 0.642 (1.886)
Train: 15 [ 500/1251 ( 40%)]  Loss:  4.967695 (5.4506)  Time: 1.510s,  678.10/s  (2.494s,  410.66/s)  LR: 2.374e-04  Data: 0.936 (1.879)
Train: 15 [ 550/1251 ( 44%)]  Loss:  5.214638 (5.4310)  Time: 0.643s, 1591.92/s  (2.486s,  411.94/s)  LR: 2.374e-04  Data: 0.021 (1.872)
Train: 15 [ 600/1251 ( 48%)]  Loss:  5.652594 (5.4480)  Time: 1.704s,  601.04/s  (2.484s,  412.28/s)  LR: 2.374e-04  Data: 1.047 (1.870)
Train: 15 [ 650/1251 ( 52%)]  Loss:  5.500126 (5.4517)  Time: 0.586s, 1748.16/s  (2.526s,  405.43/s)  LR: 2.374e-04  Data: 0.018 (1.912)
Train: 15 [ 700/1251 ( 56%)]  Loss:  5.437331 (5.4508)  Time: 0.592s, 1730.84/s  (2.533s,  404.27/s)  LR: 2.374e-04  Data: 0.019 (1.921)
Train: 15 [ 750/1251 ( 60%)]  Loss:  4.761445 (5.4077)  Time: 0.588s, 1741.99/s  (2.541s,  403.00/s)  LR: 2.374e-04  Data: 0.022 (1.929)
Train: 15 [ 800/1251 ( 64%)]  Loss:  5.336328 (5.4035)  Time: 0.588s, 1740.28/s  (2.540s,  403.09/s)  LR: 2.374e-04  Data: 0.018 (1.930)
Train: 15 [ 850/1251 ( 68%)]  Loss:  5.759387 (5.4233)  Time: 0.584s, 1753.50/s  (2.544s,  402.54/s)  LR: 2.374e-04  Data: 0.020 (1.934)
Train: 15 [ 900/1251 ( 72%)]  Loss:  5.411454 (5.4226)  Time: 0.588s, 1741.10/s  (2.536s,  403.76/s)  LR: 2.374e-04  Data: 0.026 (1.928)
Train: 15 [ 950/1251 ( 76%)]  Loss:  5.654075 (5.4342)  Time: 0.587s, 1744.42/s  (2.549s,  401.71/s)  LR: 2.374e-04  Data: 0.021 (1.942)
Train: 15 [1000/1251 ( 80%)]  Loss:  5.673295 (5.4456)  Time: 0.586s, 1747.26/s  (2.552s,  401.28/s)  LR: 2.374e-04  Data: 0.019 (1.945)
Train: 15 [1050/1251 ( 84%)]  Loss:  5.232971 (5.4359)  Time: 0.586s, 1747.07/s  (2.557s,  400.51/s)  LR: 2.374e-04  Data: 0.020 (1.951)
Train: 15 [1100/1251 ( 88%)]  Loss:  5.275254 (5.4289)  Time: 0.588s, 1741.36/s  (2.552s,  401.20/s)  LR: 2.374e-04  Data: 0.020 (1.948)
Train: 15 [1150/1251 ( 92%)]  Loss:  5.528607 (5.4331)  Time: 0.585s, 1751.55/s  (2.557s,  400.46/s)  LR: 2.374e-04  Data: 0.019 (1.953)
Train: 15 [1200/1251 ( 96%)]  Loss:  5.445285 (5.4336)  Time: 0.591s, 1734.10/s  (2.550s,  401.61/s)  LR: 2.374e-04  Data: 0.021 (1.946)
Train: 15 [1250/1251 (100%)]  Loss:  5.265533 (5.4271)  Time: 0.565s, 1811.29/s  (2.546s,  402.21/s)  LR: 2.374e-04  Data: 0.000 (1.942)
Test: [   0/48]  Time: 14.649 (14.649)  Loss:  2.1529 (2.1529)  Acc@1: 57.1289 (57.1289)  Acc@5: 79.7852 (79.7852)
Test: [  48/48]  Time: 0.148 (3.676)  Loss:  1.8667 (3.1446)  Acc@1: 63.2076 (36.2960)  Acc@5: 80.5424 (61.5180)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-15.pth.tar', 36.29600004882813)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-6.pth.tar', 16.17600001586914)

Train: 16 [   0/1251 (  0%)]  Loss:  4.884405 (4.8844)  Time: 13.378s,   76.55/s  (13.378s,   76.55/s)  LR: 1.808e-04  Data: 11.894 (11.894)
Train: 16 [  50/1251 (  4%)]  Loss:  5.001312 (4.9429)  Time: 0.586s, 1747.25/s  (2.763s,  370.60/s)  LR: 1.808e-04  Data: 0.024 (2.154)
Train: 16 [ 100/1251 (  8%)]  Loss:  5.421604 (5.1024)  Time: 0.589s, 1738.27/s  (2.703s,  378.86/s)  LR: 1.808e-04  Data: 0.025 (2.108)
Train: 16 [ 150/1251 ( 12%)]  Loss:  5.543428 (5.2127)  Time: 0.584s, 1751.95/s  (2.636s,  388.53/s)  LR: 1.808e-04  Data: 0.020 (2.041)
Train: 16 [ 200/1251 ( 16%)]  Loss:  5.256489 (5.2214)  Time: 0.586s, 1746.50/s  (2.609s,  392.43/s)  LR: 1.808e-04  Data: 0.023 (2.008)
Train: 16 [ 250/1251 ( 20%)]  Loss:  5.276150 (5.2306)  Time: 0.590s, 1734.37/s  (2.546s,  402.15/s)  LR: 1.808e-04  Data: 0.020 (1.950)
Train: 16 [ 300/1251 ( 24%)]  Loss:  5.689707 (5.2962)  Time: 0.592s, 1729.01/s  (2.531s,  404.57/s)  LR: 1.808e-04  Data: 0.021 (1.935)
Train: 16 [ 350/1251 ( 28%)]  Loss:  5.670530 (5.3430)  Time: 0.585s, 1749.93/s  (2.549s,  401.72/s)  LR: 1.808e-04  Data: 0.022 (1.953)
Train: 16 [ 400/1251 ( 32%)]  Loss:  4.905039 (5.2943)  Time: 0.583s, 1757.34/s  (2.559s,  400.21/s)  LR: 1.808e-04  Data: 0.020 (1.965)
Train: 16 [ 450/1251 ( 36%)]  Loss:  5.244713 (5.2893)  Time: 0.588s, 1742.75/s  (2.547s,  401.99/s)  LR: 1.808e-04  Data: 0.020 (1.955)
Train: 16 [ 500/1251 ( 40%)]  Loss:  5.081750 (5.2705)  Time: 0.584s, 1752.14/s  (2.543s,  402.63/s)  LR: 1.808e-04  Data: 0.020 (1.951)
Train: 16 [ 550/1251 ( 44%)]  Loss:  5.571843 (5.2956)  Time: 0.781s, 1311.62/s  (2.528s,  405.07/s)  LR: 1.808e-04  Data: 0.122 (1.935)
Train: 16 [ 600/1251 ( 48%)]  Loss:  5.424924 (5.3055)  Time: 0.590s, 1736.78/s  (2.533s,  404.21/s)  LR: 1.808e-04  Data: 0.021 (1.940)
Train: 16 [ 650/1251 ( 52%)]  Loss:  5.439690 (5.3151)  Time: 3.458s,  296.08/s  (2.532s,  404.48/s)  LR: 1.808e-04  Data: 2.805 (1.938)
Train: 16 [ 700/1251 ( 56%)]  Loss:  5.332247 (5.3163)  Time: 0.591s, 1731.94/s  (2.557s,  400.52/s)  LR: 1.808e-04  Data: 0.029 (1.962)
Train: 16 [ 750/1251 ( 60%)]  Loss:  5.167756 (5.3070)  Time: 4.216s,  242.86/s  (2.568s,  398.79/s)  LR: 1.808e-04  Data: 3.276 (1.973)
Train: 16 [ 800/1251 ( 64%)]  Loss:  5.244007 (5.3033)  Time: 0.595s, 1722.11/s  (2.574s,  397.90/s)  LR: 1.808e-04  Data: 0.019 (1.976)
Train: 16 [ 850/1251 ( 68%)]  Loss:  5.354234 (5.3061)  Time: 0.597s, 1715.30/s  (2.572s,  398.20/s)  LR: 1.808e-04  Data: 0.021 (1.975)
Train: 16 [ 900/1251 ( 72%)]  Loss:  5.286680 (5.3051)  Time: 0.589s, 1738.66/s  (2.570s,  398.45/s)  LR: 1.808e-04  Data: 0.022 (1.974)
Train: 16 [ 950/1251 ( 76%)]  Loss:  5.394008 (5.3095)  Time: 0.586s, 1747.71/s  (2.560s,  399.93/s)  LR: 1.808e-04  Data: 0.022 (1.965)
Train: 16 [1000/1251 ( 80%)]  Loss:  5.067363 (5.2980)  Time: 0.586s, 1748.51/s  (2.559s,  400.10/s)  LR: 1.808e-04  Data: 0.020 (1.964)
Train: 16 [1050/1251 ( 84%)]  Loss:  5.511781 (5.3077)  Time: 0.583s, 1755.50/s  (2.573s,  398.01/s)  LR: 1.808e-04  Data: 0.021 (1.977)
Train: 16 [1100/1251 ( 88%)]  Loss:  5.571492 (5.3192)  Time: 0.584s, 1752.45/s  (2.584s,  396.25/s)  LR: 1.808e-04  Data: 0.021 (1.989)
Train: 16 [1150/1251 ( 92%)]  Loss:  5.021770 (5.3068)  Time: 0.586s, 1748.43/s  (2.586s,  396.05/s)  LR: 1.808e-04  Data: 0.019 (1.991)
Train: 16 [1200/1251 ( 96%)]  Loss:  5.457198 (5.3128)  Time: 0.584s, 1753.75/s  (2.587s,  395.76/s)  LR: 1.808e-04  Data: 0.020 (1.993)
Train: 16 [1250/1251 (100%)]  Loss:  5.484275 (5.3194)  Time: 0.564s, 1816.46/s  (2.580s,  396.96/s)  LR: 1.808e-04  Data: 0.000 (1.985)
Test: [   0/48]  Time: 15.227 (15.227)  Loss:  2.0660 (2.0660)  Acc@1: 59.5703 (59.5703)  Acc@5: 80.6641 (80.6641)
Test: [  48/48]  Time: 0.149 (3.416)  Loss:  1.7924 (3.0690)  Acc@1: 66.3915 (37.5940)  Acc@5: 81.4859 (62.8860)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-16.pth.tar', 37.59400000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-15.pth.tar', 36.29600004882813)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-7.pth.tar', 18.93600006225586)

Train: 17 [   0/1251 (  0%)]  Loss:  5.365191 (5.3652)  Time: 11.559s,   88.59/s  (11.559s,   88.59/s)  LR: 1.309e-04  Data: 10.685 (10.685)
Train: 17 [  50/1251 (  4%)]  Loss:  5.223695 (5.2944)  Time: 0.587s, 1743.89/s  (2.599s,  393.95/s)  LR: 1.309e-04  Data: 0.023 (2.006)
Train: 17 [ 100/1251 (  8%)]  Loss:  5.652143 (5.4137)  Time: 0.588s, 1741.31/s  (2.729s,  375.20/s)  LR: 1.309e-04  Data: 0.021 (2.127)
Train: 17 [ 150/1251 ( 12%)]  Loss:  5.212095 (5.3633)  Time: 0.584s, 1753.08/s  (2.728s,  375.38/s)  LR: 1.309e-04  Data: 0.021 (2.121)
Train: 17 [ 200/1251 ( 16%)]  Loss:  5.590542 (5.4087)  Time: 0.588s, 1740.56/s  (2.669s,  383.69/s)  LR: 1.309e-04  Data: 0.019 (2.066)
Train: 17 [ 250/1251 ( 20%)]  Loss:  4.971122 (5.3358)  Time: 0.588s, 1740.80/s  (2.657s,  385.40/s)  LR: 1.309e-04  Data: 0.023 (2.053)
Train: 17 [ 300/1251 ( 24%)]  Loss:  5.489248 (5.3577)  Time: 2.271s,  450.84/s  (2.608s,  392.64/s)  LR: 1.309e-04  Data: 1.610 (2.006)
Train: 17 [ 350/1251 ( 28%)]  Loss:  5.297966 (5.3503)  Time: 0.587s, 1743.20/s  (2.586s,  396.05/s)  LR: 1.309e-04  Data: 0.021 (1.985)
Train: 17 [ 400/1251 ( 32%)]  Loss:  5.646230 (5.3831)  Time: 0.588s, 1742.73/s  (2.549s,  401.66/s)  LR: 1.309e-04  Data: 0.021 (1.951)
Train: 17 [ 450/1251 ( 36%)]  Loss:  5.062275 (5.3511)  Time: 0.585s, 1749.96/s  (2.590s,  395.43/s)  LR: 1.309e-04  Data: 0.023 (1.991)
Train: 17 [ 500/1251 ( 40%)]  Loss:  5.226372 (5.3397)  Time: 0.588s, 1741.26/s  (2.593s,  394.94/s)  LR: 1.309e-04  Data: 0.020 (1.995)
Train: 17 [ 550/1251 ( 44%)]  Loss:  5.367617 (5.3420)  Time: 0.585s, 1751.31/s  (2.595s,  394.61/s)  LR: 1.309e-04  Data: 0.022 (1.998)
Train: 17 [ 600/1251 ( 48%)]  Loss:  5.479164 (5.3526)  Time: 0.586s, 1748.13/s  (2.593s,  394.94/s)  LR: 1.309e-04  Data: 0.020 (1.995)
Train: 17 [ 650/1251 ( 52%)]  Loss:  5.005219 (5.3278)  Time: 0.586s, 1747.99/s  (2.601s,  393.75/s)  LR: 1.309e-04  Data: 0.023 (2.004)
Train: 17 [ 700/1251 ( 56%)]  Loss:  4.938669 (5.3018)  Time: 0.586s, 1746.95/s  (2.584s,  396.23/s)  LR: 1.309e-04  Data: 0.021 (1.988)
Train: 17 [ 750/1251 ( 60%)]  Loss:  5.390558 (5.3074)  Time: 0.584s, 1752.46/s  (2.591s,  395.26/s)  LR: 1.309e-04  Data: 0.020 (1.995)
Train: 17 [ 800/1251 ( 64%)]  Loss:  5.687634 (5.3297)  Time: 0.583s, 1756.10/s  (2.592s,  395.02/s)  LR: 1.309e-04  Data: 0.020 (1.996)
Train: 17 [ 850/1251 ( 68%)]  Loss:  5.310648 (5.3287)  Time: 0.583s, 1754.94/s  (2.603s,  393.41/s)  LR: 1.309e-04  Data: 0.019 (2.006)
Train: 17 [ 900/1251 ( 72%)]  Loss:  5.809136 (5.3540)  Time: 0.591s, 1733.47/s  (2.597s,  394.31/s)  LR: 1.309e-04  Data: 0.022 (2.001)
Train: 17 [ 950/1251 ( 76%)]  Loss:  5.248045 (5.3487)  Time: 0.587s, 1745.75/s  (2.601s,  393.74/s)  LR: 1.309e-04  Data: 0.020 (2.005)
Train: 17 [1000/1251 ( 80%)]  Loss:  5.607896 (5.3610)  Time: 0.588s, 1742.30/s  (2.589s,  395.46/s)  LR: 1.309e-04  Data: 0.020 (1.994)
Train: 17 [1050/1251 ( 84%)]  Loss:  4.931204 (5.3415)  Time: 0.584s, 1752.92/s  (2.585s,  396.18/s)  LR: 1.309e-04  Data: 0.020 (1.989)
Train: 17 [1100/1251 ( 88%)]  Loss:  4.894646 (5.3221)  Time: 0.583s, 1755.78/s  (2.579s,  397.07/s)  LR: 1.309e-04  Data: 0.021 (1.984)
Train: 17 [1150/1251 ( 92%)]  Loss:  5.404584 (5.3255)  Time: 0.587s, 1743.61/s  (2.589s,  395.54/s)  LR: 1.309e-04  Data: 0.019 (1.994)
Train: 17 [1200/1251 ( 96%)]  Loss:  5.077903 (5.3156)  Time: 0.587s, 1745.91/s  (2.585s,  396.09/s)  LR: 1.309e-04  Data: 0.021 (1.991)
Train: 17 [1250/1251 (100%)]  Loss:  5.791888 (5.3339)  Time: 0.564s, 1815.45/s  (2.589s,  395.47/s)  LR: 1.309e-04  Data: 0.000 (1.995)
Test: [   0/48]  Time: 15.583 (15.583)  Loss:  2.0162 (2.0162)  Acc@1: 58.3008 (58.3008)  Acc@5: 82.6172 (82.6172)
Test: [  48/48]  Time: 0.148 (3.561)  Loss:  1.7324 (3.0192)  Acc@1: 66.3915 (38.2280)  Acc@5: 81.8396 (63.5140)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-17.pth.tar', 38.22800000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-16.pth.tar', 37.59400000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-15.pth.tar', 36.29600004882813)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-8.pth.tar', 22.012000002441408)

Train: 18 [   0/1251 (  0%)]  Loss:  5.766208 (5.7662)  Time: 12.183s,   84.05/s  (12.183s,   84.05/s)  LR: 8.858e-05  Data: 11.176 (11.176)
Train: 18 [  50/1251 (  4%)]  Loss:  5.509038 (5.6376)  Time: 0.589s, 1739.49/s  (2.618s,  391.10/s)  LR: 8.858e-05  Data: 0.026 (2.025)
Train: 18 [ 100/1251 (  8%)]  Loss:  5.667994 (5.6477)  Time: 0.589s, 1737.37/s  (2.550s,  401.62/s)  LR: 8.858e-05  Data: 0.021 (1.958)
Train: 18 [ 150/1251 ( 12%)]  Loss:  5.721528 (5.6662)  Time: 0.583s, 1755.12/s  (2.641s,  387.79/s)  LR: 8.858e-05  Data: 0.020 (2.049)
Train: 18 [ 200/1251 ( 16%)]  Loss:  5.640339 (5.6610)  Time: 1.765s,  580.24/s  (2.628s,  389.66/s)  LR: 8.858e-05  Data: 1.189 (2.025)
Train: 18 [ 250/1251 ( 20%)]  Loss:  5.003867 (5.5515)  Time: 0.583s, 1755.43/s  (2.614s,  391.80/s)  LR: 8.858e-05  Data: 0.019 (2.003)
Train: 18 [ 300/1251 ( 24%)]  Loss:  5.554637 (5.5519)  Time: 1.342s,  762.95/s  (2.604s,  393.27/s)  LR: 8.858e-05  Data: 0.758 (1.989)
Train: 18 [ 350/1251 ( 28%)]  Loss:  5.518946 (5.5478)  Time: 0.584s, 1752.40/s  (2.573s,  398.03/s)  LR: 8.858e-05  Data: 0.021 (1.956)
Train: 18 [ 400/1251 ( 32%)]  Loss:  5.262571 (5.5161)  Time: 0.590s, 1736.30/s  (2.564s,  399.32/s)  LR: 8.858e-05  Data: 0.026 (1.944)
Train: 18 [ 450/1251 ( 36%)]  Loss:  5.477290 (5.5122)  Time: 0.589s, 1739.77/s  (2.538s,  403.45/s)  LR: 8.858e-05  Data: 0.023 (1.922)
Train: 18 [ 500/1251 ( 40%)]  Loss:  5.411739 (5.5031)  Time: 1.347s,  760.31/s  (2.576s,  397.51/s)  LR: 8.858e-05  Data: 0.781 (1.959)
Train: 18 [ 550/1251 ( 44%)]  Loss:  5.111441 (5.4705)  Time: 4.400s,  232.75/s  (2.580s,  396.98/s)  LR: 8.858e-05  Data: 3.837 (1.962)
Train: 18 [ 600/1251 ( 48%)]  Loss:  5.311319 (5.4582)  Time: 0.589s, 1737.49/s  (2.597s,  394.34/s)  LR: 8.858e-05  Data: 0.021 (1.979)
Train: 18 [ 650/1251 ( 52%)]  Loss:  4.688336 (5.4032)  Time: 6.615s,  154.79/s  (2.605s,  393.11/s)  LR: 8.858e-05  Data: 5.985 (1.988)
Train: 18 [ 700/1251 ( 56%)]  Loss:  5.519537 (5.4110)  Time: 0.586s, 1746.29/s  (2.601s,  393.71/s)  LR: 8.858e-05  Data: 0.020 (1.984)
Train: 18 [ 750/1251 ( 60%)]  Loss:  5.111771 (5.3923)  Time: 0.919s, 1114.57/s  (2.598s,  394.16/s)  LR: 8.858e-05  Data: 0.315 (1.980)
Train: 18 [ 800/1251 ( 64%)]  Loss:  5.466393 (5.3966)  Time: 5.030s,  203.58/s  (2.594s,  394.81/s)  LR: 8.858e-05  Data: 4.435 (1.975)
Train: 18 [ 850/1251 ( 68%)]  Loss:  5.736087 (5.4155)  Time: 3.846s,  266.24/s  (2.606s,  392.90/s)  LR: 8.858e-05  Data: 3.179 (1.988)
Train: 18 [ 900/1251 ( 72%)]  Loss:  5.513096 (5.4206)  Time: 3.484s,  293.88/s  (2.614s,  391.78/s)  LR: 8.858e-05  Data: 2.922 (1.997)
Train: 18 [ 950/1251 ( 76%)]  Loss:  5.305375 (5.4149)  Time: 4.873s,  210.13/s  (2.616s,  391.50/s)  LR: 8.858e-05  Data: 4.222 (1.999)
Train: 18 [1000/1251 ( 80%)]  Loss:  4.888705 (5.3898)  Time: 3.289s,  311.34/s  (2.613s,  391.84/s)  LR: 8.858e-05  Data: 2.561 (1.997)
Train: 18 [1050/1251 ( 84%)]  Loss:  5.173975 (5.3800)  Time: 4.805s,  213.13/s  (2.612s,  391.99/s)  LR: 8.858e-05  Data: 4.242 (1.996)
Train: 18 [1100/1251 ( 88%)]  Loss:  5.709413 (5.3943)  Time: 0.587s, 1745.47/s  (2.607s,  392.84/s)  LR: 8.858e-05  Data: 0.020 (1.991)
Train: 18 [1150/1251 ( 92%)]  Loss:  5.604762 (5.4031)  Time: 7.577s,  135.15/s  (2.600s,  393.79/s)  LR: 8.858e-05  Data: 6.927 (1.985)
Train: 18 [1200/1251 ( 96%)]  Loss:  5.562801 (5.4095)  Time: 1.485s,  689.53/s  (2.614s,  391.67/s)  LR: 8.858e-05  Data: 0.923 (1.999)
Train: 18 [1250/1251 (100%)]  Loss:  5.595668 (5.4166)  Time: 0.564s, 1814.27/s  (2.615s,  391.66/s)  LR: 8.858e-05  Data: 0.000 (1.999)
Test: [   0/48]  Time: 15.559 (15.559)  Loss:  1.9583 (1.9583)  Acc@1: 59.5703 (59.5703)  Acc@5: 83.2031 (83.2031)
Test: [  48/48]  Time: 0.148 (3.599)  Loss:  1.8088 (2.9794)  Acc@1: 66.7453 (39.0120)  Acc@5: 80.7783 (64.2620)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-18.pth.tar', 39.012000034179685)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-17.pth.tar', 38.22800000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-16.pth.tar', 37.59400000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-15.pth.tar', 36.29600004882813)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-9.pth.tar', 24.527999958496093)

Train: 19 [   0/1251 (  0%)]  Loss:  5.627905 (5.6279)  Time: 12.298s,   83.26/s  (12.298s,   83.26/s)  LR: 5.473e-05  Data: 11.570 (11.570)
Train: 19 [  50/1251 (  4%)]  Loss:  5.539750 (5.5838)  Time: 1.164s,  879.52/s  (2.672s,  383.20/s)  LR: 5.473e-05  Data: 0.572 (2.055)
Train: 19 [ 100/1251 (  8%)]  Loss:  5.417601 (5.5284)  Time: 0.703s, 1456.53/s  (2.582s,  396.62/s)  LR: 5.473e-05  Data: 0.020 (1.968)
Train: 19 [ 150/1251 ( 12%)]  Loss:  5.313128 (5.4746)  Time: 4.253s,  240.77/s  (2.562s,  399.67/s)  LR: 5.473e-05  Data: 3.593 (1.948)
Train: 19 [ 200/1251 ( 16%)]  Loss:  5.103154 (5.4003)  Time: 2.245s,  456.19/s  (2.703s,  378.84/s)  LR: 5.473e-05  Data: 1.473 (2.085)
Train: 19 [ 250/1251 ( 20%)]  Loss:  5.450206 (5.4086)  Time: 1.403s,  729.88/s  (2.730s,  375.06/s)  LR: 5.473e-05  Data: 0.711 (2.116)
Train: 19 [ 300/1251 ( 24%)]  Loss:  4.703612 (5.3079)  Time: 0.585s, 1750.21/s  (2.751s,  372.23/s)  LR: 5.473e-05  Data: 0.021 (2.136)
Train: 19 [ 350/1251 ( 28%)]  Loss:  5.554423 (5.3387)  Time: 0.583s, 1755.97/s  (2.741s,  373.58/s)  LR: 5.473e-05  Data: 0.020 (2.126)
Train: 19 [ 400/1251 ( 32%)]  Loss:  5.692768 (5.3781)  Time: 0.587s, 1745.68/s  (2.743s,  373.37/s)  LR: 5.473e-05  Data: 0.019 (2.130)
Train: 19 [ 450/1251 ( 36%)]  Loss:  4.997132 (5.3400)  Time: 0.591s, 1731.33/s  (2.701s,  379.07/s)  LR: 5.473e-05  Data: 0.020 (2.090)
Train: 19 [ 500/1251 ( 40%)]  Loss:  4.956184 (5.3051)  Time: 0.585s, 1751.80/s  (2.686s,  381.27/s)  LR: 5.473e-05  Data: 0.020 (2.075)
Train: 19 [ 550/1251 ( 44%)]  Loss:  5.313471 (5.3058)  Time: 0.589s, 1739.48/s  (2.759s,  371.19/s)  LR: 5.473e-05  Data: 0.025 (2.148)
Train: 19 [ 600/1251 ( 48%)]  Loss:  5.589756 (5.3276)  Time: 0.585s, 1749.42/s  (2.775s,  368.98/s)  LR: 5.473e-05  Data: 0.023 (2.165)
Train: 19 [ 650/1251 ( 52%)]  Loss:  5.516174 (5.3411)  Time: 0.587s, 1743.14/s  (2.810s,  364.37/s)  LR: 5.473e-05  Data: 0.024 (2.202)
Train: 19 [ 700/1251 ( 56%)]  Loss:  5.773390 (5.3699)  Time: 0.588s, 1741.39/s  (2.813s,  364.07/s)  LR: 5.473e-05  Data: 0.021 (2.204)
Train: 19 [ 750/1251 ( 60%)]  Loss:  5.045238 (5.3496)  Time: 0.586s, 1746.16/s  (2.814s,  363.91/s)  LR: 5.473e-05  Data: 0.023 (2.207)
Train: 19 [ 800/1251 ( 64%)]  Loss:  5.445461 (5.3553)  Time: 0.586s, 1747.55/s  (2.789s,  367.17/s)  LR: 5.473e-05  Data: 0.023 (2.183)
Train: 19 [ 850/1251 ( 68%)]  Loss:  5.377335 (5.3565)  Time: 0.590s, 1736.26/s  (2.793s,  366.60/s)  LR: 5.473e-05  Data: 0.020 (2.189)
Train: 19 [ 900/1251 ( 72%)]  Loss:  4.995331 (5.3375)  Time: 0.587s, 1743.45/s  (2.784s,  367.82/s)  LR: 5.473e-05  Data: 0.021 (2.181)
Train: 19 [ 950/1251 ( 76%)]  Loss:  5.336867 (5.3374)  Time: 0.586s, 1747.28/s  (2.784s,  367.87/s)  LR: 5.473e-05  Data: 0.022 (2.182)
Train: 19 [1000/1251 ( 80%)]  Loss:  5.693616 (5.3544)  Time: 0.590s, 1736.83/s  (2.769s,  369.77/s)  LR: 5.473e-05  Data: 0.023 (2.168)
Train: 19 [1050/1251 ( 84%)]  Loss:  4.709120 (5.3251)  Time: 0.586s, 1746.57/s  (2.757s,  371.47/s)  LR: 5.473e-05  Data: 0.021 (2.155)
Train: 19 [1100/1251 ( 88%)]  Loss:  5.318933 (5.3248)  Time: 0.588s, 1740.74/s  (2.741s,  373.63/s)  LR: 5.473e-05  Data: 0.021 (2.140)
Train: 19 [1150/1251 ( 92%)]  Loss:  4.658963 (5.2971)  Time: 0.585s, 1750.16/s  (2.729s,  375.22/s)  LR: 5.473e-05  Data: 0.020 (2.129)
Train: 19 [1200/1251 ( 96%)]  Loss:  5.046268 (5.2870)  Time: 0.587s, 1743.07/s  (2.728s,  375.42/s)  LR: 5.473e-05  Data: 0.026 (2.128)
Train: 19 [1250/1251 (100%)]  Loss:  5.482848 (5.2946)  Time: 0.564s, 1815.15/s  (2.729s,  375.19/s)  LR: 5.473e-05  Data: 0.000 (2.130)
Test: [   0/48]  Time: 16.059 (16.059)  Loss:  1.8567 (1.8567)  Acc@1: 61.9141 (61.9141)  Acc@5: 84.0820 (84.0820)
Test: [  48/48]  Time: 0.149 (3.576)  Loss:  1.7723 (2.9516)  Acc@1: 66.7453 (39.5580)  Acc@5: 82.1934 (64.9580)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-19.pth.tar', 39.558000034179685)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-18.pth.tar', 39.012000034179685)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-17.pth.tar', 38.22800000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-16.pth.tar', 37.59400000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-15.pth.tar', 36.29600004882813)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-10.pth.tar', 27.038000047607422)

Train: 20 [   0/1251 (  0%)]  Loss:  4.951796 (4.9518)  Time: 12.501s,   81.92/s  (12.501s,   81.92/s)  LR: 3.005e-05  Data: 11.065 (11.065)
Train: 20 [  50/1251 (  4%)]  Loss:  5.441181 (5.1965)  Time: 0.586s, 1746.58/s  (2.566s,  398.99/s)  LR: 3.005e-05  Data: 0.022 (1.952)
Train: 20 [ 100/1251 (  8%)]  Loss:  5.201883 (5.1983)  Time: 1.177s,  870.17/s  (2.520s,  406.38/s)  LR: 3.005e-05  Data: 0.586 (1.908)
Train: 20 [ 150/1251 ( 12%)]  Loss:  5.614104 (5.3022)  Time: 0.587s, 1743.35/s  (2.427s,  421.85/s)  LR: 3.005e-05  Data: 0.020 (1.820)
Train: 20 [ 200/1251 ( 16%)]  Loss:  5.752352 (5.3923)  Time: 0.588s, 1741.90/s  (2.457s,  416.82/s)  LR: 3.005e-05  Data: 0.020 (1.852)
Train: 20 [ 250/1251 ( 20%)]  Loss:  5.300874 (5.3770)  Time: 2.605s,  393.14/s  (2.458s,  416.53/s)  LR: 3.005e-05  Data: 2.016 (1.854)
Train: 20 [ 300/1251 ( 24%)]  Loss:  5.088337 (5.3358)  Time: 0.589s, 1738.78/s  (2.484s,  412.22/s)  LR: 3.005e-05  Data: 0.020 (1.877)
Train: 20 [ 350/1251 ( 28%)]  Loss:  5.520464 (5.3589)  Time: 1.146s,  893.76/s  (2.477s,  413.46/s)  LR: 3.005e-05  Data: 0.583 (1.870)
Train: 20 [ 400/1251 ( 32%)]  Loss:  5.250075 (5.3468)  Time: 0.588s, 1740.12/s  (2.479s,  413.02/s)  LR: 3.005e-05  Data: 0.022 (1.874)
Train: 20 [ 450/1251 ( 36%)]  Loss:  4.757945 (5.2879)  Time: 0.852s, 1202.26/s  (2.468s,  414.95/s)  LR: 3.005e-05  Data: 0.287 (1.865)
Train: 20 [ 500/1251 ( 40%)]  Loss:  5.138007 (5.2743)  Time: 0.587s, 1744.08/s  (2.467s,  415.06/s)  LR: 3.005e-05  Data: 0.022 (1.865)
Train: 20 [ 550/1251 ( 44%)]  Loss:  5.296853 (5.2762)  Time: 2.724s,  375.91/s  (2.449s,  418.17/s)  LR: 3.005e-05  Data: 2.078 (1.847)
Train: 20 [ 600/1251 ( 48%)]  Loss:  5.542256 (5.2966)  Time: 0.588s, 1741.32/s  (2.489s,  411.33/s)  LR: 3.005e-05  Data: 0.021 (1.888)
Train: 20 [ 650/1251 ( 52%)]  Loss:  5.105676 (5.2830)  Time: 0.586s, 1746.98/s  (2.509s,  408.17/s)  LR: 3.005e-05  Data: 0.021 (1.906)
Train: 20 [ 700/1251 ( 56%)]  Loss:  5.338228 (5.2867)  Time: 0.587s, 1745.31/s  (2.514s,  407.25/s)  LR: 3.005e-05  Data: 0.020 (1.912)
Train: 20 [ 750/1251 ( 60%)]  Loss:  5.312229 (5.2883)  Time: 0.589s, 1737.68/s  (2.522s,  406.00/s)  LR: 3.005e-05  Data: 0.020 (1.920)
Train: 20 [ 800/1251 ( 64%)]  Loss:  5.611796 (5.3073)  Time: 0.589s, 1737.90/s  (2.517s,  406.91/s)  LR: 3.005e-05  Data: 0.024 (1.915)
Train: 20 [ 850/1251 ( 68%)]  Loss:  5.409517 (5.3130)  Time: 0.584s, 1751.97/s  (2.516s,  407.06/s)  LR: 3.005e-05  Data: 0.021 (1.914)
Train: 20 [ 900/1251 ( 72%)]  Loss:  4.811404 (5.2866)  Time: 0.586s, 1746.19/s  (2.512s,  407.65/s)  LR: 3.005e-05  Data: 0.020 (1.909)
Train: 20 [ 950/1251 ( 76%)]  Loss:  5.092342 (5.2769)  Time: 0.586s, 1748.44/s  (2.534s,  404.03/s)  LR: 3.005e-05  Data: 0.022 (1.932)
Train: 20 [1000/1251 ( 80%)]  Loss:  5.322776 (5.2791)  Time: 0.587s, 1744.56/s  (2.545s,  402.29/s)  LR: 3.005e-05  Data: 0.022 (1.943)
Train: 20 [1050/1251 ( 84%)]  Loss:  4.914491 (5.2625)  Time: 0.587s, 1744.05/s  (2.548s,  401.94/s)  LR: 3.005e-05  Data: 0.019 (1.946)
Train: 20 [1100/1251 ( 88%)]  Loss:  5.195534 (5.2596)  Time: 0.587s, 1743.87/s  (2.553s,  401.14/s)  LR: 3.005e-05  Data: 0.025 (1.951)
Train: 20 [1150/1251 ( 92%)]  Loss:  5.039196 (5.2504)  Time: 0.588s, 1742.09/s  (2.549s,  401.66/s)  LR: 3.005e-05  Data: 0.019 (1.947)
Train: 20 [1200/1251 ( 96%)]  Loss:  5.439238 (5.2579)  Time: 0.587s, 1744.43/s  (2.544s,  402.48/s)  LR: 3.005e-05  Data: 0.024 (1.943)
Train: 20 [1250/1251 (100%)]  Loss:  5.632435 (5.2723)  Time: 0.567s, 1804.58/s  (2.551s,  401.38/s)  LR: 3.005e-05  Data: 0.000 (1.949)
Test: [   0/48]  Time: 17.485 (17.485)  Loss:  1.8801 (1.8801)  Acc@1: 61.8164 (61.8164)  Acc@5: 83.9844 (83.9844)
Test: [  48/48]  Time: 0.150 (3.728)  Loss:  1.7441 (2.9305)  Acc@1: 66.9811 (39.8800)  Acc@5: 81.6038 (65.2540)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-20.pth.tar', 39.88000000732422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-19.pth.tar', 39.558000034179685)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-18.pth.tar', 39.012000034179685)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-17.pth.tar', 38.22800000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-16.pth.tar', 37.59400000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-15.pth.tar', 36.29600004882813)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-11.pth.tar', 29.61600001464844)

Train: 21 [   0/1251 (  0%)]  Loss:  5.633553 (5.6336)  Time: 12.169s,   84.15/s  (12.169s,   84.15/s)  LR: 1.504e-05  Data: 11.391 (11.391)
Train: 21 [  50/1251 (  4%)]  Loss:  5.277892 (5.4557)  Time: 0.585s, 1750.61/s  (2.723s,  376.01/s)  LR: 1.504e-05  Data: 0.020 (2.115)
Train: 21 [ 100/1251 (  8%)]  Loss:  5.399651 (5.4370)  Time: 0.981s, 1043.75/s  (2.693s,  380.29/s)  LR: 1.504e-05  Data: 0.275 (2.071)
Train: 21 [ 150/1251 ( 12%)]  Loss:  5.218486 (5.3824)  Time: 0.588s, 1742.80/s  (2.626s,  389.94/s)  LR: 1.504e-05  Data: 0.020 (2.006)
Train: 21 [ 200/1251 ( 16%)]  Loss:  4.948335 (5.2956)  Time: 0.589s, 1739.97/s  (2.622s,  390.58/s)  LR: 1.504e-05  Data: 0.020 (2.007)
Train: 21 [ 250/1251 ( 20%)]  Loss:  5.307642 (5.2976)  Time: 0.587s, 1745.70/s  (2.567s,  398.85/s)  LR: 1.504e-05  Data: 0.020 (1.960)
Train: 21 [ 300/1251 ( 24%)]  Loss:  5.395015 (5.3115)  Time: 0.588s, 1742.74/s  (2.621s,  390.63/s)  LR: 1.504e-05  Data: 0.020 (2.018)
Train: 21 [ 350/1251 ( 28%)]  Loss:  5.192480 (5.2966)  Time: 0.589s, 1739.39/s  (2.608s,  392.61/s)  LR: 1.504e-05  Data: 0.023 (2.005)
Train: 21 [ 400/1251 ( 32%)]  Loss:  5.525532 (5.3221)  Time: 0.589s, 1739.10/s  (2.614s,  391.67/s)  LR: 1.504e-05  Data: 0.019 (2.014)
Train: 21 [ 450/1251 ( 36%)]  Loss:  5.551931 (5.3451)  Time: 0.590s, 1735.07/s  (2.593s,  394.92/s)  LR: 1.504e-05  Data: 0.026 (1.994)
Train: 21 [ 500/1251 ( 40%)]  Loss:  5.040472 (5.3174)  Time: 2.406s,  425.64/s  (2.583s,  396.51/s)  LR: 1.504e-05  Data: 1.747 (1.984)
Train: 21 [ 550/1251 ( 44%)]  Loss:  5.450450 (5.3285)  Time: 0.588s, 1740.67/s  (2.562s,  399.75/s)  LR: 1.504e-05  Data: 0.024 (1.964)
Train: 21 [ 600/1251 ( 48%)]  Loss:  5.652299 (5.3534)  Time: 3.526s,  290.41/s  (2.560s,  400.01/s)  LR: 1.504e-05  Data: 2.859 (1.959)
Train: 21 [ 650/1251 ( 52%)]  Loss:  5.023380 (5.3298)  Time: 0.587s, 1745.01/s  (2.582s,  396.65/s)  LR: 1.504e-05  Data: 0.019 (1.979)
Train: 21 [ 700/1251 ( 56%)]  Loss:  5.034082 (5.3101)  Time: 3.796s,  269.78/s  (2.594s,  394.76/s)  LR: 1.504e-05  Data: 3.217 (1.991)
Train: 21 [ 750/1251 ( 60%)]  Loss:  5.349864 (5.3126)  Time: 0.585s, 1749.26/s  (2.589s,  395.53/s)  LR: 1.504e-05  Data: 0.023 (1.986)
Train: 21 [ 800/1251 ( 64%)]  Loss:  5.567069 (5.3275)  Time: 0.584s, 1753.04/s  (2.592s,  395.11/s)  LR: 1.504e-05  Data: 0.020 (1.990)
Train: 21 [ 850/1251 ( 68%)]  Loss:  4.724651 (5.2940)  Time: 0.589s, 1738.34/s  (2.582s,  396.57/s)  LR: 1.504e-05  Data: 0.023 (1.981)
Train: 21 [ 900/1251 ( 72%)]  Loss:  4.668773 (5.2611)  Time: 0.584s, 1753.72/s  (2.575s,  397.62/s)  LR: 1.504e-05  Data: 0.019 (1.975)
Train: 21 [ 950/1251 ( 76%)]  Loss:  5.209841 (5.2586)  Time: 0.583s, 1757.35/s  (2.570s,  398.43/s)  LR: 1.504e-05  Data: 0.021 (1.970)
Train: 21 [1000/1251 ( 80%)]  Loss:  5.434248 (5.2669)  Time: 0.584s, 1752.97/s  (2.599s,  393.94/s)  LR: 1.504e-05  Data: 0.019 (1.999)
Train: 21 [1050/1251 ( 84%)]  Loss:  5.475005 (5.2764)  Time: 1.440s,  711.07/s  (2.612s,  391.99/s)  LR: 1.504e-05  Data: 0.878 (2.011)
Train: 21 [1100/1251 ( 88%)]  Loss:  5.376025 (5.2807)  Time: 0.588s, 1740.68/s  (2.624s,  390.29/s)  LR: 1.504e-05  Data: 0.025 (2.020)
Train: 21 [1150/1251 ( 92%)]  Loss:  5.453876 (5.2879)  Time: 3.257s,  314.38/s  (2.630s,  389.34/s)  LR: 1.504e-05  Data: 2.695 (2.025)
Train: 21 [1200/1251 ( 96%)]  Loss:  5.428348 (5.2936)  Time: 0.586s, 1746.46/s  (2.632s,  389.05/s)  LR: 1.504e-05  Data: 0.021 (2.026)
Train: 21 [1250/1251 (100%)]  Loss:  5.447075 (5.2995)  Time: 0.566s, 1809.38/s  (2.628s,  389.70/s)  LR: 1.504e-05  Data: 0.000 (2.022)
Test: [   0/48]  Time: 14.786 (14.786)  Loss:  1.8929 (1.8929)  Acc@1: 60.7422 (60.7422)  Acc@5: 84.1797 (84.1797)
Test: [  48/48]  Time: 0.149 (3.592)  Loss:  1.7264 (2.9191)  Acc@1: 66.9811 (40.2020)  Acc@5: 82.7830 (65.5200)
Current checkpoints:
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-21.pth.tar', 40.202000007324216)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-20.pth.tar', 39.88000000732422)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-19.pth.tar', 39.558000034179685)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-18.pth.tar', 39.012000034179685)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-17.pth.tar', 38.22800000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-16.pth.tar', 37.59400000976562)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-15.pth.tar', 36.29600004882813)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-14.pth.tar', 35.11400000244141)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-13.pth.tar', 32.55999999755859)
 ('train_result/PreTraining_vit_deit_tiny_patch16_224_1k/checkpoint-12.pth.tar', 30.886000034179688)

*** Best metric: 40.202000007324216 (epoch 21)

wandb: Waiting for W&B process to finish, PID 15045
wandb: Program ended successfully.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210523_173510-PreTraining_vit_deit_tiny_patch16_224_1k/logs/debug.log
wandb: Find internal logs for this run at: /gs/hs0/tga-i/sugiyama.y.al/TIMM/pytorch-image-models/wandb/run-20210523_173510-PreTraining_vit_deit_tiny_patch16_224_1k/logs/debug-internal.log
wandb: Run summary:
wandb:        epoch 21
wandb:   train_loss 5.29946
wandb:    eval_loss 2.91906
wandb:    eval_top1 40.202
wandb:    eval_top5 65.52
wandb:     _runtime 72667
wandb:   _timestamp 1621831577
wandb:        _step 21
wandb: Run history:
wandb:        epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:    eval_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    eval_top1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    eval_top5 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     _runtime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   _timestamp ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:        _step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced PreTraining_vit_deit_tiny_patch16_224_1k: https://wandb.ai/gyama_x/pytorch-image-models/runs/PreTraining_vit_deit_tiny_patch16_224_1k
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
--End--
Mon May 24 13:46:29 JST 2021
